{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You used two hidden layers. Try using one or three hidden layers, and see how doing so affects validation and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "    num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000): \n",
    "    results = np.zeros((len(sequences), dimension)) \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1. \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data) \n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "part_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "part_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 9s 342us/step - loss: 0.4506 - acc: 0.8292\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 6s 228us/step - loss: 0.2769 - acc: 0.9070\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 5s 201us/step - loss: 0.2189 - acc: 0.9249\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 5s 212us/step - loss: 0.1881 - acc: 0.9351\n",
      "25000/25000 [==============================] - 10s 415us/step\n",
      "[0.28889801345825195, 0.88328]\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) #one hidden layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test) \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 7s 267us/step - loss: 0.4582 - acc: 0.8196\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s 215us/step - loss: 0.2508 - acc: 0.9066\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 5s 210us/step - loss: 0.1951 - acc: 0.9293\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 5s 204us/step - loss: 0.1607 - acc: 0.9424\n",
      "25000/25000 [==============================] - 5s 219us/step\n",
      "[0.3069689905548096, 0.88232]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) #three hidden layers\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test) \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "\n",
    "1 слой: [0.28889801345825195, 0.88328]\n",
    "\n",
    "2 слоя: [0.2992042181968689, 0.88172] (результаты взяты из Lecture2)\n",
    "\n",
    "3 слоя: [0.3069689905548096, 0.88232]\n",
    "\n",
    "Однослойная модель показывает чуть бОльшую точность, но этот отрыв может исчезнуть при перезапуске."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using layers with more hidden units or fewer hidden units: 32 units, 64 units, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 6s 258us/step - loss: 0.4244 - acc: 0.8220\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 6s 220us/step - loss: 0.2404 - acc: 0.9124\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 5s 219us/step - loss: 0.1893 - acc: 0.9300\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 6s 234us/step - loss: 0.1587 - acc: 0.9433\n",
      "25000/25000 [==============================] - 6s 228us/step\n",
      "[0.31684351998806, 0.87772]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 7s 284us/step - loss: 0.4183 - acc: 0.8166\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 8s 329us/step - loss: 0.2336 - acc: 0.9105\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 7s 289us/step - loss: 0.1841 - acc: 0.9287\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 7s 275us/step - loss: 0.1439 - acc: 0.9459\n",
      "25000/25000 [==============================] - 7s 268us/step\n",
      "[0.3457731051063538, 0.87328]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "16 нейронов: [0.2992042181968689, 0.88172] (результаты взяты из Lecture2)\n",
    "\n",
    "32 нейрона: [0.31684351998806, 0.87772]\n",
    "\n",
    "64 нейрона: [0.3457731051063538, 0.87328]\n",
    "\n",
    "Модель с 16 нейронами дает большую точность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using the mse loss function instead of binary_crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 5s 214us/step - loss: 0.1483 - acc: 0.8120\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s 192us/step - loss: 0.0761 - acc: 0.9117\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 5s 210us/step - loss: 0.0577 - acc: 0.9310\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 5s 195us/step - loss: 0.0475 - acc: 0.9431\n",
      "25000/25000 [==============================] - 5s 214us/step\n",
      "[0.09209134727954864, 0.87588]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Сравниваем функции потерь:\n",
    "\n",
    "binary_crossentropy [0.2992042181968689, 0.88172] (результаты взяты из Lecture2)\n",
    "\n",
    "mse [0.09209134727954864, 0.87588]\n",
    "\n",
    "У нас задача классификации, в ней используется binary_crossentropy. MSE для задач регрессии. Но при MSE заметно уменьшается test loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using the tanh activation (an activation that was popular in the early days of neural networks) instead of relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 6s 252us/step - loss: 0.4290 - acc: 0.8332\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s 187us/step - loss: 0.2367 - acc: 0.9141\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 5s 206us/step - loss: 0.1769 - acc: 0.9353\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 5s 219us/step - loss: 0.1484 - acc: 0.9455\n",
      "25000/25000 [==============================] - 6s 230us/step\n",
      "[0.35529177773714066, 0.86956]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Сравниваем функции активации:\n",
    "    \n",
    "relu:[0.2992042181968689, 0.88172] (результаты взяты из Lecture2)\n",
    "    \n",
    "tanh:[0.35529177773714066, 0.86956]\n",
    "    \n",
    "При использовании функции активации \"tanh\" точность уменьшается, а test loss увеличивается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "## Try using larger or smaller layers: 32 units, 128 units, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
    "    num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 352us/step - loss: 3.0949 - acc: 0.4847 - val_loss: 2.3680 - val_acc: 0.5730\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 196us/step - loss: 1.9645 - acc: 0.6055 - val_loss: 1.7334 - val_acc: 0.6240\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 195us/step - loss: 1.4699 - acc: 0.6863 - val_loss: 1.4556 - val_acc: 0.6850\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 207us/step - loss: 1.2077 - acc: 0.7403 - val_loss: 1.2995 - val_acc: 0.7020\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 195us/step - loss: 1.0267 - acc: 0.7751 - val_loss: 1.1925 - val_acc: 0.7360\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 195us/step - loss: 0.8850 - acc: 0.8087 - val_loss: 1.1186 - val_acc: 0.7680\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 197us/step - loss: 0.7725 - acc: 0.8312 - val_loss: 1.0764 - val_acc: 0.7720\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 195us/step - loss: 0.6742 - acc: 0.8527 - val_loss: 1.0397 - val_acc: 0.7770\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 211us/step - loss: 0.5887 - acc: 0.8697 - val_loss: 1.0133 - val_acc: 0.7850\n",
      "2246/2246 [==============================] - 1s 502us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0746706011883405, 0.7573463936416782]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 408us/step - loss: 2.6565 - acc: 0.5316 - val_loss: 1.7434 - val_acc: 0.6420\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 1.4065 - acc: 0.7146 - val_loss: 1.3234 - val_acc: 0.7180\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 245us/step - loss: 1.0457 - acc: 0.7760 - val_loss: 1.1490 - val_acc: 0.7450\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 247us/step - loss: 0.8323 - acc: 0.8218 - val_loss: 1.0537 - val_acc: 0.7820\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 249us/step - loss: 0.6693 - acc: 0.8583 - val_loss: 0.9862 - val_acc: 0.7900\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 249us/step - loss: 0.5375 - acc: 0.8864 - val_loss: 0.9375 - val_acc: 0.8080\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.4369 - acc: 0.9085 - val_loss: 0.9857 - val_acc: 0.7850\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 249us/step - loss: 0.3616 - acc: 0.9252 - val_loss: 0.9084 - val_acc: 0.8120\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 251us/step - loss: 0.2994 - acc: 0.9370 - val_loss: 0.8827 - val_acc: 0.8100\n",
      "2246/2246 [==============================] - 1s 318us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9841250855266677, 0.7867319679430098]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 4s 491us/step - loss: 2.2444 - acc: 0.5604 - val_loss: 1.4596 - val_acc: 0.6720\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 3s 352us/step - loss: 1.1564 - acc: 0.7473 - val_loss: 1.1595 - val_acc: 0.7380\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 3s 402us/step - loss: 0.8395 - acc: 0.8141 - val_loss: 1.0144 - val_acc: 0.7770\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 3s 429us/step - loss: 0.6210 - acc: 0.8673 - val_loss: 0.9314 - val_acc: 0.8060\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 3s 421us/step - loss: 0.4475 - acc: 0.9070 - val_loss: 0.8986 - val_acc: 0.8020\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 3s 360us/step - loss: 0.3452 - acc: 0.9236 - val_loss: 0.8798 - val_acc: 0.8180\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 3s 368us/step - loss: 0.2760 - acc: 0.9390 - val_loss: 1.0626 - val_acc: 0.7760\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 3s 398us/step - loss: 0.2306 - acc: 0.9431 - val_loss: 0.9100 - val_acc: 0.8180\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 3s 368us/step - loss: 0.1952 - acc: 0.9505 - val_loss: 0.8880 - val_acc: 0.8190\n",
      "2246/2246 [==============================] - 1s 454us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0182387423324246, 0.7938557435706165]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax')) \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "32 нейрона: [1.0746706011883405, 0.7573463936416782]\n",
    "\n",
    "64 нейрона: [0.9841250855266677, 0.7867319679430098]\n",
    "\n",
    "128 нейронов:[1.0182387423324246, 0.7938557435706165]\n",
    "\n",
    "Если мы меняем размерность слоев, на 128 нейронах точность модели оказывается лучше. Однако, в предыдущем запуске модель с 64 нейронами показала бОльшую точность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You used two hidden layers. Now try using a single hidden layer, or three hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 338us/step - loss: 2.4983 - acc: 0.5727 - val_loss: 1.7686 - val_acc: 0.6660\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 262us/step - loss: 1.4390 - acc: 0.7253 - val_loss: 1.3275 - val_acc: 0.7250\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 245us/step - loss: 1.0475 - acc: 0.7884 - val_loss: 1.1264 - val_acc: 0.7700\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.8164 - acc: 0.8363 - val_loss: 1.0147 - val_acc: 0.8000\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.6541 - acc: 0.8735 - val_loss: 0.9383 - val_acc: 0.8070\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 0.5338 - acc: 0.8971 - val_loss: 0.8914 - val_acc: 0.8150\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 249us/step - loss: 0.4402 - acc: 0.9134 - val_loss: 0.8639 - val_acc: 0.8170\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 251us/step - loss: 0.3673 - acc: 0.9255 - val_loss: 0.8437 - val_acc: 0.8170\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 251us/step - loss: 0.3087 - acc: 0.9350 - val_loss: 0.8437 - val_acc: 0.8160\n",
      "2246/2246 [==============================] - 1s 332us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9057835927523361, 0.7996438112199465]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) #one hidden layer\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 396us/step - loss: 2.5588 - acc: 0.5589 - val_loss: 1.6607 - val_acc: 0.6580\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 1.3588 - acc: 0.7196 - val_loss: 1.2472 - val_acc: 0.7130\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 247us/step - loss: 1.0078 - acc: 0.7855 - val_loss: 1.0997 - val_acc: 0.7720\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 0.7979 - acc: 0.8287 - val_loss: 1.0073 - val_acc: 0.7820\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 250us/step - loss: 0.6428 - acc: 0.8607 - val_loss: 0.9699 - val_acc: 0.7870\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 310us/step - loss: 0.5138 - acc: 0.8896 - val_loss: 0.9088 - val_acc: 0.8090\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 263us/step - loss: 0.4193 - acc: 0.9117 - val_loss: 0.8806 - val_acc: 0.8220\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 245us/step - loss: 0.3392 - acc: 0.9296 - val_loss: 0.8798 - val_acc: 0.8150\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 299us/step - loss: 0.2801 - acc: 0.9372 - val_loss: 0.8769 - val_acc: 0.8170\n",
      "2246/2246 [==============================] - 1s 510us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9845317970506867, 0.7885129118698151]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 392us/step - loss: 2.5556 - acc: 0.5046 - val_loss: 1.6809 - val_acc: 0.6500\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 244us/step - loss: 1.4205 - acc: 0.6987 - val_loss: 1.3512 - val_acc: 0.6910\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 282us/step - loss: 1.1002 - acc: 0.7508 - val_loss: 1.1951 - val_acc: 0.7250\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 296us/step - loss: 0.8765 - acc: 0.8042 - val_loss: 1.0903 - val_acc: 0.7570\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 284us/step - loss: 0.6928 - acc: 0.8470 - val_loss: 1.0250 - val_acc: 0.7950\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 270us/step - loss: 0.5530 - acc: 0.8800 - val_loss: 1.0816 - val_acc: 0.7750\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 273us/step - loss: 0.4461 - acc: 0.9027 - val_loss: 0.9923 - val_acc: 0.7970\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 306us/step - loss: 0.3816 - acc: 0.9181 - val_loss: 1.0090 - val_acc: 0.7920\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 269us/step - loss: 0.2995 - acc: 0.9302 - val_loss: 1.0722 - val_acc: 0.7890\n",
      "2246/2246 [==============================] - 1s 599us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1366345856939164, 0.7675868210682143]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) #three hidden layers\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "\n",
    "1 слой: [0.9057835927523361, 0.7996438112199465]\n",
    "\n",
    "2 слоя: [0.9845317970506867, 0.7885129118698151]\n",
    "\n",
    "3 слоя: [1.1366345856939164, 0.7675868210682143]\n",
    "\n",
    "Если мы меняем количество слоев, лучшей оказывается однослойная модель (точность почти 0,8 и test loss наименьшая). Наши данные несложные, на 3 слоях модель переобучается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
