{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "    num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 654s 26ms/step - loss: 0.4483 - acc: 0.8173\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 106s 4ms/step - loss: 0.2546 - acc: 0.9096\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s 167us/step - loss: 0.1968 - acc: 0.9296\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s 147us/step - loss: 0.1668 - acc: 0.9411\n",
      "25000/25000 [==============================] - 871s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2950650653219223, 0.88352]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test) \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Tasks\n",
    "\n",
    "The following experiments will help convince you that the architecture choices you’ve made are all fairly reasonable, although there’s still room for improvement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) You used two hidden layers. Try using one or three hidden layers, and see how doing so affects validation and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      " 1024/25000 [>.............................] - ETA: 12:30 - loss: 0.6891 - acc: 0.5625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3 5.2.0\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.117707). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 840s 34ms/step - loss: 0.4751 - acc: 0.8092\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 15s 587us/step - loss: 0.2629 - acc: 0.9075\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s 136us/step - loss: 0.1986 - acc: 0.9292\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 135us/step - loss: 0.1659 - acc: 0.9412\n",
      "25000/25000 [==============================] - 1206s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3012056277227402, 0.88232]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test) \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 1427s 57ms/step - loss: 0.4433 - acc: 0.8277\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 31s 1ms/step - loss: 0.2714 - acc: 0.9089\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s 142us/step - loss: 0.2146 - acc: 0.9265\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 135us/step - loss: 0.1841 - acc: 0.9365\n",
      "25000/25000 [==============================] - 783s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28360106026649473, 0.88732]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test) \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "    one hidden layer - [0.28360106026649473, 0.88732]\n",
    "    two hidden layers - [0.2950650653219223, 0.88352] \n",
    "    three hidden layers - [0.3012056277227402, 0.88232]\n",
    "    \n",
    "    При уменьшении количества скрытых слоёв незначительно уменьшается test loss и повышается test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Try using layers with more hidden units or fewer hidden units: 32 units, 64 units, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 524s 21ms/step - loss: 0.5406 - acc: 0.8078\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s 212us/step - loss: 0.3445 - acc: 0.8937\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s 126us/step - loss: 0.2521 - acc: 0.9147\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 126us/step - loss: 0.2061 - acc: 0.9296\n",
      "25000/25000 [==============================] - 500s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2787383371067047, 0.89052]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test) \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 322s 13ms/step - loss: 0.4253 - acc: 0.8052\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 7s 284us/step - loss: 0.2250 - acc: 0.9113\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 6s 255us/step - loss: 0.1616 - acc: 0.9365\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 6s 253us/step - loss: 0.1124 - acc: 0.9574\n",
      "25000/25000 [==============================] - 404s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35319236679553984, 0.87748]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test) \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "    8 hidden units - [0.2787383371067047, 0.89052]\n",
    "    16 hidden units - [0.2950650653219223, 0.88352]\n",
    "    128 hidden units - [0.35319236679553984, 0.87748]\n",
    "    \n",
    "    При уменьшении количества скрытых единиц уменьшается test loss и незначительно увеличивается test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Try using the mse loss function instead of binary_crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 423s 17ms/step - loss: 0.1504 - acc: 0.8286\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s 193us/step - loss: 0.0797 - acc: 0.9075\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s 131us/step - loss: 0.0596 - acc: 0.9308\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 133us/step - loss: 0.0481 - acc: 0.9445 1s - lo\n",
      "25000/25000 [==============================] - 469s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0853683164858818, 0.8852]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test) \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comclusion:\n",
    "    binary_crossentropy - [0.2950650653219223, 0.88352]\n",
    "    mse - [0.0853683164858818, 0.8852]\n",
    "    При использовании mse значительно уменьшается test loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Try using the tanh activation (an activation that was popular in the early days of neural networks) instead of relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 1030s 41ms/step - loss: 0.4301 - acc: 0.8260\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 4s 157us/step - loss: 0.2344 - acc: 0.9132\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s 145us/step - loss: 0.1783 - acc: 0.9336\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s 148us/step - loss: 0.1453 - acc: 0.9479\n",
      "25000/25000 [==============================] - 479s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3241392808437347, 0.8772]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test) \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "    relu activation - [0.2950650653219223, 0.88352]\n",
    "    tanh activation - [0.3241392808437347, 0.8772]\n",
    "    При использовании активации tanh test loss увеличивается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
    "    num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)\n",
    "\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 10s 1ms/step - loss: 2.5241 - acc: 0.4977 - val_loss: 1.7178 - val_acc: 0.6120\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 212us/step - loss: 1.4442 - acc: 0.6889 - val_loss: 1.3496 - val_acc: 0.7090\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 211us/step - loss: 1.0992 - acc: 0.7643 - val_loss: 1.1752 - val_acc: 0.7430\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 225us/step - loss: 0.8728 - acc: 0.8160 - val_loss: 1.0836 - val_acc: 0.7590\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 209us/step - loss: 0.7060 - acc: 0.8488 - val_loss: 0.9866 - val_acc: 0.7810\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 199us/step - loss: 0.5695 - acc: 0.8790 - val_loss: 0.9414 - val_acc: 0.8040\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 207us/step - loss: 0.4621 - acc: 0.9038 - val_loss: 0.9078 - val_acc: 0.8040\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 210us/step - loss: 0.3728 - acc: 0.9218 - val_loss: 0.9338 - val_acc: 0.7870\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 202us/step - loss: 0.3050 - acc: 0.9312 - val_loss: 0.8917 - val_acc: 0.8050\n",
      "2246/2246 [==============================] - 0s 204us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9823264784825666, 0.7853962600708857]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further experiments (Hometask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Try using larger or smaller layers: 32 units, 128 units, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 2s 235us/step - loss: 3.0975 - acc: 0.4546 - val_loss: 2.3165 - val_acc: 0.6090\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 178us/step - loss: 1.8966 - acc: 0.6625 - val_loss: 1.6682 - val_acc: 0.6590\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 163us/step - loss: 1.4035 - acc: 0.7175 - val_loss: 1.4031 - val_acc: 0.6950\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 165us/step - loss: 1.1576 - acc: 0.7502 - val_loss: 1.2633 - val_acc: 0.7280\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 168us/step - loss: 0.9929 - acc: 0.7890 - val_loss: 1.1801 - val_acc: 0.7520\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 167us/step - loss: 0.8635 - acc: 0.8166 - val_loss: 1.1190 - val_acc: 0.7720\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 165us/step - loss: 0.7562 - acc: 0.8356 - val_loss: 1.0802 - val_acc: 0.7700\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 165us/step - loss: 0.6663 - acc: 0.8539 - val_loss: 1.0447 - val_acc: 0.7820\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 166us/step - loss: 0.5829 - acc: 0.8733 - val_loss: 1.0104 - val_acc: 0.7980\n",
      "2246/2246 [==============================] - 0s 163us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0722838923640263, 0.7644701692427468]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 346us/step - loss: 2.2531 - acc: 0.5534 - val_loss: 1.4524 - val_acc: 0.6630\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 284us/step - loss: 1.1717 - acc: 0.7428 - val_loss: 1.1415 - val_acc: 0.7490\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 279us/step - loss: 0.8202 - acc: 0.8260 - val_loss: 1.0116 - val_acc: 0.7760\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 277us/step - loss: 0.5955 - acc: 0.8776 - val_loss: 0.9961 - val_acc: 0.7720\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 276us/step - loss: 0.4333 - acc: 0.9114 - val_loss: 0.9036 - val_acc: 0.7960\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 277us/step - loss: 0.3378 - acc: 0.9263 - val_loss: 0.8720 - val_acc: 0.8190\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 277us/step - loss: 0.2604 - acc: 0.9411 - val_loss: 0.8659 - val_acc: 0.8270\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 278us/step - loss: 0.2148 - acc: 0.9471 - val_loss: 0.9802 - val_acc: 0.8020\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 279us/step - loss: 0.1816 - acc: 0.9524 - val_loss: 1.0121 - val_acc: 0.7910\n",
      "2246/2246 [==============================] - 1s 271us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1203325656727818, 0.7684772929652716]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "    32 hidden units - [1.0722838923640263, 0.7644701692427468]\n",
    "    64 hidden units - [0.9823264784825666, 0.7853962600708857]\n",
    "    128 hidden units - [1.1203325656727818, 0.7684772929652716]\n",
    "    \n",
    "    Слои с 64 скрытыми единицами - самый низкий показатель test loss и самая высокая test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) You used two hidden layers. Now try using a single hidden layer, or three hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 2s 269us/step - loss: 2.4502 - acc: 0.5531 - val_loss: 1.7298 - val_acc: 0.6450\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 204us/step - loss: 1.4111 - acc: 0.7179 - val_loss: 1.3156 - val_acc: 0.7180\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 209us/step - loss: 1.0441 - acc: 0.7874 - val_loss: 1.1265 - val_acc: 0.7540\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 218us/step - loss: 0.8211 - acc: 0.8316 - val_loss: 1.0136 - val_acc: 0.7890\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 206us/step - loss: 0.6597 - acc: 0.8703 - val_loss: 0.9498 - val_acc: 0.7920\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 205us/step - loss: 0.5390 - acc: 0.8919 - val_loss: 0.8916 - val_acc: 0.8140\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 204us/step - loss: 0.4415 - acc: 0.9126 - val_loss: 0.8568 - val_acc: 0.8190\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 209us/step - loss: 0.3682 - acc: 0.9255 - val_loss: 0.8416 - val_acc: 0.8190\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 204us/step - loss: 0.3092 - acc: 0.9364 - val_loss: 0.8294 - val_acc: 0.8240\n",
      "2246/2246 [==============================] - 0s 191us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.88876136370461, 0.7978628673196795]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 2s 266us/step - loss: 2.5622 - acc: 0.5053 - val_loss: 1.6806 - val_acc: 0.6450\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 205us/step - loss: 1.4219 - acc: 0.6972 - val_loss: 1.3588 - val_acc: 0.6900\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 205us/step - loss: 1.1071 - acc: 0.7496 - val_loss: 1.2192 - val_acc: 0.7220\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 206us/step - loss: 0.8902 - acc: 0.8014 - val_loss: 1.1329 - val_acc: 0.7350\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 205us/step - loss: 0.7058 - acc: 0.8415 - val_loss: 1.0288 - val_acc: 0.7880\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 206us/step - loss: 0.5670 - acc: 0.8756 - val_loss: 0.9874 - val_acc: 0.8020\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 210us/step - loss: 0.4422 - acc: 0.9059 - val_loss: 1.0496 - val_acc: 0.7870\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 209us/step - loss: 0.3746 - acc: 0.9189 - val_loss: 1.0135 - val_acc: 0.7930\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 211us/step - loss: 0.2940 - acc: 0.9315 - val_loss: 1.0718 - val_acc: 0.7850\n",
      "2246/2246 [==============================] - 0s 186us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1389648417543325, 0.7653606411928804]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "    one hidden layer - [0.88876136370461, 0.7978628673196795]\n",
    "    two hidden layers - [0.9823264784825666, 0.7853962600708857]\n",
    "    three hidden layers - [0.9823264784825666, 0.7853962600708857]\n",
    "    \n",
    "    Чем меньше слоёв, тем ниже test loss и выше test accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
