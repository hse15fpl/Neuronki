{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "    num_words=10000)\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 HIDDEN LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#16 units\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 HIDDEN LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16 units\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 HIDDEN LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#16 units\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 15s 1ms/step - loss: 0.5487 - acc: 0.7730 - val_loss: 0.4519 - val_acc: 0.8076\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 4s 269us/step - loss: 0.3288 - acc: 0.8983 - val_loss: 0.3191 - val_acc: 0.8790\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 5s 342us/step - loss: 0.2325 - acc: 0.9237 - val_loss: 0.2753 - val_acc: 0.8928\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 5s 314us/step - loss: 0.1747 - acc: 0.9449 - val_loss: 0.2788 - val_acc: 0.8901\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 4s 286us/step - loss: 0.1413 - acc: 0.9548 - val_loss: 0.2820 - val_acc: 0.8887\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 5s 343us/step - loss: 0.1108 - acc: 0.9668 - val_loss: 0.3060 - val_acc: 0.8853\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 4s 286us/step - loss: 0.0905 - acc: 0.9731 - val_loss: 0.3268 - val_acc: 0.8807\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 5s 323us/step - loss: 0.0737 - acc: 0.9795 - val_loss: 0.3644 - val_acc: 0.8780\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 5s 350us/step - loss: 0.0541 - acc: 0.9863 - val_loss: 0.3843 - val_acc: 0.8792\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 5s 335us/step - loss: 0.0463 - acc: 0.9871 - val_loss: 0.4165 - val_acc: 0.8766\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 6s 424us/step - loss: 0.0334 - acc: 0.9923 - val_loss: 0.4512 - val_acc: 0.8728\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 5s 323us/step - loss: 0.0292 - acc: 0.9918 - val_loss: 0.4894 - val_acc: 0.8733\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 5s 359us/step - loss: 0.0201 - acc: 0.9960 - val_loss: 0.5225 - val_acc: 0.8734\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 4s 285us/step - loss: 0.0206 - acc: 0.9945 - val_loss: 0.5542 - val_acc: 0.8734\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 5s 301us/step - loss: 0.0071 - acc: 0.9995 - val_loss: 0.5892 - val_acc: 0.8727\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 4s 283us/step - loss: 0.0121 - acc: 0.9967 - val_loss: 0.6181 - val_acc: 0.8720\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 4s 283us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 0.6591 - val_acc: 0.8721\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 4s 267us/step - loss: 0.0141 - acc: 0.9955 - val_loss: 0.6952 - val_acc: 0.8683\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 4s 290us/step - loss: 0.0020 - acc: 0.9999 - val_loss: 0.7215 - val_acc: 0.8668\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 4s 286us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.8572 - val_acc: 0.8551\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUFERIr8P7T4ZPbvf1sjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b0880c8048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(history_dict['acc']) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNjip/iQtACIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b088194eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 HIDDEN LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 168s 7ms/step - loss: 0.4229 - acc: 0.8207\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 7s 280us/step - loss: 0.2401 - acc: 0.9100\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 6s 256us/step - loss: 0.1903 - acc: 0.9302\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 7s 268us/step - loss: 0.1588 - acc: 0.9413\n",
      "25000/25000 [==============================] - 117s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "#32 units\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 HIDDEN LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 393s 16ms/step - loss: 0.4169 - acc: 0.8114\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 14s 560us/step - loss: 0.2335 - acc: 0.9096\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 9s 356us/step - loss: 0.1903 - acc: 0.9283\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 8s 334us/step - loss: 0.1457 - acc: 0.9455\n",
      "25000/25000 [==============================] - 101s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#64 units\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 HIDDEN LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 25s 994us/step - loss: 0.4238 - acc: 0.8006\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 12s 462us/step - loss: 0.2319 - acc: 0.9097\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 11s 424us/step - loss: 0.1635 - acc: 0.9371\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 11s 421us/step - loss: 0.1168 - acc: 0.9541\n",
      "25000/25000 [==============================] - 22s 875us/step\n"
     ]
    }
   ],
   "source": [
    "#128 units\n",
    "model_2_128 = models.Sequential()\n",
    "model_2_128.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "model_2_128.add(layers.Dense(128, activation='relu'))\n",
    "model_2_128.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2_128.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2_128.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model_2_128.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE LOSS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 389s 16ms/step - loss: 0.1353 - binary_accuracy: 0.8081\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 16s 637us/step - loss: 0.0682 - binary_accuracy: 0.9113\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 7s 296us/step - loss: 0.0536 - binary_accuracy: 0.9326\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 8s 317us/step - loss: 0.0402 - binary_accuracy: 0.9500\n",
      "25000/25000 [==============================] - 98s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.mse,\n",
    "              metrics=[metrics.binary_accuracy])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TANH ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 177s 7ms/step - loss: 0.4036 - binary_accuracy: 0.8247\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 13s 510us/step - loss: 0.2229 - binary_accuracy: 0.91205s - loss: 0.2181 - b\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 8s 314us/step - loss: 0.1851 - binary_accuracy: 0.9288\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 8s 302us/step - loss: 0.1511 - binary_accuracy: 0.9438\n",
      "25000/25000 [==============================] - 74s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "'''model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])'''\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RESULTS\n",
    "1. Наиболее точные результаты показывает сетка с двумя hidden  layers. Думаю, что это связано с тем, что 1 скрытые слой дает риск недообучения, а при добавлении 3 скрытого слоя значения функции потерь увеличиваются -  сеть хуже предсказывает значения, риск переобучения, возможно. \n",
    "Говоря о количестве юнитов (нейронах), схожие результаты показали сетки с использованием 16 units и 32 units. При использовании 64 units модель начинает переобучаться.  \n",
    "2. Функция MSE показала себя лучше чем binary_crossentropy - значения функции потерь меньше. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hometask 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
    "    num_words=10000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 HIDDEN LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 5s 668us/step - loss: 1.8689 - acc: 0.6362 - val_loss: 1.2009 - val_acc: 0.7270\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 4s 445us/step - loss: 0.9378 - acc: 0.8047 - val_loss: 0.9695 - val_acc: 0.8010\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 4s 541us/step - loss: 0.6365 - acc: 0.8686 - val_loss: 0.8608 - val_acc: 0.8200\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 4s 516us/step - loss: 0.4528 - acc: 0.9063 - val_loss: 0.8317 - val_acc: 0.8170\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 4s 461us/step - loss: 0.3376 - acc: 0.9292 - val_loss: 0.8210 - val_acc: 0.8230\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 4s 519us/step - loss: 0.2618 - acc: 0.9407 - val_loss: 0.8034 - val_acc: 0.8430\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 5s 656us/step - loss: 0.2162 - acc: 0.9479 - val_loss: 0.8302 - val_acc: 0.8360\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 5s 637us/step - loss: 0.1830 - acc: 0.9509 - val_loss: 0.8502 - val_acc: 0.8280\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 4s 484us/step - loss: 0.1628 - acc: 0.9524 - val_loss: 0.8850 - val_acc: 0.8260\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 4s 503us/step - loss: 0.1491 - acc: 0.9557 - val_loss: 0.9339 - val_acc: 0.8100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 4s 496us/step - loss: 0.1345 - acc: 0.9563 - val_loss: 0.9188 - val_acc: 0.8200\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 4s 510us/step - loss: 0.1301 - acc: 0.9551 - val_loss: 0.9899 - val_acc: 0.8110\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 4s 492us/step - loss: 0.1226 - acc: 0.9562 - val_loss: 0.9758 - val_acc: 0.8180\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 4s 496us/step - loss: 0.1189 - acc: 0.9564 - val_loss: 1.0181 - val_acc: 0.8080\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 4s 556us/step - loss: 0.1139 - acc: 0.9565 - val_loss: 1.0494 - val_acc: 0.8080\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 5s 613us/step - loss: 0.1105 - acc: 0.9580 - val_loss: 1.1085 - val_acc: 0.8040\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 5s 588us/step - loss: 0.1099 - acc: 0.9569 - val_loss: 1.0753 - val_acc: 0.8080\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 5s 673us/step - loss: 0.1075 - acc: 0.9583 - val_loss: 1.0940 - val_acc: 0.8100\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 4s 530us/step - loss: 0.1064 - acc: 0.9567 - val_loss: 1.1003 - val_acc: 0.8070\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 4s 490us/step - loss: 0.1049 - acc: 0.9570 - val_loss: 1.1428 - val_acc: 0.8020\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_1_layer = model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 HIDDEN LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 6s 779us/step - loss: 1.8419 - acc: 0.6253 - val_loss: 1.2206 - val_acc: 0.7380\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 4s 457us/step - loss: 0.9481 - acc: 0.7987 - val_loss: 1.0120 - val_acc: 0.7850\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 4s 474us/step - loss: 0.6281 - acc: 0.8677 - val_loss: 0.9127 - val_acc: 0.8100\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 5s 616us/step - loss: 0.4300 - acc: 0.9087 - val_loss: 0.8805 - val_acc: 0.8160\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 6s 703us/step - loss: 0.3145 - acc: 0.9326 - val_loss: 0.8842 - val_acc: 0.8130\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 5s 600us/step - loss: 0.2453 - acc: 0.9444 - val_loss: 0.8843 - val_acc: 0.8340\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 4s 482us/step - loss: 0.2042 - acc: 0.9468 - val_loss: 0.9352 - val_acc: 0.8210\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 4s 473us/step - loss: 0.1781 - acc: 0.9529 - val_loss: 1.0760 - val_acc: 0.7810\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 4s 471us/step - loss: 0.1639 - acc: 0.9539 - val_loss: 0.9860 - val_acc: 0.8080\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 4s 488us/step - loss: 0.1490 - acc: 0.9538 - val_loss: 0.9966 - val_acc: 0.8100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 4s 532us/step - loss: 0.1431 - acc: 0.9548 - val_loss: 1.0690 - val_acc: 0.7950\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 4s 540us/step - loss: 0.1339 - acc: 0.9568 - val_loss: 1.0499 - val_acc: 0.7920\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 5s 605us/step - loss: 0.1297 - acc: 0.9568 - val_loss: 1.1314 - val_acc: 0.7990\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 5s 604us/step - loss: 0.1254 - acc: 0.9554 - val_loss: 1.1252 - val_acc: 0.7890\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 5s 595us/step - loss: 0.1217 - acc: 0.9545 - val_loss: 1.1085 - val_acc: 0.7970\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 4s 554us/step - loss: 0.1151 - acc: 0.9575 - val_loss: 1.1799 - val_acc: 0.7860\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 4s 496us/step - loss: 0.1164 - acc: 0.9553 - val_loss: 1.1503 - val_acc: 0.7960\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 4s 523us/step - loss: 0.1122 - acc: 0.9575 - val_loss: 1.2057 - val_acc: 0.7820\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 4s 468us/step - loss: 0.1103 - acc: 0.9551 - val_loss: 1.2054 - val_acc: 0.7920\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 4s 479us/step - loss: 0.1027 - acc: 0.9595 - val_loss: 1.2363 - val_acc: 0.7920\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_2_layers = model2.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 HIDDEN LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 6s 722us/step - loss: 1.8337 - acc: 0.6115 - val_loss: 1.2708 - val_acc: 0.7050\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 4s 449us/step - loss: 0.9798 - acc: 0.7737 - val_loss: 1.1415 - val_acc: 0.7360\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 4s 472us/step - loss: 0.6577 - acc: 0.8558 - val_loss: 0.9477 - val_acc: 0.8000\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 4s 467us/step - loss: 0.4615 - acc: 0.9018 - val_loss: 0.9340 - val_acc: 0.8100\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 4s 467us/step - loss: 0.3375 - acc: 0.9260 - val_loss: 1.0363 - val_acc: 0.7840\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 4s 474us/step - loss: 0.2611 - acc: 0.9407 - val_loss: 0.9952 - val_acc: 0.8010\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 4s 475us/step - loss: 0.2190 - acc: 0.9478 - val_loss: 1.0827 - val_acc: 0.8040\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 4s 537us/step - loss: 0.1956 - acc: 0.9513 - val_loss: 1.1717 - val_acc: 0.7710\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 5s 646us/step - loss: 0.1718 - acc: 0.9533 - val_loss: 1.0723 - val_acc: 0.7990\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 5s 618us/step - loss: 0.1609 - acc: 0.9523 - val_loss: 1.1249 - val_acc: 0.7850\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 4s 492us/step - loss: 0.1479 - acc: 0.9560 - val_loss: 1.2005 - val_acc: 0.7830\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 4s 468us/step - loss: 0.1417 - acc: 0.9550 - val_loss: 1.1198 - val_acc: 0.7960\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 4s 469us/step - loss: 0.1319 - acc: 0.9557 - val_loss: 1.2217 - val_acc: 0.7790\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 4s 491us/step - loss: 0.1288 - acc: 0.9540 - val_loss: 1.2400 - val_acc: 0.7760\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 4s 479us/step - loss: 0.1219 - acc: 0.9544 - val_loss: 1.2410 - val_acc: 0.7930\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 4s 477us/step - loss: 0.1183 - acc: 0.9565 - val_loss: 1.2564 - val_acc: 0.7890\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 4s 497us/step - loss: 0.1120 - acc: 0.9574 - val_loss: 1.2254 - val_acc: 0.8010\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 4s 506us/step - loss: 0.1086 - acc: 0.9567 - val_loss: 1.3132 - val_acc: 0.7920\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 4s 503us/step - loss: 0.1032 - acc: 0.9574 - val_loss: 1.3336 - val_acc: 0.7880\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 4s 507us/step - loss: 0.1054 - acc: 0.9577 - val_loss: 1.3306 - val_acc: 0.7800\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model3.add(layers.Dense(64, activation='relu'))\n",
    "model3.add(layers.Dense(64, activation='relu'))\n",
    "model3.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_3_layers = model3.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 1s 342us/step\n",
      "2246/2246 [==============================] - 1s 365us/step\n",
      "2246/2246 [==============================] - 1s 348us/step\n",
      "[1.3345707462816927, 0.7853962600708857]\n",
      "[1.4700521401603204, 0.77025823686553874]\n",
      "[1.5067622767743105, 0.7822796082454182]\n"
     ]
    }
   ],
   "source": [
    "results1 = model.evaluate(x_test, y_test)\n",
    "results2 = model2.evaluate(x_test, y_test)\n",
    "results3 = model3.evaluate(x_test, y_test)\n",
    "print(results1)\n",
    "print(results2)\n",
    "print(results3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 HIDDEN LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 5s 622us/step - loss: 2.2997 - acc: 0.5551 - val_loss: 1.4805 - val_acc: 0.6700\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 3s 351us/step - loss: 1.2432 - acc: 0.7301 - val_loss: 1.1858 - val_acc: 0.7410\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 3s 349us/step - loss: 0.9331 - acc: 0.7978 - val_loss: 1.0447 - val_acc: 0.7740\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 3s 345us/step - loss: 0.7190 - acc: 0.8418 - val_loss: 0.9829 - val_acc: 0.7830\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 3s 337us/step - loss: 0.5591 - acc: 0.8750 - val_loss: 0.9422 - val_acc: 0.7970\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 3s 331us/step - loss: 0.4409 - acc: 0.9018 - val_loss: 0.9204 - val_acc: 0.8080\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 3s 343us/step - loss: 0.3527 - acc: 0.9247 - val_loss: 0.9155 - val_acc: 0.8170\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 3s 341us/step - loss: 0.2881 - acc: 0.9356 - val_loss: 0.9643 - val_acc: 0.8000\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 4s 524us/step - loss: 0.2465 - acc: 0.9446 - val_loss: 0.9254 - val_acc: 0.8160\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 3s 436us/step - loss: 0.2078 - acc: 0.9510 - val_loss: 0.9809 - val_acc: 0.8080\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 3s 341us/step - loss: 0.1869 - acc: 0.9511 - val_loss: 1.0273 - val_acc: 0.8090\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 3s 356us/step - loss: 0.1678 - acc: 0.9554 - val_loss: 1.0063 - val_acc: 0.8040\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 3s 333us/step - loss: 0.1535 - acc: 0.9573 - val_loss: 1.0812 - val_acc: 0.8000\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 4s 469us/step - loss: 0.1443 - acc: 0.9557 - val_loss: 1.0787 - val_acc: 0.7970\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 3s 382us/step - loss: 0.1325 - acc: 0.9594 - val_loss: 1.1273 - val_acc: 0.7970\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 3s 362us/step - loss: 0.1299 - acc: 0.9569 - val_loss: 1.1142 - val_acc: 0.8020\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - ETA: 0s - loss: 0.1265 - acc: 0.956 - 3s 349us/step - loss: 0.1261 - acc: 0.9567 - val_loss: 1.1875 - val_acc: 0.7890\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 3s 351us/step - loss: 0.1204 - acc: 0.9555 - val_loss: 1.1830 - val_acc: 0.7860\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 3s 341us/step - loss: 0.1191 - acc: 0.9575 - val_loss: 1.1784 - val_acc: 0.7990\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 3s 349us/step - loss: 0.1133 - acc: 0.9563 - val_loss: 1.1904 - val_acc: 0.7990\n"
     ]
    }
   ],
   "source": [
    "#32 units\n",
    "model32 = models.Sequential()\n",
    "model32.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model32.add(layers.Dense(32, activation='relu'))\n",
    "model32.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model32.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history32 = model32.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 HIDDEN LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 6s 733us/step - loss: 1.9264 - acc: 0.5968 - val_loss: 1.2453 - val_acc: 0.7370\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 4s 500us/step - loss: 0.9949 - acc: 0.7845 - val_loss: 1.0303 - val_acc: 0.7720\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 4s 469us/step - loss: 0.6747 - acc: 0.8538 - val_loss: 0.9255 - val_acc: 0.8120\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 4s 492us/step - loss: 0.4696 - acc: 0.9002 - val_loss: 0.8729 - val_acc: 0.8140\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 4s 471us/step - loss: 0.3401 - acc: 0.9261 - val_loss: 0.8790 - val_acc: 0.8260\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 4s 505us/step - loss: 0.2613 - acc: 0.9404 - val_loss: 0.9470 - val_acc: 0.8120\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 4s 498us/step - loss: 0.2132 - acc: 0.9488 - val_loss: 0.9358 - val_acc: 0.8130\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 4s 506us/step - loss: 0.1813 - acc: 0.9530 - val_loss: 0.9887 - val_acc: 0.8030\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 4s 484us/step - loss: 0.1677 - acc: 0.9530 - val_loss: 0.9881 - val_acc: 0.8140\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 4s 487us/step - loss: 0.1563 - acc: 0.9548 - val_loss: 0.9872 - val_acc: 0.8170\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 4s 468us/step - loss: 0.1406 - acc: 0.9570 - val_loss: 0.9993 - val_acc: 0.8160\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 4s 480us/step - loss: 0.1352 - acc: 0.9551 - val_loss: 1.0824 - val_acc: 0.8080\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 4s 478us/step - loss: 0.1300 - acc: 0.9575 - val_loss: 1.1132 - val_acc: 0.8130\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 4s 493us/step - loss: 0.1250 - acc: 0.9577 - val_loss: 1.1279 - val_acc: 0.8040\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 4s 510us/step - loss: 0.1214 - acc: 0.9570 - val_loss: 1.1435 - val_acc: 0.7980\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 4s 498us/step - loss: 0.1178 - acc: 0.9562 - val_loss: 1.1097 - val_acc: 0.8060\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 4s 510us/step - loss: 0.1117 - acc: 0.9572 - val_loss: 1.1818 - val_acc: 0.8050\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 4s 507us/step - loss: 0.1118 - acc: 0.9564 - val_loss: 1.1621 - val_acc: 0.8050\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 4s 517us/step - loss: 0.1101 - acc: 0.9551 - val_loss: 1.2409 - val_acc: 0.7950\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 4s 526us/step - loss: 0.1046 - acc: 0.9577 - val_loss: 1.1930 - val_acc: 0.8050\n"
     ]
    }
   ],
   "source": [
    "#64 units\n",
    "model64 = models.Sequential()\n",
    "model64.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model64.add(layers.Dense(64, activation='relu'))\n",
    "model64.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model64.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history64 = model64.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 HIDDEN LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 1.6136 - acc: 0.6604 - val_loss: 1.0882 - val_acc: 0.7570\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 6s 705us/step - loss: 0.7640 - acc: 0.8339 - val_loss: 0.9091 - val_acc: 0.7940\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 5s 670us/step - loss: 0.4459 - acc: 0.9048 - val_loss: 0.8621 - val_acc: 0.8330\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 5s 670us/step - loss: 0.3005 - acc: 0.9349 - val_loss: 0.9041 - val_acc: 0.8170\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 5s 682us/step - loss: 0.2265 - acc: 0.9454 - val_loss: 0.8959 - val_acc: 0.8220\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 5s 682us/step - loss: 0.1879 - acc: 0.9494 - val_loss: 0.9474 - val_acc: 0.8200\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 5s 681us/step - loss: 0.1678 - acc: 0.9524 - val_loss: 1.0801 - val_acc: 0.7950\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 5s 688us/step - loss: 0.1530 - acc: 0.9525 - val_loss: 1.0351 - val_acc: 0.8080\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 6s 801us/step - loss: 0.1432 - acc: 0.9560 - val_loss: 1.0797 - val_acc: 0.7940\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 6s 716us/step - loss: 0.1362 - acc: 0.9541 - val_loss: 1.0863 - val_acc: 0.7960\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 6s 711us/step - loss: 0.1244 - acc: 0.9545 - val_loss: 1.1237 - val_acc: 0.8010\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 6s 704us/step - loss: 0.1195 - acc: 0.9569 - val_loss: 1.1346 - val_acc: 0.8080\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 6s 702us/step - loss: 0.1137 - acc: 0.9567 - val_loss: 1.1153 - val_acc: 0.8000\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 6s 718us/step - loss: 0.1053 - acc: 0.9567 - val_loss: 1.1583 - val_acc: 0.8030\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 6s 736us/step - loss: 0.1027 - acc: 0.9569 - val_loss: 1.2838 - val_acc: 0.7850\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 6s 749us/step - loss: 0.0990 - acc: 0.9563 - val_loss: 1.2503 - val_acc: 0.7930\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 7s 870us/step - loss: 0.0956 - acc: 0.9554 - val_loss: 1.2885 - val_acc: 0.7910\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 6s 772us/step - loss: 0.0923 - acc: 0.9575 - val_loss: 1.3081 - val_acc: 0.7980\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 6s 748us/step - loss: 0.0880 - acc: 0.9587 - val_loss: 1.3539 - val_acc: 0.7990\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 6s 729us/step - loss: 0.0847 - acc: 0.9587 - val_loss: 1.3729 - val_acc: 0.7900\n"
     ]
    }
   ],
   "source": [
    "#128 units\n",
    "model128 = models.Sequential()\n",
    "model128.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "model128.add(layers.Dense(128, activation='relu'))\n",
    "model128.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model128.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history128 = model128.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 1s 326us/step\n",
      "[1.3886601865450825, 0.77159394479073906]\n",
      "2246/2246 [==============================] - 1s 346us/step\n",
      "[1.4074819223857413, 0.78272484416740873]\n",
      "2246/2246 [==============================] - 1s 377us/step\n",
      "[1.6074163905234604, 0.78049866434515103]\n"
     ]
    }
   ],
   "source": [
    "results32 = model32.evaluate(x_test, y_test)\n",
    "print(results32)\n",
    "results64 = model64.evaluate(x_test, y_test)\n",
    "print(results64)\n",
    "results128 = model128.evaluate(x_test, y_test)\n",
    "print(results128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### RESULTS\n",
    "1. Наиболее высокая точность у моделей с использованием 64 units. Хоть разница и малоразличима, если сравнивать с 128 units. \n",
    "2. Касательно количества скрытых слоев - наиболее хорошо себя показала модель с 1 hidden layer. При увеличении числа слоев модель начинает переобучаться. Функция потерь увеличивает свои значения. Скорее всего, это связано с тем, что выборка небольшая, и использования 1 слоя с 64 нейронами достаточно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
