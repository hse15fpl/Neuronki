{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programs\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, Dropout, Embedding, LSTM, Bidirectional, TimeDistributed, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем генерировать текст на двух произведениях Эдгара По - \"Убийство на улице Морг\" (тестовое) и \"Тайна Мари Роже\" (тренировочное). Распределение \"тестовая-тренировочная\" обусловлено размерами произведений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = codecs.open(\"books/marie.txt\", 'r', encoding=\"utf-8\", errors=\"ignore\")\n",
    "lines = []\n",
    "for line in text:\n",
    "    line = line.strip().lower()\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "text.close()\n",
    "train = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = codecs.open(\"books/morgue.txt\", 'r', encoding=\"utf-8\", errors=\"ignore\")\n",
    "lines = []\n",
    "for line in text:\n",
    "    line = line.strip().lower()\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "text.close()\n",
    "test = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'параллельно с реальными событиями существует идеальная их последовательность. они редко полностью совпадают. люди и обстоятельства обычно изменяют идеальную цепь событий, а потому она кажется несовершенной, и следствия ее равно несовершенны. так было с реформацией – взамен протестантства явилось лютеранство.</ новалис. «взгляд на мораль» * * * примечание: «мари роже» впервые была опубликована без примечаний, поскольку тогда они казались излишними; однако со времени трагедии, которая легла в основу этой истории, прошли годы, а потому появилась нужда и в примечаниях, и в небольшом вступлении, объясняющем суть дела. в окрестностях нью-йорка была убита молодая девушка мэри сесилия роджерс, и хотя это убийство вызвало большое волнение и очень долго оставалось в центре внимания публики, его тайна еще не была раскрыта в тот момент, когда был написан и опубликован настоящий рассказ (в ноябре 1842 г.). автор, якобы описывая судьбу французской гризетки, на самом деле точно и со всеми подробностями воспроизвел основные акты убийства мэри роджерс, ограничиваясь параллелизмами в менее существенны'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'аналитические способности человека сами по себе весьма мало подходят под анализ. мы ценим их только по их выводами. мы знаем о них только то, что они доставляют человеку громадный источник самых истинных наслаждений. сильный человек наслаждается своей физической мощью, любит упражнения, в которых играют роль его мускулы, а аналитик предпочитает мозговую деятельность, дающую ему возможность исследования. ему доставляют удовольствие даже самые обыкновенные случаи, представляющие возможность применить свои способности, даже загадки, ребусы, иероглифы. способность разгадывания или расследования зависит много от математических знаний, но высшую математику называют несправедливо анализом, потому что не всякий расчет можно назвать этим именем. игрок в шашки, например, очень удачно рассчитывает, не прибегая к анализу. оставляя в стороне абстракции, обратимся к примеру и возьмем игру в шашки, когда действуют только четыре дамки, и, следовательно, нельзя предполагать недостатка внимания. очевидн'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_train = [w for w in word_tokenize(train)] # разделим текст пословно\n",
    "words_test = [w for w in word_tokenize(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train = list(set(words_train)) # посчитаем уникальные слова\n",
    "unique_test = list(set(words_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19218, 4987)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_train), len(unique_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8920, 2781)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_test), len(unique_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_unique = deepcopy(set(unique_test)) # найдем слова, уникальные для тестового корпуса и удалим их\n",
    "words_unique.difference_update(set(unique_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1872"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_test = [w for w in words_test if w not in list(words_unique)] # создадим новый список тестовых слов без уникальных\n",
    "unique_test = list(set(words_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {w:n for n,w in enumerate(unique_train)} # создадим lookup-словари: из слова в индекс и из индекса в слово на основе слов тренировочной выборки\n",
    "index2word = {n:w for n,w in enumerate(unique_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = len(word2index) # длина lookup словаря и будет количеством возможных вариантов предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN = 10 # переведем данные в векторное представление. Так как количество слов в тестовой и тренировочной неодинаково, добавим в тестовую паддинги\n",
    "STEP = 1 # т.е длина одного варианта-вектора будет одинаковая и в тестовых ответах, и в тренировочных\n",
    "\n",
    "def to_vectors(words, pad = False):\n",
    "    global SEQLEN, STEP\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(0, len(words) - SEQLEN, STEP):\n",
    "        seqs = words[i:i + SEQLEN]\n",
    "        #print(seqs)\n",
    "        ans = words[i + SEQLEN]\n",
    "        X.append([word2index.get(word) for word in seqs])\n",
    "        Y.append(word2index.get(ans))\n",
    "    if pad == True:\n",
    "        return np.array(X),to_categorical(Y, num_classes=WORDS)\n",
    "    else:\n",
    "        return np.array(X),to_categorical(Y, num_classes=WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = to_vectors(words_train)\n",
    "X_test, Y_test = to_vectors(words_test, pad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(X_test, model):\n",
    "    global Y_test, SEQLEN\n",
    "    probs = []\n",
    "\n",
    "    for ind in tqdm(range(len(X_test))):\n",
    "        inp = X_test[ind]\n",
    "        lab = Y_test[ind]\n",
    "        lab = list(lab).index(1)\n",
    "        test_seq = np.reshape(inp, (1, SEQLEN))\n",
    "        # generating characters\n",
    "        #x = np.reshape(string_mapped,(1,len(string_mapped)))\n",
    "        pred = model.predict(test_seq, verbose=0)[0]\n",
    "        prob = pred[lab]\n",
    "        probs.append(prob)\n",
    "    \n",
    "    log_sum = 0\n",
    "    for prob in probs:\n",
    "        log_sum += math.log2(prob)\n",
    "    mean = -(log_sum/len(probs))\n",
    "    return math.pow(2, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplex = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(X_test, model): # посмотрим, как модель сможет генерировать текст для 5 рандомных примеров из тестовой выборки\n",
    "    global WORDS, SEQLEN, word2index, indes2word\n",
    "    for i in range(5): \n",
    "        test_chars = X_test[np.random.randint(len(X_test))]\n",
    "        test_str = [index2word[i] for i in test_chars] # перекодируем пример обратно в слова\n",
    "        print(\"Generating from seed: %s\" % (\" \".join(test_str)))\n",
    "        print(*test_str, end=\" \")\n",
    "        for i in range(30): # сгенерируем последовательность из 30 слов за выбранным ядром\n",
    "            Xtest = np.reshape(test_chars, (1, SEQLEN))\n",
    "            pred = model.predict_classes(Xtest, verbose=0)\n",
    "            ypred = [index2word[i] for i in pred] # переводим предсказание из числа в слово\n",
    "            print(*ypred, end=\" \")\n",
    "            test_chars = np.append(test_chars[1:], pred) # создадим новый входной элемент, включающий в себя уже предсказанное\n",
    "            #print(*[index2word[i] for i in test_chars])\n",
    "        print(\"\\n__________\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с очень простой модели: один слой LSTM с 64 нейронами и размер эмбеддинга 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(WORDS, 100, input_length=SEQLEN))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(WORDS, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 100)           498700    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4987)              324155    \n",
      "=================================================================\n",
      "Total params: 865,095\n",
      "Trainable params: 865,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15366 samples, validate on 3842 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 7.4976 - acc: 0.0957 - val_loss: 7.1800 - val_acc: 0.0953\n",
      "Epoch 2/10\n",
      " - 12s - loss: 6.8002 - acc: 0.0990 - val_loss: 7.3301 - val_acc: 0.0953\n",
      "Epoch 3/10\n",
      " - 11s - loss: 6.7249 - acc: 0.0990 - val_loss: 7.3634 - val_acc: 0.0953\n",
      "Epoch 4/10\n",
      " - 11s - loss: 6.5938 - acc: 0.0990 - val_loss: 7.2870 - val_acc: 0.0953\n",
      "Epoch 5/10\n",
      " - 11s - loss: 6.4447 - acc: 0.0990 - val_loss: 7.3261 - val_acc: 0.0950\n",
      "Epoch 6/10\n",
      " - 12s - loss: 6.3414 - acc: 0.1084 - val_loss: 7.4070 - val_acc: 0.1093\n",
      "Epoch 7/10\n",
      " - 12s - loss: 6.2654 - acc: 0.1118 - val_loss: 7.4531 - val_acc: 0.1111\n",
      "Epoch 8/10\n",
      " - 12s - loss: 6.1940 - acc: 0.1125 - val_loss: 7.4645 - val_acc: 0.1117\n",
      "Epoch 9/10\n",
      " - 12s - loss: 6.1243 - acc: 0.1134 - val_loss: 7.5055 - val_acc: 0.1114\n",
      "Epoch 10/10\n",
      " - 12s - loss: 6.0514 - acc: 0.1138 - val_loss: 7.4838 - val_acc: 0.1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa5be93acc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность на обоих выборках мала (хотя валидацию в данной задаче можно отбросить, так как мы не пытаемся выбрать конкретное слово из множества возможных, а пытаемся научить модель строить фразы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fea401924864103b3e5347e9486a880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6244), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplex[0] = perplexity(X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из генерации, данная модель совсем не подходит - она застревает в циклах на одних и тех же словах, так как слишком проста. Попробуем ее усложнить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from seed: , не ни к какому , на дома . там\n",
      ", не ни к какому , на дома . там , что в не не не не не не не не не не не не не не не не не не не не не не не не не не не \n",
      "__________\n",
      "\n",
      "Generating from seed: беспорядок в , тело , в вниз , тела ,\n",
      "беспорядок в , тело , в вниз , тела , что в не не не не не не не не не не не не не не не не не не не не не не не не не не не не \n",
      "__________\n",
      "\n",
      "Generating from seed: их . мы знаем о них только то , что\n",
      "их . мы знаем о них только то , что в не не не не не не не не не не не не не не не не не не не не не не не не не не не не не \n",
      "__________\n",
      "\n",
      "Generating from seed: , немного , – я вам все , что ;\n",
      ", немного , – я вам все , что ; в не не не не не не не не не не не не не не не не не не не не не не не не не не не не не \n",
      "__________\n",
      "\n",
      "Generating from seed: . с тем же он отправился к , ее и\n",
      ". с тем же он отправился к , ее и не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate(X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усложним предыдущую модель:\n",
    "* Удвоим LSTM и Dropout слои\n",
    "* Увеличим размер эмбеддингов и неронов в LSTM слоях\n",
    "* Увеличим число эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(WORDS, 300, input_length=SEQLEN))\n",
    "model3.add(LSTM(512, return_sequences=True))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(LSTM(512))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(WORDS, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 10, 300)           1496100   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10, 512)           1665024   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4987)              2558331   \n",
      "=================================================================\n",
      "Total params: 7,818,655\n",
      "Trainable params: 7,818,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15366 samples, validate on 3842 samples\n",
      "Epoch 1/30\n",
      " - 191s - loss: 7.2004 - acc: 0.0924 - val_loss: 7.1125 - val_acc: 0.0950\n",
      "Epoch 2/30\n",
      " - 165s - loss: 6.7455 - acc: 0.0981 - val_loss: 7.1982 - val_acc: 0.0953\n",
      "Epoch 3/30\n",
      " - 156s - loss: 6.5085 - acc: 0.0990 - val_loss: 7.2380 - val_acc: 0.0953\n",
      "Epoch 4/30\n",
      " - 158s - loss: 6.3386 - acc: 0.1046 - val_loss: 7.3132 - val_acc: 0.1005\n",
      "Epoch 5/30\n",
      " - 157s - loss: 6.1791 - acc: 0.1087 - val_loss: 7.4328 - val_acc: 0.0984\n",
      "Epoch 6/30\n",
      " - 156s - loss: 6.0027 - acc: 0.1100 - val_loss: 7.5142 - val_acc: 0.0940\n",
      "Epoch 7/30\n",
      " - 155s - loss: 5.7992 - acc: 0.1128 - val_loss: 7.5453 - val_acc: 0.0846\n",
      "Epoch 8/30\n",
      " - 155s - loss: 5.5915 - acc: 0.1250 - val_loss: 7.5660 - val_acc: 0.0726\n",
      "Epoch 9/30\n",
      " - 156s - loss: 5.3653 - acc: 0.1341 - val_loss: 7.7364 - val_acc: 0.0796\n",
      "Epoch 10/30\n",
      " - 156s - loss: 5.1263 - acc: 0.1542 - val_loss: 7.8303 - val_acc: 0.0695\n",
      "Epoch 11/30\n",
      " - 155s - loss: 4.9191 - acc: 0.1645 - val_loss: 7.9471 - val_acc: 0.0679\n",
      "Epoch 12/30\n",
      " - 155s - loss: 4.6806 - acc: 0.1818 - val_loss: 8.1438 - val_acc: 0.0645\n",
      "Epoch 13/30\n",
      " - 155s - loss: 4.4619 - acc: 0.1954 - val_loss: 8.1791 - val_acc: 0.0664\n",
      "Epoch 14/30\n",
      " - 156s - loss: 4.2357 - acc: 0.2125 - val_loss: 8.3295 - val_acc: 0.0651\n",
      "Epoch 15/30\n",
      " - 155s - loss: 4.0159 - acc: 0.2309 - val_loss: 8.4368 - val_acc: 0.0635\n",
      "Epoch 16/30\n",
      " - 155s - loss: 3.7977 - acc: 0.2566 - val_loss: 8.5260 - val_acc: 0.0593\n",
      "Epoch 17/30\n",
      " - 155s - loss: 3.5895 - acc: 0.2822 - val_loss: 8.6321 - val_acc: 0.0656\n",
      "Epoch 18/30\n",
      " - 158s - loss: 3.3693 - acc: 0.3182 - val_loss: 8.6961 - val_acc: 0.0677\n",
      "Epoch 19/30\n",
      " - 154s - loss: 3.1460 - acc: 0.3631 - val_loss: 8.8155 - val_acc: 0.0640\n",
      "Epoch 20/30\n",
      " - 154s - loss: 2.9376 - acc: 0.4054 - val_loss: 8.9366 - val_acc: 0.0656\n",
      "Epoch 21/30\n",
      " - 155s - loss: 2.7625 - acc: 0.4416 - val_loss: 8.9884 - val_acc: 0.0690\n",
      "Epoch 22/30\n",
      " - 155s - loss: 2.5319 - acc: 0.4941 - val_loss: 9.1045 - val_acc: 0.0604\n",
      "Epoch 23/30\n",
      " - 155s - loss: 2.3969 - acc: 0.5212 - val_loss: 9.1445 - val_acc: 0.0687\n",
      "Epoch 24/30\n",
      " - 155s - loss: 2.1651 - acc: 0.5800 - val_loss: 9.1952 - val_acc: 0.0724\n",
      "Epoch 25/30\n",
      " - 155s - loss: 1.9904 - acc: 0.6172 - val_loss: 9.2950 - val_acc: 0.0659\n",
      "Epoch 26/30\n",
      " - 169s - loss: 1.8391 - acc: 0.6428 - val_loss: 9.3718 - val_acc: 0.0674\n",
      "Epoch 27/30\n",
      " - 182s - loss: 1.6735 - acc: 0.6848 - val_loss: 9.4530 - val_acc: 0.0700\n",
      "Epoch 28/30\n",
      " - 190s - loss: 1.5443 - acc: 0.7116 - val_loss: 9.5398 - val_acc: 0.0690\n",
      "Epoch 29/30\n",
      " - 182s - loss: 1.4216 - acc: 0.7357 - val_loss: 9.5843 - val_acc: 0.0698\n",
      "Epoch 30/30\n",
      " - 186s - loss: 1.2915 - acc: 0.7603 - val_loss: 9.6541 - val_acc: 0.0687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa5e9ee3ac8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, Y_train, batch_size=128, epochs=30, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, результаты стали лучше - модель больше не повторяет бесконечно одни и те же слова (хотя все же иногда зацикливается), хотя смысла в последовательностях нет нкакого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from seed: и , что дверь , где было найдено тело мадемуазель\n",
      "и , что дверь , где было найдено тело мадемуазель человеческое человеческое попять попять попять разрушает разрушает разрушает следов следов произвели произвели пропадут пропадут несчастная несчастная лопаток лопаток лопаток лопаток нашлось нашлось предполагаемым труды труды труды труды труды автор автор \n",
      "__________\n",
      "\n",
      "Generating from seed: игрой пустой . действительно , более других заставляет . в\n",
      "игрой пустой . действительно , более других заставляет . в заметно заметно газетных газетных газетных порождена порождена доказательство доказательство доказательство положения исповеди исповеди восемнадцать восемнадцать восемнадцать гибели людьми дороги дороги глубокой глубокой проверять проверять части части эта-то лицемер травки парфюмера \n",
      "__________\n",
      "\n",
      "Generating from seed: . голосом говорил . несколько слов . , , .\n",
      ". голосом говорил . несколько слов . , , . справедливым справедливым кости кости выяснилось выяснилось выяснилось сент-эсташу подводит подверглась важнейшие подозреваемых становятся подозреваемых завершается живейший живейший нередко нередко нередко исполнение попросила попросила вызвано вызвано скверны опосредствованно утоптана показать показать \n",
      "__________\n",
      "\n",
      "Generating from seed: стали – сказать ! – вытащили тело дочери , которое\n",
      "стали – сказать ! – вытащили тело дочери , которое камни всевозможные всевозможные всевозможные верно оказываются оказываются оказываются точно точно ссылка ссылка ссылка обвитой ему колючек колючек внимание ни ни ни геометрической вспышка ярлычке отделяют отделяют кораблей кораблей слепая всеми \n",
      "__________\n",
      "\n",
      "Generating from seed: , может быть , , что меня мое открытие ?\n",
      ", может быть , , что меня мое открытие ? слезет подведем подведем подведем голове сгнивать спине соединяющих соединяющих пытаемся смущать сил возможным год допросам допросам справки префектуре префектуре префектуре степени квартал помешали помешали помешали дает дает дает дает двоицы \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate(X_test, model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde46676381943eab8167e0b5bd88e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6244), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplex[1] = perplexity(X_test, model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще усложним модель той же архитектуры,но сократим число эпох для экономия времени:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Embedding(WORDS, 300, input_length=10))\n",
    "model4.add(LSTM(700, return_sequences=True))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(LSTM(700))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(WORDS, activation='softmax'))\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 10, 300)           1496100   \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 10, 700)           2802800   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 10, 700)           0         \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 700)               3922800   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4987)              3495887   \n",
      "=================================================================\n",
      "Total params: 11,717,587\n",
      "Trainable params: 11,717,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 375s - loss: 7.1700 - acc: 0.0950\n",
      "Epoch 2/15\n",
      " - 370s - loss: 6.7283 - acc: 0.0983\n",
      "Epoch 3/15\n",
      " - 349s - loss: 6.5317 - acc: 0.0996\n",
      "Epoch 4/15\n",
      " - 357s - loss: 6.3467 - acc: 0.1068\n",
      "Epoch 5/15\n",
      " - 353s - loss: 6.1281 - acc: 0.1101\n",
      "Epoch 6/15\n",
      " - 367s - loss: 5.8806 - acc: 0.1154\n",
      "Epoch 7/15\n",
      " - 348s - loss: 5.6379 - acc: 0.1272\n",
      "Epoch 8/15\n",
      " - 326s - loss: 5.3906 - acc: 0.1425\n",
      "Epoch 9/15\n",
      " - 344s - loss: 5.1242 - acc: 0.1615\n",
      "Epoch 10/15\n",
      " - 332s - loss: 4.8509 - acc: 0.1776\n",
      "Epoch 11/15\n",
      " - 323s - loss: 4.5690 - acc: 0.1981\n",
      "Epoch 12/15\n",
      " - 355s - loss: 4.2899 - acc: 0.2162\n",
      "Epoch 13/15\n",
      " - 360s - loss: 3.9862 - acc: 0.2439\n",
      "Epoch 14/15\n",
      " - 347s - loss: 3.6891 - acc: 0.2744\n",
      "Epoch 15/15\n",
      " - 332s - loss: 3.3844 - acc: 0.3221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa598f77e80>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, Y_train, batch_size=128, epochs=15, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель уже лучше генерирует последовательности, меньше повторяет одни и те же слова, по большей части правильно расставляет знаки препинание, а некоторые участки последовательности даже несут смысл: \"пока не не успевают извлечь из того , что\", \"брошенные на реку вскоре после наступления смерти , всплывают , и когда процесс разложения зайдет бы далеко\", \"что она волочили бы мари\", \"и сквозь борьба , перевезти на этой сторону\". Хотя при этом грамматического согласование почти нет, даже если по смыслу слова сочетаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from seed: . я этого человека к себе с минуты на минуту\n",
      ". я этого человека к себе с минуты на минуту берег и следует , пока не не успевают извлечь из того , что она действительно вообразить , что преклонный провести часов ткани . затем есть , какие леблан на париже \n",
      "__________\n",
      "\n",
      "Generating from seed: два , и один из них был , несомненно ,\n",
      "два , и один из них был , несомненно , короткая , но я будем не зайдет бы доказано , что она не мог внимание из дома мари . я , возможно , брошенные на реку , неопровержимо бы не \n",
      "__________\n",
      "\n",
      "Generating from seed: на . он слышал . голосом говорил . несколько слов\n",
      "на . он слышал . голосом говорил . несколько слов смеркаться , брошенные на реку вскоре после наступления смерти , всплывают , и когда процесс разложения зайдет бы далеко , что она волочили бы мари . для многочисленность не дну \n",
      "__________\n",
      "\n",
      "Generating from seed: до тех пор , пока не ; потом внезапно .\n",
      "до тех пор , пока не ; потом внезапно . и сквозь борьба , перевезти на этой сторону . « этуаль » дает и были подброшены мари , бросили тело в них подозрительные не дней . мы не судьба бить \n",
      "__________\n",
      "\n",
      "Generating from seed: он сопровождал доказательствами , меня доводами моей . в такие\n",
      "он сопровождал доказательствами , меня доводами моей . в такие паве-сент-андре , когда эти незамеченным три зайдет . на результате сторону , а потому мы не можем вообразить , что я будем вещи могли бы через сомнения , всплывают , \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate(X_test, model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a9e5e9bce24a268acf2085247354eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6244), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplex[2] = perplexity(X_test, model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим архитектуру: возьмем оптимальные параметры третьей модели (так как они выдали неплохие результаты и при этом не такие тяжелые для ноутбука), но не будем дуплицировать LSTM and Dropout, а также используем вместо простой двунаправленную с активацией релу (вместо tanh по умолчанию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Embedding(WORDS, 300, input_length=SEQLEN))\n",
    "model5.add(Bidirectional(LSTM(512, activation = \"relu\", dropout=0.2, recurrent_dropout=0.2)))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(WORDS, activation='softmax'))\n",
    "\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['categorical_accuracy', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 10, 300)           1496100   \n",
      "_________________________________________________________________\n",
      "bidirectional_26 (Bidirectio (None, 1024)              3330048   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4987)              5111675   \n",
      "=================================================================\n",
      "Total params: 9,937,823\n",
      "Trainable params: 9,937,823\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15366 samples, validate on 3842 samples\n",
      "Epoch 1/50\n",
      " - 166s - loss: 7.2845 - categorical_accuracy: 0.0679 - acc: 0.0679 - val_loss: 7.0464 - val_categorical_accuracy: 0.0953 - val_acc: 0.0953\n",
      "Epoch 2/50\n",
      " - 158s - loss: 6.6832 - categorical_accuracy: 0.0990 - acc: 0.0990 - val_loss: 7.0954 - val_categorical_accuracy: 0.0953 - val_acc: 0.0953\n",
      "Epoch 3/50\n",
      " - 158s - loss: 6.4608 - categorical_accuracy: 0.0990 - acc: 0.0990 - val_loss: 7.1758 - val_categorical_accuracy: 0.0958 - val_acc: 0.0958\n",
      "Epoch 4/50\n",
      " - 159s - loss: 6.2459 - categorical_accuracy: 0.1091 - acc: 0.1091 - val_loss: 7.2427 - val_categorical_accuracy: 0.1101 - val_acc: 0.1101\n",
      "Epoch 5/50\n",
      " - 159s - loss: 5.9762 - categorical_accuracy: 0.1154 - acc: 0.1154 - val_loss: 7.3976 - val_categorical_accuracy: 0.1080 - val_acc: 0.1080\n",
      "Epoch 6/50\n",
      " - 157s - loss: 5.6403 - categorical_accuracy: 0.1240 - acc: 0.1240 - val_loss: 7.4659 - val_categorical_accuracy: 0.1104 - val_acc: 0.1104\n",
      "Epoch 7/50\n",
      " - 157s - loss: 5.2153 - categorical_accuracy: 0.1389 - acc: 0.1389 - val_loss: 7.5593 - val_categorical_accuracy: 0.0908 - val_acc: 0.0908\n",
      "Epoch 8/50\n",
      " - 158s - loss: 4.6691 - categorical_accuracy: 0.1681 - acc: 0.1681 - val_loss: 7.7557 - val_categorical_accuracy: 0.1044 - val_acc: 0.1044\n",
      "Epoch 9/50\n",
      " - 159s - loss: 3.9627 - categorical_accuracy: 0.2150 - acc: 0.2150 - val_loss: 8.1596 - val_categorical_accuracy: 0.0929 - val_acc: 0.0929\n",
      "Epoch 10/50\n",
      " - 158s - loss: 3.1557 - categorical_accuracy: 0.3213 - acc: 0.3213 - val_loss: 8.4225 - val_categorical_accuracy: 0.0919 - val_acc: 0.0919\n",
      "Epoch 11/50\n",
      " - 157s - loss: 2.4464 - categorical_accuracy: 0.4602 - acc: 0.4602 - val_loss: 8.7309 - val_categorical_accuracy: 0.0901 - val_acc: 0.0901\n",
      "Epoch 12/50\n",
      " - 156s - loss: 1.9198 - categorical_accuracy: 0.5584 - acc: 0.5584 - val_loss: 8.8968 - val_categorical_accuracy: 0.0937 - val_acc: 0.0937\n",
      "Epoch 13/50\n",
      " - 157s - loss: 1.5348 - categorical_accuracy: 0.6315 - acc: 0.6315 - val_loss: 9.1394 - val_categorical_accuracy: 0.0836 - val_acc: 0.0836\n",
      "Epoch 14/50\n",
      " - 159s - loss: 1.2450 - categorical_accuracy: 0.6928 - acc: 0.6928 - val_loss: 9.2609 - val_categorical_accuracy: 0.0937 - val_acc: 0.0937\n",
      "Epoch 15/50\n",
      " - 157s - loss: 0.9893 - categorical_accuracy: 0.7474 - acc: 0.7474 - val_loss: 9.3822 - val_categorical_accuracy: 0.0877 - val_acc: 0.0877\n",
      "Epoch 16/50\n",
      " - 156s - loss: 0.8097 - categorical_accuracy: 0.7946 - acc: 0.7946 - val_loss: 9.4961 - val_categorical_accuracy: 0.0929 - val_acc: 0.0929\n",
      "Epoch 17/50\n",
      " - 158s - loss: 0.6542 - categorical_accuracy: 0.8266 - acc: 0.8266 - val_loss: 9.6007 - val_categorical_accuracy: 0.0921 - val_acc: 0.0921\n",
      "Epoch 18/50\n",
      " - 157s - loss: 0.5527 - categorical_accuracy: 0.8547 - acc: 0.8547 - val_loss: 9.7502 - val_categorical_accuracy: 0.0929 - val_acc: 0.0929\n",
      "Epoch 19/50\n",
      " - 157s - loss: 0.4275 - categorical_accuracy: 0.8869 - acc: 0.8869 - val_loss: 9.8845 - val_categorical_accuracy: 0.0911 - val_acc: 0.0911\n",
      "Epoch 20/50\n",
      " - 157s - loss: 0.3520 - categorical_accuracy: 0.9045 - acc: 0.9045 - val_loss: 10.0263 - val_categorical_accuracy: 0.0932 - val_acc: 0.0932\n",
      "Epoch 21/50\n",
      " - 156s - loss: 0.3072 - categorical_accuracy: 0.9173 - acc: 0.9173 - val_loss: 10.1062 - val_categorical_accuracy: 0.0927 - val_acc: 0.0927\n",
      "Epoch 22/50\n",
      " - 157s - loss: 0.2665 - categorical_accuracy: 0.9297 - acc: 0.9297 - val_loss: 10.1198 - val_categorical_accuracy: 0.0955 - val_acc: 0.0955\n",
      "Epoch 23/50\n",
      " - 158s - loss: 0.2226 - categorical_accuracy: 0.9419 - acc: 0.9419 - val_loss: 10.1456 - val_categorical_accuracy: 0.0932 - val_acc: 0.0932\n",
      "Epoch 24/50\n",
      " - 157s - loss: 0.2016 - categorical_accuracy: 0.9494 - acc: 0.9494 - val_loss: 10.2799 - val_categorical_accuracy: 0.0973 - val_acc: 0.0973\n",
      "Epoch 25/50\n",
      " - 156s - loss: 0.1622 - categorical_accuracy: 0.9606 - acc: 0.9606 - val_loss: 10.3404 - val_categorical_accuracy: 0.0950 - val_acc: 0.0950\n",
      "Epoch 26/50\n",
      " - 158s - loss: 0.1532 - categorical_accuracy: 0.9611 - acc: 0.9611 - val_loss: 10.2849 - val_categorical_accuracy: 0.1036 - val_acc: 0.1036\n",
      "Epoch 27/50\n",
      " - 157s - loss: 0.1312 - categorical_accuracy: 0.9672 - acc: 0.9672 - val_loss: 10.3407 - val_categorical_accuracy: 0.0960 - val_acc: 0.0960\n",
      "Epoch 28/50\n",
      " - 164s - loss: 0.1147 - categorical_accuracy: 0.9717 - acc: 0.9717 - val_loss: 10.5457 - val_categorical_accuracy: 0.0960 - val_acc: 0.0960\n",
      "Epoch 29/50\n",
      " - 164s - loss: 0.1189 - categorical_accuracy: 0.9697 - acc: 0.9697 - val_loss: 10.5108 - val_categorical_accuracy: 0.0942 - val_acc: 0.0942\n",
      "Epoch 30/50\n",
      " - 164s - loss: 0.1082 - categorical_accuracy: 0.9723 - acc: 0.9723 - val_loss: 10.5631 - val_categorical_accuracy: 0.0979 - val_acc: 0.0979\n",
      "Epoch 31/50\n",
      " - 161s - loss: 0.0908 - categorical_accuracy: 0.9788 - acc: 0.9788 - val_loss: 10.4955 - val_categorical_accuracy: 0.0950 - val_acc: 0.0950\n",
      "Epoch 32/50\n",
      " - 160s - loss: 0.0842 - categorical_accuracy: 0.9797 - acc: 0.9797 - val_loss: 10.6270 - val_categorical_accuracy: 0.0971 - val_acc: 0.0971\n",
      "Epoch 33/50\n",
      " - 159s - loss: 0.0878 - categorical_accuracy: 0.9773 - acc: 0.9773 - val_loss: 10.5774 - val_categorical_accuracy: 0.0989 - val_acc: 0.0989\n",
      "Epoch 34/50\n",
      " - 158s - loss: 0.0787 - categorical_accuracy: 0.9790 - acc: 0.9790 - val_loss: 10.5568 - val_categorical_accuracy: 0.0950 - val_acc: 0.0950\n",
      "Epoch 35/50\n",
      " - 157s - loss: 0.0726 - categorical_accuracy: 0.9826 - acc: 0.9826 - val_loss: 10.6364 - val_categorical_accuracy: 0.0971 - val_acc: 0.0971\n",
      "Epoch 36/50\n",
      " - 158s - loss: 0.0790 - categorical_accuracy: 0.9801 - acc: 0.9801 - val_loss: 10.6726 - val_categorical_accuracy: 0.0986 - val_acc: 0.0986\n",
      "Epoch 37/50\n",
      " - 160s - loss: 0.0668 - categorical_accuracy: 0.9828 - acc: 0.9828 - val_loss: 10.6916 - val_categorical_accuracy: 0.0989 - val_acc: 0.0989\n",
      "Epoch 38/50\n",
      " - 165s - loss: 0.0643 - categorical_accuracy: 0.9840 - acc: 0.9840 - val_loss: 10.7008 - val_categorical_accuracy: 0.1015 - val_acc: 0.1015\n",
      "Epoch 39/50\n",
      " - 158s - loss: 0.0586 - categorical_accuracy: 0.9861 - acc: 0.9861 - val_loss: 10.6860 - val_categorical_accuracy: 0.1007 - val_acc: 0.1007\n",
      "Epoch 40/50\n",
      " - 158s - loss: 0.0540 - categorical_accuracy: 0.9871 - acc: 0.9871 - val_loss: 10.6681 - val_categorical_accuracy: 0.1057 - val_acc: 0.1057\n",
      "Epoch 41/50\n",
      " - 158s - loss: 0.0677 - categorical_accuracy: 0.9833 - acc: 0.9833 - val_loss: 10.7284 - val_categorical_accuracy: 0.1039 - val_acc: 0.1039\n",
      "Epoch 42/50\n",
      " - 158s - loss: 0.0582 - categorical_accuracy: 0.9854 - acc: 0.9854 - val_loss: 10.7542 - val_categorical_accuracy: 0.0971 - val_acc: 0.0971\n",
      "Epoch 43/50\n",
      " - 157s - loss: 0.0523 - categorical_accuracy: 0.9866 - acc: 0.9866 - val_loss: 10.8146 - val_categorical_accuracy: 0.0958 - val_acc: 0.0958\n",
      "Epoch 44/50\n",
      " - 157s - loss: 0.0480 - categorical_accuracy: 0.9876 - acc: 0.9876 - val_loss: 10.8754 - val_categorical_accuracy: 0.0929 - val_acc: 0.0929\n",
      "Epoch 45/50\n",
      " - 158s - loss: 0.0594 - categorical_accuracy: 0.9841 - acc: 0.9841 - val_loss: 10.7368 - val_categorical_accuracy: 0.0960 - val_acc: 0.0960\n",
      "Epoch 46/50\n",
      " - 167s - loss: 0.0452 - categorical_accuracy: 0.9891 - acc: 0.9891 - val_loss: 10.7553 - val_categorical_accuracy: 0.1012 - val_acc: 0.1012\n",
      "Epoch 47/50\n",
      " - 157s - loss: 0.0432 - categorical_accuracy: 0.9889 - acc: 0.9889 - val_loss: 10.7356 - val_categorical_accuracy: 0.1007 - val_acc: 0.1007\n",
      "Epoch 48/50\n",
      " - 161s - loss: 0.0470 - categorical_accuracy: 0.9880 - acc: 0.9880 - val_loss: 10.6772 - val_categorical_accuracy: 0.1059 - val_acc: 0.1059\n",
      "Epoch 49/50\n",
      " - 158s - loss: 0.0492 - categorical_accuracy: 0.9872 - acc: 0.9872 - val_loss: 10.8074 - val_categorical_accuracy: 0.1007 - val_acc: 0.1007\n",
      "Epoch 50/50\n",
      " - 158s - loss: 0.0464 - categorical_accuracy: 0.9880 - acc: 0.9880 - val_loss: 10.7816 - val_categorical_accuracy: 0.1028 - val_acc: 0.1028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa58ecc3ba8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X_train, Y_train, batch_size=128, epochs=50, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, модель очень быстро набрала высокие показатели точности на тренировочной выборке (хотя и плохо справляется с тестовой). Генерация чуть лучше, чем у третьей модели - все еще хорошая пунктуация, попытка строить осмысленные фразы, но так же в одном контексте начали встречаться семантически связанные слова (пусть и плохо связанные синтаксически): \"у кого и рекой, были переправились на берег\", \"и попросила сент-эсташа зайти за ней, и вечером в пансионе ее\", \"благодаря идущего известно\" (!), \"мать и никто не выходили из дома\" (!), \"в результате разложения\" (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from seed: , показал , что он , в небольшом и иногда\n",
      ", показал , что он , в небольшом и иногда вещи , чем вытесняет , в большой , у кого и рекой , были переправились на берег берег как их вес нашли , насколько я было возможно , замяли . \n",
      "__________\n",
      "\n",
      "Generating from seed: против другой . к не следует с , хотя непременно\n",
      "против другой . к не следует с , хотя непременно гораздо более ней , и попросила сент-эсташа зайти за ней , и вечером в пансионе ее , ее ботинки , в связи с тонкими противоречивых человек . три там , \n",
      "__________\n",
      "\n",
      "Generating from seed: время , как свидетели по , убийца не мог .\n",
      "время , как свидетели по , убийца не мог . благодаря идущего известно , что не более том как будто был других был извлечен довод , мать и никто не выходили из дома . в результате разложения , даже в \n",
      "__________\n",
      "\n",
      "Generating from seed: хотя не дает его . дюпен этим делом , но\n",
      "хотя не дает его . дюпен этим делом , но они никем представляется и не настолько в то истинности , а в чаще все же совпадений . именно в любой день после людей , по раскрыться принципу была особому существенной \n",
      "__________\n",
      "\n",
      "Generating from seed: что ; но не , чтобы вы и в поверили\n",
      "что ; но не , чтобы вы и в поверили мадам роже , мадам б. , только хочу сказать , что место , где его недавняя маленьких , кроме того , чтобы прочитав какая-то себе привлекли ; однако было бы \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate(X_test, model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b551c0ce3b45b6b65265d786d1ec9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6244), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplex[3] = perplexity(X_test, model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим также работу ГРУ на тех же данных и с теми же параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Embedding(WORDS, 300, input_length=10))\n",
    "model6.add(GRU(512, return_sequences = True))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(GRU(512))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(WORDS, activation='softmax'))\n",
    "\n",
    "model6.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['categorical_accuracy', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 10, 300)           1496100   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 10, 512)           1248768   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 512)               1574400   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4987)              2558331   \n",
      "=================================================================\n",
      "Total params: 6,877,599\n",
      "Trainable params: 6,877,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 165s - loss: 6.5553 - categorical_accuracy: 0.1088 - acc: 0.1088\n",
      "Epoch 2/15\n",
      " - 165s - loss: 6.1056 - categorical_accuracy: 0.1223 - acc: 0.1223\n",
      "Epoch 3/15\n",
      " - 165s - loss: 5.5398 - categorical_accuracy: 0.1471 - acc: 0.1471\n",
      "Epoch 4/15\n",
      " - 176s - loss: 4.7178 - categorical_accuracy: 0.1955 - acc: 0.1955\n",
      "Epoch 5/15\n",
      " - 170s - loss: 3.7330 - categorical_accuracy: 0.2744 - acc: 0.2744\n",
      "Epoch 6/15\n",
      " - 175s - loss: 2.7326 - categorical_accuracy: 0.4487 - acc: 0.4487\n",
      "Epoch 7/15\n",
      " - 170s - loss: 1.9284 - categorical_accuracy: 0.6033 - acc: 0.6033\n",
      "Epoch 8/15\n",
      " - 163s - loss: 1.3810 - categorical_accuracy: 0.7138 - acc: 0.7138\n",
      "Epoch 9/15\n",
      " - 164s - loss: 1.0129 - categorical_accuracy: 0.7922 - acc: 0.7922\n",
      "Epoch 10/15\n",
      " - 165s - loss: 0.7308 - categorical_accuracy: 0.8566 - acc: 0.8566\n",
      "Epoch 11/15\n",
      " - 166s - loss: 0.5106 - categorical_accuracy: 0.9100 - acc: 0.9100\n",
      "Epoch 12/15\n",
      " - 164s - loss: 0.3668 - categorical_accuracy: 0.9444 - acc: 0.9444\n",
      "Epoch 13/15\n",
      " - 162s - loss: 0.2598 - categorical_accuracy: 0.9664 - acc: 0.9664\n",
      "Epoch 14/15\n",
      " - 176s - loss: 0.1718 - categorical_accuracy: 0.9847 - acc: 0.9847\n",
      "Epoch 15/15\n",
      " - 173s - loss: 0.1181 - categorical_accuracy: 0.9913 - acc: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa6252ca7b8>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(X_train, Y_train, batch_size=128, epochs=15, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя модель и достигла достаточно высоких показателей точности, предсказывает она все еще неважно, хотя есть последовательности осмысленные, намного лучше,чем предыдущие модели (но они очень похожи на целые куски тестового текста): **\"даже если бы в чаще у заставы дюруль в три часа дня , то есть через несколько часов после \"**, **\"которые по воскресеньям наводняют города\"**, **« в трактир ввалилась компания хулиганов , которые вели себя очень буйно , не заплатили за то , что \"** (!), **\"но полицейские не собиралась начать серьезное расследование , как вдруг в одно прекрасное утро ровно через неделю мари вновь появилась на \"**(!), **\"успел донести на него\"** (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from seed: что вы заметили ? – я заметил , что все\n",
      "что вы заметили ? – я заметил , что все какую-то газеты , мадам дюлюк из дома , а все эта свои мари девушки , а во второй случае она не знают никаких , чем под нового . десять шансов \n",
      "__________\n",
      "\n",
      "Generating from seed: все еще о камнях ) до тех пор , пока\n",
      "все еще о камнях ) до тех пор , пока количество о оторвана примеров , и мысль об наших заметно бы даже если бы в чаще у заставы дюруль в три часа дня , то есть через несколько часов после \n",
      "__________\n",
      "\n",
      "Generating from seed: я не ни одного , ни на минуту не из\n",
      "я не ни одного , ни на минуту не из драма . связь людей , которые по воскресеньям наводняют города : « в трактир ввалилась компания хулиганов , которые вели себя очень буйно , не заплатили за то , что \n",
      "__________\n",
      "\n",
      "Generating from seed: пор , пока часы не знать , что ночь .\n",
      "пор , пока часы не знать , что ночь . мы правило , а потому лишь лишь газеты , но полицейские не собиралась начать серьезное расследование , как вдруг в одно прекрасное утро ровно через неделю мари вновь появилась на \n",
      "__________\n",
      "\n",
      "Generating from seed: с огромной на голове чуть не меня с ног ,\n",
      "с огромной на голове чуть не меня с ног , а потому это это труп » . он невозможно долго , что в момент же самый вечер и она ничего не знали , как все идти успел донести на него \n",
      "__________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate(X_test, model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d1fe6adf1942f6999257b7e0a9443f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6244), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplex[4] = perplexity(X_test, model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-layer Simple LSTM:  414.391 \n",
      "Big LSTM:  4987.051 \n",
      "Great LSTM:  1696.654 \n",
      "Bidirectional LSTM:  3949331.39 \n",
      "Two-layered GRU:  14532.495\n"
     ]
    }
   ],
   "source": [
    "print(\"One-layer Simple LSTM: \", round(perplex[0],3), \"\\nBig LSTM: \", round(perplex[1],3), \"\\nGreat LSTM: \", round(perplex[2],3), \"\\nBidirectional LSTM: \", round(perplex[3],3), \"\\nTwo-layered GRU: \", round(perplex[4], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая низкая перплексия - у самой простой LSTM. Маловероятно, что это отражение качества модели, скорее, того, что она опирается на небольшие параметры, которые не могут учесть всех слов, а значит, у нее меньше вариантов предсказаний, следовательно, она меньше всего в \"замешательстве\" при выборе последующего слова.  \n",
    "\n",
    "Наибольшая перплексия (даже очень) - у двунаправленной LSTM. В принципе, это логично, так как двунаправленная ЛСТМ фиксирует контекст и прошлый, и будущий, то есть анализирует больший набор данных. При больших параметрах модели у нее появляется слишком много вариантов возможных слов.\n",
    "\n",
    "Наиболее оптимальным представляется третий вариант LSTM - у нее не очень высокая перплексия, и хотя отдельные части последовательностей не несут особого смысла в сочетании, отдельные куски вполне осмысленные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что можно еще сделать:**\n",
    "* так как самым оптимальным оказался вариант, у которого просто были достаточно высокие параметры, можно продолжать их наращивать, чтобы выцепить больше информации из входных данных для модели\n",
    "* увеличить число эпох, не переходя границу переобучения, чтобы иметь возможность предсказывать новые тексты\n",
    "* попробовать использовать несколько слоев LSTM\n",
    "* часто страдает согласование слов, даже при наличии смысловой сочетаемости. Можно было бы помимо непосредственно слов, авать на вход моделям частеречную разметку для более точного предсказания\n",
    "\n",
    "**Основная проблема** - что делать со словами, уникальными для тестовой выборки. Если их просто игнорировать, не теряем ли мы часть информации контекста, которая может быть важна для моделей LSTM типа, которые именно и ориентированы на запоминание контекста? Если бы была возможность как-то учитывать эти слова, мы могли бы улучшить предсказательную способность модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
