{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q24vDAMUFlL2"
   },
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uo4sziz1FlL9",
    "outputId": "4ead28ae-9ed8-4225-b572-b4ef53ca0490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from input...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "INPUT_FILE = \"ADVENTURES_OF_SHERLOCK_HOLMES.txt\"\n",
    "text = []\n",
    "# extract the input as a stream of characters\n",
    "print(\"Extracting text from input...\")\n",
    "fin = open(INPUT_FILE, 'r', encoding='utf-8')\n",
    "lines = []\n",
    "counter = 0\n",
    "for line in fin:\n",
    "    counter = counter + 1 \n",
    "    if(counter <= 5000): \n",
    "        new_line = re.findall('\\w+', line)\n",
    "        for word in new_line:\n",
    "            word = word_tokenize(word)\n",
    "            text.append(word[0].lower())\n",
    "fin.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-9HdmvhFlMG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5147\n"
     ]
    }
   ],
   "source": [
    "# creating lookup tables\n",
    "# Here chars is the number of features in our character \"vocabulary\"\n",
    "word = set([c for c in text])\n",
    "nb_words = len(word)\n",
    "print(nb_words)\n",
    "word2index = dict((c, i) for i, c in enumerate(word))\n",
    "index2word = dict((i, c) for i, c in enumerate(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kcekrcx6FlMS",
    "outputId": "80e6d607-3fd2-4602-d73a-630821a6d00e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input and label text...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating input and label text...\")\n",
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "\n",
    "input_words = []\n",
    "label_words = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_words.append(text[i:i + SEQLEN])\n",
    "    label_words.append(text[i + SEQLEN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7EUPyt6FlMY",
    "outputId": "07e3429c-0562-4103-9006-7b44fb9e79fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing input and label text...\n"
     ]
    }
   ],
   "source": [
    "# vectorize the input and label chars\n",
    "# Each row of the input is represented by seqlen characters, each \n",
    "# represented as a 1-hot encoding of size len(char). There are \n",
    "# len(input_chars) such rows, so shape(X) is (len(input_chars),\n",
    "# seqlen, nb_chars).\n",
    "# Each row of output is a single character, also represented as a\n",
    "# dense encoding of size len(char). Hence shape(y) is (len(input_chars),\n",
    "# nb_chars).\n",
    "print(\"Vectorizing input and label text...\")\n",
    "X = np.zeros((len(input_words), SEQLEN))\n",
    "y = np.zeros((len(input_words), nb_words), dtype=np.bool)\n",
    "for i,ch in enumerate(input_words):\n",
    "    for j, cm in enumerate(ch):\n",
    "        X[i, j] = word2index[cm]\n",
    "    y[i, word2index[label_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDQJoWxiFlMe"
   },
   "outputs": [],
   "source": [
    "# Build the model. We use a single RNN with a fully connected layer\n",
    "# to compute the most likely predicted output char\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(Embedding(nb_words, 64, input_length=SEQLEN))\n",
    "RNNmodel.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_words),\n",
    "                    unroll=True))\n",
    "RNNmodel.add(Dense(nb_words))\n",
    "RNNmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "RNNmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ME_NslKFlMk",
    "outputId": "a0cf4705-da83-4e8e-a1cd-541631b6ba8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 29s 662us/step - loss: 6.3480 - acc: 0.0621\n",
      "Generating from seed: \n",
      "by his whole appearance he carried a broad brimmed hat \n",
      "\n",
      "by his whole appearance he carried a broad brimmed hat and the own man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 33s 745us/step - loss: 5.9470 - acc: 0.0903\n",
      "Generating from seed: \n",
      "and said that it would be safer and better not \n",
      "\n",
      "and said that it would be safer and better not have be the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man \n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 34s 774us/step - loss: 5.7909 - acc: 0.1062\n",
      "Generating from seed: \n",
      "remarkable as your advertisement oh he has his faults too \n",
      "\n",
      "remarkable as your advertisement oh he has his faults too very man i have not be that i am not be that i am not be you have be that i am not be that i have not be that i am not be that i am not be you have be that i am not be that i have not be that i am not be that i am not be you have be that i am not be that i have not be that i am not be that i am not be you have be that i am not be that i have not be that i \n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 35s 793us/step - loss: 5.6656 - acc: 0.1192\n",
      "Generating from seed: \n",
      "day so far forgotten his filial duty as to bandy \n",
      "\n",
      "day so far forgotten his filial duty as to bandy his own man and the man and the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and the man of the man and \n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 47s 1ms/step - loss: 5.5521 - acc: 0.1301: 1s - loss: 5.5492 - acc: 0. - ETA: 0s - loss: 5.5492 -\n",
      "Generating from seed: \n",
      "very neat and plain but his eyes were weak just \n",
      "\n",
      "very neat and plain but his eyes were weak just i had a little of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man \n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 34s 774us/step - loss: 5.4404 - acc: 0.14230s - loss: 5.4406 - acc: 0. - ETA: 0s - loss: 5.4409 - acc: 0.14\n",
      "Generating from seed: \n",
      "tiptoes square too quite unusual boots they come they go \n",
      "\n",
      "tiptoes square too quite unusual boots they come they go to be a man who was a very man and i have not a man and i have a little of the man and i was a man of the other which was a little of the man and i was a man of the other which was a little of the man and i was a man of the other which was a little of the man and i was a man of the other which was a little of the man and i was a man of the other which was a little of the man and i \n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 32s 724us/step - loss: 5.3387 - acc: 0.1518\n",
      "Generating from seed: \n",
      "about to withdraw when holmes pulled me abruptly into the \n",
      "\n",
      "about to withdraw when holmes pulled me abruptly into the other and i have a little of the man and the man was of the man was of the other and and the door of the man is of the house of the man is of the sort of the man is of the other is of the house of the other i have been been to me for the other is of the other said holmes i have a very man and i have been in the other is of the house i was not to the man is of the house of the man is of the sort \n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 32s 723us/step - loss: 5.2380 - acc: 0.1629\n",
      "Generating from seed: \n",
      "between them and what the object of his repeated visits \n",
      "\n",
      "between them and what the object of his repeated visits was in the other of the s of his father was a from the of the man was of the other and i have not to him that i had not been to me to be a little of the man and i had a little of the man and of the door of the man was of the house of the other which was the other that i had not his face to his father was in his face and his father was his father was a man and he had been his face and his father was his \n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 35s 794us/step - loss: 5.1528 - acc: 0.17304s - lo\n",
      "Generating from seed: \n",
      "his shelves eglow eglonitz here we are egria it is \n",
      "\n",
      "his shelves eglow eglonitz here we are egria it is a very fellow is a man who was a very man and he had been to him and with his father was a man and he had been in his face and his father was a man and he had been up to his chair and his had been and in his hand and as he had been his eyes were for his own was not to be a little of the s man which i had been to him to be the of the man and i had been to him at the other is a little of this \n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 38s 847us/step - loss: 5.0872 - acc: 0.18414s - loss\n",
      "Generating from seed: \n",
      "actor even as science lost an acute reasoner when he \n",
      "\n",
      "actor even as science lost an acute reasoner when he is a to be of the one of the man s is and i have not to the that i have not been to be in a but of the said holmes i have been to me to be a little of a and i have not a little for that i have been to be to be to be a little of the but i have not to my father i have not to him to be a little of a little and i have to be an for this is of a little man who s i have \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 38s 856us/step - loss: 5.0791 - acc: 0.1949\n",
      "Generating from seed: \n",
      "done of an evening mr holmes especially thursday and friday \n",
      "\n",
      "done of an evening mr holmes especially thursday and friday were to me that the his had been been in his chair and he was not be at him and with his own at the is of the said i have not to him i have to him at the when he had been at his own she was not to be in the but i have not to him i have not to him and the other had been been in his chair and he was his be at his and he was in his way with a man and he was not to him and with his own \n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 32s 720us/step - loss: 5.1080 - acc: 0.2113\n",
      "Generating from seed: \n",
      "to frighten a chap for he sank his face onto \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to frighten a chap for he sank his face onto his father was in his father was in his own and he was a little of the which was of a in which i have the very of the but i had not been of some and or my father was in his father and what do you know that it is not be well to the your be in a very is not so that i had not see my own said holmes you have been in a very of which i had been to his own and in the other were of the which was no so in \n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 31s 698us/step - loss: 5.1341 - acc: 0.2258\n",
      "Generating from seed: \n",
      "does but he is too tender hearted to hurt a \n",
      "\n",
      "does but he is too tender hearted to hurt a little but i am a little for one of the which was not to the with a of the of which i have been in his face and i have not see him that i had not been in him and of the man and as he had a from the that of the of which he had been to the man and the of which was to be a of the man and the of the and s that he was a man s a and and i am that his father was a and for it is a \n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 36s 819us/step - loss: 5.1450 - acc: 0.2406\n",
      "Generating from seed: \n",
      "know how he was employing his extraordinary powers his rooms \n",
      "\n",
      "know how he was employing his extraordinary powers his rooms was a man and his as he had been and his father was in his it was a very of some i have the little from which i have a little from the but i had not a very man and i have to be a very man and the have been of his as i was to his come to his father i was in the that of it was in a very of the that was of it was a man who was the me of the and i had been at a i have been a very \n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 37s 835us/step - loss: 5.1430 - acc: 0.2558\n",
      "Generating from seed: \n",
      "letters come so we may put our little problem upon \n",
      "\n",
      "letters come so we may put our little problem upon the i have been to the so i am not know a you which i know the that i was that you will not have been to a very of it is a very my own to have a little and i have a little that i have been some very to you have the but i am that you i was so that i was in the of which he said holmes as he had been to his not have been in his to be he and his to his had been his very his and or his is \n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 31s 695us/step - loss: 5.1348 - acc: 0.2740\n",
      "Generating from seed: \n",
      "he come with you to night no his orders were \n",
      "\n",
      "he come with you to night no his orders were he is not that he had a his and i was in the of one of it was in the of the of which he had been in his face and his he was not his his was in his own for he and i have to the that he had a at the other s but he was not have been and to his as she was to be his when he was in his it and the man had which was his as i was so i have the at one of the which i had been in \n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 36s 802us/step - loss: 5.1146 - acc: 0.2882\n",
      "Generating from seed: \n",
      "on the sundial i read peeping over his shoulder what \n",
      "\n",
      "on the sundial i read peeping over his shoulder what s not to be of a you and i have a little of a but i am not to be a very i have the little of the but i have it is a very man who is a a man and i have the one of my own and i have been a man and that the has been out the very of the he was a and of the and which i was in the of which i have had been in a and of my father was the of that a holmes and the the is of \n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 29s 664us/step - loss: 5.0830 - acc: 0.3038\n",
      "Generating from seed: \n",
      "it was very sweet of you to come now you \n",
      "\n",
      "it was very sweet of you to come now you will have been your at all i have been little to you have a a then that there is a man who was a in the at the of the he had been and i was that my father was in a not and to the so of the that i was to him i am that he had a little i am as he said i have the the man and of my father s not and but i was in that it was in his own as he had at the i of the at the of which \n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 45s 1ms/step - loss: 5.0561 - acc: 0.3184\n",
      "Generating from seed: \n",
      "their singular warning or token before them when starting upon \n",
      "\n",
      "their singular warning or token before them when starting upon me and the you have not a with you that there is a little that he was a a man and for his face and he was in a my man was in which he was in his very little and he was a to the that of his was and in it and that i had the him i am that he would not have been of the but what is it to be i am but i had the little i of the i am not and my man to do it i have the little that she \n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 36s 801us/step - loss: 5.0191 - acc: 0.33542s - los - ETA: 1s - loss: 5.0151 - acc: 0. - ETA: 1s -\n",
      "Generating from seed: \n",
      "is that which is given to one of the states \n",
      "\n",
      "is that which is given to one of the states of the it was a man from his and his and was in his to his and and i have not been but for it was not be of a very and but i have not to him as we had been in his to be and in his to be the very of a he had a his face in a he had the me to be in which i had not to him that i had the so i am of my that it is the of of which i have had been at him as i am \n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 36s 804us/step - loss: 4.9843 - acc: 0.34980s - loss: 4.9848 - a\n",
      "Generating from seed: \n",
      "have done before now had i been recognized in that \n",
      "\n",
      "have done before now had i been recognized in that i have been to his face it out of it and that it was of it was there are no of the man of which you have been i have the one of the not have to it was in a to which i do you are to the my man is a a s one or in the of of my in the i s that i was and that it was in it i have a i shall be as a as we could to the very of a and i can have been it by the that \n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 33s 734us/step - loss: 4.9492 - acc: 0.3655\n",
      "Generating from seed: \n",
      "of a very remarkable inquiry and i have hoped to \n",
      "\n",
      "of a very remarkable inquiry and i have hoped to his to have the of the said holmes as a man and that his was his on the not a and the little man with a for your this is a from one a man is in a and and a have had in the of this is of my own i have not a s man for i have the that of it is not i have a s man with a a man but my have is a a man is in which i had been but i was the to do which as a little to have \n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 32s 731us/step - loss: 4.9122 - acc: 0.37691s - loss: \n",
      "Generating from seed: \n",
      "considerable crime is in contemplation i have every reason to \n",
      "\n",
      "considerable crime is in contemplation i have every reason to have you have a very and i am not so i am in the of which i am not to a man which would be a a of man and i have a little from an this is of my own to and i have a from the but of my father to be it and i have a to be but this i was that it is a little as i have not to what i have been at a very of my own have been and his as is as he was a man who was his be \n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 33s 742us/step - loss: 4.8746 - acc: 0.39013s - loss: 4.8540 - acc: 0 - ETA: 2s - - ETA: 1s - loss: 4.86\n",
      "Generating from seed: \n",
      "tossed it it was an indian cigar of the variety \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tossed it it was an indian cigar of the variety which are it in my father i have a very by one of the of some but you would have been to be to an one of his the to the which there was no one of him and i was a man who was the in which he and that it was was that by the was in the which was in the of a but so i was that there was no i was in the which you but but i have been my own man is a you are and i have the at the but i \n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 34s 766us/step - loss: 4.8414 - acc: 0.40321s - loss: 4\n",
      "Generating from seed: \n",
      "good for some years and an extra couple of hundred \n",
      "\n",
      "good for some years and an extra couple of hundred that it was very very would be to by the of this of the that i was the that of the and then i had been in upon his it was a little of the and then that there was a to be of a a she and at his have you have been it is that for he has been been in his case and he was not to him and i am a little of a man and i was in my father and i and with a it s is not have been but two is of \n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    RNNmodel.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars, then use it to \n",
    "    # generate text from model for next 100  \n",
    "    test_idx = np.random.randint(len(input_words))\n",
    "    test_words = input_words[test_idx]\n",
    "    print(\"Generating from seed: \")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    print(\"\\n\")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN))\n",
    "        for i, ch in enumerate(test_words[-10:len(test_words)]):\n",
    "            Xtest[0, i] = word2index[ch]\n",
    "        pred = RNNmodel.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2word[np.argmax(pred)]\n",
    "        print(ypred, end=\" \")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_words.append(ypred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from input...\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE = \"A_STUDY_IN_SCARLET.txt\"\n",
    "text2 = []\n",
    "\n",
    "print(\"Extracting text from input...\")\n",
    "book2 = open(INPUT_FILE, 'r', encoding='utf8')\n",
    "counter = 0\n",
    "for line in book2:\n",
    "    counter = counter + 1 \n",
    "    if(counter <= 5000): \n",
    "        new_line = re.findall('\\w+', line)\n",
    "        for word in new_line:\n",
    "            word = word_tokenize(word)\n",
    "            text2.append(word[0].lower())\n",
    "book2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Итак, у нас имеются 2 списка: text и text2\n",
    "#Добавим одинаковые слова во вторую книгу\n",
    "\n",
    "new_text = []\n",
    "for t in text2:\n",
    "    if t in text:\n",
    "        new_text.append(t)\n",
    "        \n",
    "text2 = new_text\n",
    "#print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = []\n",
    "test_labels = []\n",
    "for i in range(0, len(text2) - SEQLEN, STEP):\n",
    "    test_words.append(text2[i:i + SEQLEN])\n",
    "    test_labels.append(text2[i + SEQLEN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39888\n",
      "10\n",
      "[['a', 'study', 'in', 'scarlet', 'by', 'a', '1', 's', 'note', 'this'], ['study', 'in', 'scarlet', 'by', 'a', '1', 's', 'note', 'this', 'is'], ['in', 'scarlet', 'by', 'a', '1', 's', 'note', 'this', 'is', 'from'], ['scarlet', 'by', 'a', '1', 's', 'note', 'this', 'is', 'from', 'an'], ['by', 'a', '1', 's', 'note', 'this', 'is', 'from', 'an', 'and'], ['a', '1', 's', 'note', 'this', 'is', 'from', 'an', 'and', 'care'], ['1', 's', 'note', 'this', 'is', 'from', 'an', 'and', 'care', 'has'], ['s', 'note', 'this', 'is', 'from', 'an', 'and', 'care', 'has', 'been'], ['note', 'this', 'is', 'from', 'an', 'and', 'care', 'has', 'been', 'taken'], ['this', 'is', 'from', 'an', 'and', 'care', 'has', 'been', 'taken', 'to'], ['is', 'from', 'an', 'and', 'care', 'has', 'been', 'taken', 'to', 'the'], ['from', 'an', 'and', 'care', 'has', 'been', 'taken', 'to', 'the', 'exactly'], ['an', 'and', 'care', 'has', 'been', 'taken', 'to', 'the', 'exactly', 'and'], ['and', 'care', 'has', 'been', 'taken', 'to', 'the', 'exactly', 'and', 'to'], ['care', 'has', 'been', 'taken', 'to', 'the', 'exactly', 'and', 'to', 'the'], ['has', 'been', 'taken', 'to', 'the', 'exactly', 'and', 'to', 'the', 'text'], ['been', 'taken', 'to', 'the', 'exactly', 'and', 'to', 'the', 'text', 'the'], ['taken', 'to', 'the', 'exactly', 'and', 'to', 'the', 'text', 'the', 'character'], ['to', 'the', 'exactly', 'and', 'to', 'the', 'text', 'the', 'character', 'to'], ['the', 'exactly', 'and', 'to', 'the', 'text', 'the', 'character', 'to', 'indicate'], ['exactly', 'and', 'to', 'the', 'text', 'the', 'character', 'to', 'indicate', 'and'], ['and', 'to', 'the', 'text', 'the', 'character', 'to', 'indicate', 'and', 'end'], ['to', 'the', 'text', 'the', 'character', 'to', 'indicate', 'and', 'end', 'notes'], ['the', 'text', 'the', 'character', 'to', 'indicate', 'and', 'end', 'notes', 'in'], ['text', 'the', 'character', 'to', 'indicate', 'and', 'end', 'notes', 'in', 'square'], ['the', 'character', 'to', 'indicate', 'and', 'end', 'notes', 'in', 'square', 's'], ['character', 'to', 'indicate', 'and', 'end', 'notes', 'in', 'square', 's', 'note'], ['to', 'indicate', 'and', 'end', 'notes', 'in', 'square', 's', 'note', 'in'], ['indicate', 'and', 'end', 'notes', 'in', 'square', 's', 'note', 'in', 'and'], ['and', 'end', 'notes', 'in', 'square', 's', 'note', 'in', 'and', 'old'], ['end', 'notes', 'in', 'square', 's', 'note', 'in', 'and', 'old', 'files'], ['notes', 'in', 'square', 's', 'note', 'in', 'and', 'old', 'files', 'such'], ['in', 'square', 's', 'note', 'in', 'and', 'old', 'files', 'such', 'as'], ['square', 's', 'note', 'in', 'and', 'old', 'files', 'such', 'as', 'this'], ['s', 'note', 'in', 'and', 'old', 'files', 'such', 'as', 'this', 'to'], ['note', 'in', 'and', 'old', 'files', 'such', 'as', 'this', 'to', 'the'], ['in', 'and', 'old', 'files', 'such', 'as', 'this', 'to', 'the', 'present'], ['and', 'old', 'files', 'such', 'as', 'this', 'to', 'the', 'present', 'system'], ['old', 'files', 'such', 'as', 'this', 'to', 'the', 'present', 'system', 'it'], ['files', 'such', 'as', 'this', 'to', 'the', 'present', 'system', 'it', 'is'], ['such', 'as', 'this', 'to', 'the', 'present', 'system', 'it', 'is', 'the'], ['as', 'this', 'to', 'the', 'present', 'system', 'it', 'is', 'the', 'policy'], ['this', 'to', 'the', 'present', 'system', 'it', 'is', 'the', 'policy', 'to'], ['to', 'the', 'present', 'system', 'it', 'is', 'the', 'policy', 'to', 'the'], ['the', 'present', 'system', 'it', 'is', 'the', 'policy', 'to', 'the', 'text'], ['present', 'system', 'it', 'is', 'the', 'policy', 'to', 'the', 'text', 'to'], ['system', 'it', 'is', 'the', 'policy', 'to', 'the', 'text', 'to', 'to'], ['it', 'is', 'the', 'policy', 'to', 'the', 'text', 'to', 'to', 'present'], ['is', 'the', 'policy', 'to', 'the', 'text', 'to', 'to', 'present', 'in'], ['the', 'policy', 'to', 'the', 'text', 'to', 'to', 'present', 'in', 'this'], ['policy', 'to', 'the', 'text', 'to', 'to', 'present', 'in', 'this', 'case'], ['to', 'the', 'text', 'to', 'to', 'present', 'in', 'this', 'case', 'however'], ['the', 'text', 'to', 'to', 'present', 'in', 'this', 'case', 'however', 'in'], ['text', 'to', 'to', 'present', 'in', 'this', 'case', 'however', 'in', 'consideration'], ['to', 'to', 'present', 'in', 'this', 'case', 'however', 'in', 'consideration', 'of'], ['to', 'present', 'in', 'this', 'case', 'however', 'in', 'consideration', 'of', 'the'], ['present', 'in', 'this', 'case', 'however', 'in', 'consideration', 'of', 'the', 'note'], ['in', 'this', 'case', 'however', 'in', 'consideration', 'of', 'the', 'note', 'above'], ['this', 'case', 'however', 'in', 'consideration', 'of', 'the', 'note', 'above', 'of'], ['case', 'however', 'in', 'consideration', 'of', 'the', 'note', 'above', 'of', 'the'], ['however', 'in', 'consideration', 'of', 'the', 'note', 'above', 'of', 'the', 'his'], ['in', 'consideration', 'of', 'the', 'note', 'above', 'of', 'the', 'his', 'care'], ['consideration', 'of', 'the', 'note', 'above', 'of', 'the', 'his', 'care', 'to'], ['of', 'the', 'note', 'above', 'of', 'the', 'his', 'care', 'to', 'try'], ['the', 'note', 'above', 'of', 'the', 'his', 'care', 'to', 'try', 'to'], ['note', 'above', 'of', 'the', 'his', 'care', 'to', 'try', 'to', 'the'], ['above', 'of', 'the', 'his', 'care', 'to', 'try', 'to', 'the', 'as'], ['of', 'the', 'his', 'care', 'to', 'try', 'to', 'the', 'as', 'to'], ['the', 'his', 'care', 'to', 'try', 'to', 'the', 'as', 'to', 'and'], ['his', 'care', 'to', 'try', 'to', 'the', 'as', 'to', 'and', 'no'], ['care', 'to', 'try', 'to', 'the', 'as', 'to', 'and', 'no', 'have'], ['to', 'try', 'to', 'the', 'as', 'to', 'and', 'no', 'have', 'been'], ['try', 'to', 'the', 'as', 'to', 'and', 'no', 'have', 'been', 'made'], ['to', 'the', 'as', 'to', 'and', 'no', 'have', 'been', 'made', 'in'], ['the', 'as', 'to', 'and', 'no', 'have', 'been', 'made', 'in', 'this'], ['as', 'to', 'and', 'no', 'have', 'been', 'made', 'in', 'this', 'text'], ['to', 'and', 'no', 'have', 'been', 'made', 'in', 'this', 'text', 'however'], ['and', 'no', 'have', 'been', 'made', 'in', 'this', 'text', 'however', 'in'], ['no', 'have', 'been', 'made', 'in', 'this', 'text', 'however', 'in', 'the'], ['have', 'been', 'made', 'in', 'this', 'text', 'however', 'in', 'the', '1'], ['been', 'made', 'in', 'this', 'text', 'however', 'in', 'the', '1', 'and'], ['made', 'in', 'this', 'text', 'however', 'in', 'the', '1', 'and', 'this'], ['in', 'this', 'text', 'however', 'in', 'the', '1', 'and', 'this', 'present'], ['this', 'text', 'however', 'in', 'the', '1', 'and', 'this', 'present', 'are'], ['text', 'however', 'in', 'the', '1', 'and', 'this', 'present', 'are', 'followed'], ['however', 'in', 'the', '1', 'and', 'this', 'present', 'are', 'followed', 'and'], ['in', 'the', '1', 'and', 'this', 'present', 'are', 'followed', 'and', 'the'], ['the', '1', 'and', 'this', 'present', 'are', 'followed', 'and', 'the', 'several'], ['1', 'and', 'this', 'present', 'are', 'followed', 'and', 'the', 'several', 'french'], ['and', 'this', 'present', 'are', 'followed', 'and', 'the', 'several', 'french', 'and'], ['this', 'present', 'are', 'followed', 'and', 'the', 'several', 'french', 'and', 'words'], ['present', 'are', 'followed', 'and', 'the', 'several', 'french', 'and', 'words', 'have'], ['are', 'followed', 'and', 'the', 'several', 'french', 'and', 'words', 'have', 'been'], ['followed', 'and', 'the', 'several', 'french', 'and', 'words', 'have', 'been', 'given'], ['and', 'the', 'several', 'french', 'and', 'words', 'have', 'been', 'given', 'their'], ['the', 'several', 'french', 'and', 'words', 'have', 'been', 'given', 'their', 'part'], ['several', 'french', 'and', 'words', 'have', 'been', 'given', 'their', 'part', 'ii'], ['french', 'and', 'words', 'have', 'been', 'given', 'their', 'part', 'ii', 'the'], ['and', 'words', 'have', 'been', 'given', 'their', 'part', 'ii', 'the', 'country'], ['words', 'have', 'been', 'given', 'their', 'part', 'ii', 'the', 'country', 'of'], ['have', 'been', 'given', 'their', 'part', 'ii', 'the', 'country', 'of', 'the'], ['been', 'given', 'their', 'part', 'ii', 'the', 'country', 'of', 'the', 'much'], ['given', 'their', 'part', 'ii', 'the', 'country', 'of', 'the', 'much', 'with'], ['their', 'part', 'ii', 'the', 'country', 'of', 'the', 'much', 'with', 'the'], ['part', 'ii', 'the', 'country', 'of', 'the', 'much', 'with', 'the', 'church'], ['ii', 'the', 'country', 'of', 'the', 'much', 'with', 'the', 'church', 'a'], ['the', 'country', 'of', 'the', 'much', 'with', 'the', 'church', 'a', 'study'], ['country', 'of', 'the', 'much', 'with', 'the', 'church', 'a', 'study', 'in'], ['of', 'the', 'much', 'with', 'the', 'church', 'a', 'study', 'in', 'scarlet'], ['the', 'much', 'with', 'the', 'church', 'a', 'study', 'in', 'scarlet', 'part'], ['much', 'with', 'the', 'church', 'a', 'study', 'in', 'scarlet', 'part', 'i'], ['with', 'the', 'church', 'a', 'study', 'in', 'scarlet', 'part', 'i', 'a'], ['the', 'church', 'a', 'study', 'in', 'scarlet', 'part', 'i', 'a', 'from'], ['church', 'a', 'study', 'in', 'scarlet', 'part', 'i', 'a', 'from', 'the'], ['a', 'study', 'in', 'scarlet', 'part', 'i', 'a', 'from', 'the', 'john'], ['study', 'in', 'scarlet', 'part', 'i', 'a', 'from', 'the', 'john', 'h'], ['in', 'scarlet', 'part', 'i', 'a', 'from', 'the', 'john', 'h', 'watson'], ['scarlet', 'part', 'i', 'a', 'from', 'the', 'john', 'h', 'watson', 'm'], ['part', 'i', 'a', 'from', 'the', 'john', 'h', 'watson', 'm', 'd'], ['i', 'a', 'from', 'the', 'john', 'h', 'watson', 'm', 'd', 'of'], ['a', 'from', 'the', 'john', 'h', 'watson', 'm', 'd', 'of', 'the'], ['from', 'the', 'john', 'h', 'watson', 'm', 'd', 'of', 'the', 'army'], ['the', 'john', 'h', 'watson', 'm', 'd', 'of', 'the', 'army', 'medical'], ['john', 'h', 'watson', 'm', 'd', 'of', 'the', 'army', 'medical', '_'], ['h', 'watson', 'm', 'd', 'of', 'the', 'army', 'medical', '_', '2'], ['watson', 'm', 'd', 'of', 'the', 'army', 'medical', '_', '2', 'i'], ['m', 'd', 'of', 'the', 'army', 'medical', '_', '2', 'i', 'mr'], ['d', 'of', 'the', 'army', 'medical', '_', '2', 'i', 'mr', 'sherlock'], ['of', 'the', 'army', 'medical', '_', '2', 'i', 'mr', 'sherlock', 'holmes'], ['the', 'army', 'medical', '_', '2', 'i', 'mr', 'sherlock', 'holmes', 'in'], ['army', 'medical', '_', '2', 'i', 'mr', 'sherlock', 'holmes', 'in', 'the'], ['medical', '_', '2', 'i', 'mr', 'sherlock', 'holmes', 'in', 'the', 'year'], ['_', '2', 'i', 'mr', 'sherlock', 'holmes', 'in', 'the', 'year', '1878'], ['2', 'i', 'mr', 'sherlock', 'holmes', 'in', 'the', 'year', '1878', 'i'], ['i', 'mr', 'sherlock', 'holmes', 'in', 'the', 'year', '1878', 'i', 'took'], ['mr', 'sherlock', 'holmes', 'in', 'the', 'year', '1878', 'i', 'took', 'my'], ['sherlock', 'holmes', 'in', 'the', 'year', '1878', 'i', 'took', 'my', 'degree'], ['holmes', 'in', 'the', 'year', '1878', 'i', 'took', 'my', 'degree', 'of'], ['in', 'the', 'year', '1878', 'i', 'took', 'my', 'degree', 'of', 'doctor'], ['the', 'year', '1878', 'i', 'took', 'my', 'degree', 'of', 'doctor', 'of'], ['year', '1878', 'i', 'took', 'my', 'degree', 'of', 'doctor', 'of', 'of'], ['1878', 'i', 'took', 'my', 'degree', 'of', 'doctor', 'of', 'of', 'the'], ['i', 'took', 'my', 'degree', 'of', 'doctor', 'of', 'of', 'the', 'of'], ['took', 'my', 'degree', 'of', 'doctor', 'of', 'of', 'the', 'of', 'london'], ['my', 'degree', 'of', 'doctor', 'of', 'of', 'the', 'of', 'london', 'and'], ['degree', 'of', 'doctor', 'of', 'of', 'the', 'of', 'london', 'and', 'to'], ['of', 'doctor', 'of', 'of', 'the', 'of', 'london', 'and', 'to', 'to'], ['doctor', 'of', 'of', 'the', 'of', 'london', 'and', 'to', 'to', 'go'], ['of', 'of', 'the', 'of', 'london', 'and', 'to', 'to', 'go', 'through'], ['of', 'the', 'of', 'london', 'and', 'to', 'to', 'go', 'through', 'the'], ['the', 'of', 'london', 'and', 'to', 'to', 'go', 'through', 'the', 'course'], ['of', 'london', 'and', 'to', 'to', 'go', 'through', 'the', 'course', 'for'], ['london', 'and', 'to', 'to', 'go', 'through', 'the', 'course', 'for', 'in'], ['and', 'to', 'to', 'go', 'through', 'the', 'course', 'for', 'in', 'the'], ['to', 'to', 'go', 'through', 'the', 'course', 'for', 'in', 'the', 'army'], ['to', 'go', 'through', 'the', 'course', 'for', 'in', 'the', 'army', 'having'], ['go', 'through', 'the', 'course', 'for', 'in', 'the', 'army', 'having', 'completed'], ['through', 'the', 'course', 'for', 'in', 'the', 'army', 'having', 'completed', 'my'], ['the', 'course', 'for', 'in', 'the', 'army', 'having', 'completed', 'my', 'there'], ['course', 'for', 'in', 'the', 'army', 'having', 'completed', 'my', 'there', 'i'], ['for', 'in', 'the', 'army', 'having', 'completed', 'my', 'there', 'i', 'was'], ['in', 'the', 'army', 'having', 'completed', 'my', 'there', 'i', 'was', 'to'], ['the', 'army', 'having', 'completed', 'my', 'there', 'i', 'was', 'to', 'the'], ['army', 'having', 'completed', 'my', 'there', 'i', 'was', 'to', 'the', 'fifth'], ['having', 'completed', 'my', 'there', 'i', 'was', 'to', 'the', 'fifth', 'as'], ['completed', 'my', 'there', 'i', 'was', 'to', 'the', 'fifth', 'as', 'assistant'], ['my', 'there', 'i', 'was', 'to', 'the', 'fifth', 'as', 'assistant', 'surgeon'], ['there', 'i', 'was', 'to', 'the', 'fifth', 'as', 'assistant', 'surgeon', 'the'], ['i', 'was', 'to', 'the', 'fifth', 'as', 'assistant', 'surgeon', 'the', 'was'], ['was', 'to', 'the', 'fifth', 'as', 'assistant', 'surgeon', 'the', 'was', 'in'], ['to', 'the', 'fifth', 'as', 'assistant', 'surgeon', 'the', 'was', 'in', 'india'], ['the', 'fifth', 'as', 'assistant', 'surgeon', 'the', 'was', 'in', 'india', 'at'], ['fifth', 'as', 'assistant', 'surgeon', 'the', 'was', 'in', 'india', 'at', 'the'], ['as', 'assistant', 'surgeon', 'the', 'was', 'in', 'india', 'at', 'the', 'time'], ['assistant', 'surgeon', 'the', 'was', 'in', 'india', 'at', 'the', 'time', 'and'], ['surgeon', 'the', 'was', 'in', 'india', 'at', 'the', 'time', 'and', 'before'], ['the', 'was', 'in', 'india', 'at', 'the', 'time', 'and', 'before', 'i'], ['was', 'in', 'india', 'at', 'the', 'time', 'and', 'before', 'i', 'could'], ['in', 'india', 'at', 'the', 'time', 'and', 'before', 'i', 'could', 'join'], ['india', 'at', 'the', 'time', 'and', 'before', 'i', 'could', 'join', 'it'], ['at', 'the', 'time', 'and', 'before', 'i', 'could', 'join', 'it', 'the'], ['the', 'time', 'and', 'before', 'i', 'could', 'join', 'it', 'the', 'second'], ['time', 'and', 'before', 'i', 'could', 'join', 'it', 'the', 'second', 'war'], ['and', 'before', 'i', 'could', 'join', 'it', 'the', 'second', 'war', 'had'], ['before', 'i', 'could', 'join', 'it', 'the', 'second', 'war', 'had', 'broken'], ['i', 'could', 'join', 'it', 'the', 'second', 'war', 'had', 'broken', 'out'], ['could', 'join', 'it', 'the', 'second', 'war', 'had', 'broken', 'out', 'on'], ['join', 'it', 'the', 'second', 'war', 'had', 'broken', 'out', 'on', 'landing'], ['it', 'the', 'second', 'war', 'had', 'broken', 'out', 'on', 'landing', 'at'], ['the', 'second', 'war', 'had', 'broken', 'out', 'on', 'landing', 'at', 'i'], ['second', 'war', 'had', 'broken', 'out', 'on', 'landing', 'at', 'i', 'learned'], ['war', 'had', 'broken', 'out', 'on', 'landing', 'at', 'i', 'learned', 'that'], ['had', 'broken', 'out', 'on', 'landing', 'at', 'i', 'learned', 'that', 'my'], ['broken', 'out', 'on', 'landing', 'at', 'i', 'learned', 'that', 'my', 'had'], ['out', 'on', 'landing', 'at', 'i', 'learned', 'that', 'my', 'had', 'through'], ['on', 'landing', 'at', 'i', 'learned', 'that', 'my', 'had', 'through', 'the'], ['landing', 'at', 'i', 'learned', 'that', 'my', 'had', 'through', 'the', 'and'], ['at', 'i', 'learned', 'that', 'my', 'had', 'through', 'the', 'and', 'was'], ['i', 'learned', 'that', 'my', 'had', 'through', 'the', 'and', 'was', 'already'], ['learned', 'that', 'my', 'had', 'through', 'the', 'and', 'was', 'already', 'deep'], ['that', 'my', 'had', 'through', 'the', 'and', 'was', 'already', 'deep', 'in'], ['my', 'had', 'through', 'the', 'and', 'was', 'already', 'deep', 'in', 'the'], ['had', 'through', 'the', 'and', 'was', 'already', 'deep', 'in', 'the', 'enemy'], ['through', 'the', 'and', 'was', 'already', 'deep', 'in', 'the', 'enemy', 's'], ['the', 'and', 'was', 'already', 'deep', 'in', 'the', 'enemy', 's', 'country'], ['and', 'was', 'already', 'deep', 'in', 'the', 'enemy', 's', 'country', 'i'], ['was', 'already', 'deep', 'in', 'the', 'enemy', 's', 'country', 'i', 'followed'], ['already', 'deep', 'in', 'the', 'enemy', 's', 'country', 'i', 'followed', 'however'], ['deep', 'in', 'the', 'enemy', 's', 'country', 'i', 'followed', 'however', 'with'], ['in', 'the', 'enemy', 's', 'country', 'i', 'followed', 'however', 'with', 'many'], ['the', 'enemy', 's', 'country', 'i', 'followed', 'however', 'with', 'many', 'other'], ['enemy', 's', 'country', 'i', 'followed', 'however', 'with', 'many', 'other', 'officers'], ['s', 'country', 'i', 'followed', 'however', 'with', 'many', 'other', 'officers', 'who'], ['country', 'i', 'followed', 'however', 'with', 'many', 'other', 'officers', 'who', 'were'], ['i', 'followed', 'however', 'with', 'many', 'other', 'officers', 'who', 'were', 'in'], ['followed', 'however', 'with', 'many', 'other', 'officers', 'who', 'were', 'in', 'the'], ['however', 'with', 'many', 'other', 'officers', 'who', 'were', 'in', 'the', 'same'], ['with', 'many', 'other', 'officers', 'who', 'were', 'in', 'the', 'same', 'situation'], ['many', 'other', 'officers', 'who', 'were', 'in', 'the', 'same', 'situation', 'as'], ['other', 'officers', 'who', 'were', 'in', 'the', 'same', 'situation', 'as', 'myself'], ['officers', 'who', 'were', 'in', 'the', 'same', 'situation', 'as', 'myself', 'and'], ['who', 'were', 'in', 'the', 'same', 'situation', 'as', 'myself', 'and', 'succeeded'], ['were', 'in', 'the', 'same', 'situation', 'as', 'myself', 'and', 'succeeded', 'in'], ['in', 'the', 'same', 'situation', 'as', 'myself', 'and', 'succeeded', 'in', 'in'], ['the', 'same', 'situation', 'as', 'myself', 'and', 'succeeded', 'in', 'in', 'safety'], ['same', 'situation', 'as', 'myself', 'and', 'succeeded', 'in', 'in', 'safety', 'where'], ['situation', 'as', 'myself', 'and', 'succeeded', 'in', 'in', 'safety', 'where', 'i'], ['as', 'myself', 'and', 'succeeded', 'in', 'in', 'safety', 'where', 'i', 'found'], ['myself', 'and', 'succeeded', 'in', 'in', 'safety', 'where', 'i', 'found', 'my'], ['and', 'succeeded', 'in', 'in', 'safety', 'where', 'i', 'found', 'my', 'and'], ['succeeded', 'in', 'in', 'safety', 'where', 'i', 'found', 'my', 'and', 'at'], ['in', 'in', 'safety', 'where', 'i', 'found', 'my', 'and', 'at', 'once'], ['in', 'safety', 'where', 'i', 'found', 'my', 'and', 'at', 'once', 'entered'], ['safety', 'where', 'i', 'found', 'my', 'and', 'at', 'once', 'entered', 'upon'], ['where', 'i', 'found', 'my', 'and', 'at', 'once', 'entered', 'upon', 'my'], ['i', 'found', 'my', 'and', 'at', 'once', 'entered', 'upon', 'my', 'new'], ['found', 'my', 'and', 'at', 'once', 'entered', 'upon', 'my', 'new', 'duties'], ['my', 'and', 'at', 'once', 'entered', 'upon', 'my', 'new', 'duties', 'the'], ['and', 'at', 'once', 'entered', 'upon', 'my', 'new', 'duties', 'the', 'campaign'], ['at', 'once', 'entered', 'upon', 'my', 'new', 'duties', 'the', 'campaign', 'brought'], ['once', 'entered', 'upon', 'my', 'new', 'duties', 'the', 'campaign', 'brought', 'and'], ['entered', 'upon', 'my', 'new', 'duties', 'the', 'campaign', 'brought', 'and', 'to'], ['upon', 'my', 'new', 'duties', 'the', 'campaign', 'brought', 'and', 'to', 'many'], ['my', 'new', 'duties', 'the', 'campaign', 'brought', 'and', 'to', 'many', 'but'], ['new', 'duties', 'the', 'campaign', 'brought', 'and', 'to', 'many', 'but', 'for'], ['duties', 'the', 'campaign', 'brought', 'and', 'to', 'many', 'but', 'for', 'me'], ['the', 'campaign', 'brought', 'and', 'to', 'many', 'but', 'for', 'me', 'it'], ['campaign', 'brought', 'and', 'to', 'many', 'but', 'for', 'me', 'it', 'had'], ['brought', 'and', 'to', 'many', 'but', 'for', 'me', 'it', 'had', 'nothing'], ['and', 'to', 'many', 'but', 'for', 'me', 'it', 'had', 'nothing', 'but'], ['to', 'many', 'but', 'for', 'me', 'it', 'had', 'nothing', 'but', 'misfortune'], ['many', 'but', 'for', 'me', 'it', 'had', 'nothing', 'but', 'misfortune', 'and'], ['but', 'for', 'me', 'it', 'had', 'nothing', 'but', 'misfortune', 'and', 'i'], ['for', 'me', 'it', 'had', 'nothing', 'but', 'misfortune', 'and', 'i', 'was'], ['me', 'it', 'had', 'nothing', 'but', 'misfortune', 'and', 'i', 'was', 'removed'], ['it', 'had', 'nothing', 'but', 'misfortune', 'and', 'i', 'was', 'removed', 'from'], ['had', 'nothing', 'but', 'misfortune', 'and', 'i', 'was', 'removed', 'from', 'my'], ['nothing', 'but', 'misfortune', 'and', 'i', 'was', 'removed', 'from', 'my', 'and'], ['but', 'misfortune', 'and', 'i', 'was', 'removed', 'from', 'my', 'and', 'to'], ['misfortune', 'and', 'i', 'was', 'removed', 'from', 'my', 'and', 'to', 'the'], ['and', 'i', 'was', 'removed', 'from', 'my', 'and', 'to', 'the', 'with'], ['i', 'was', 'removed', 'from', 'my', 'and', 'to', 'the', 'with', 'whom'], ['was', 'removed', 'from', 'my', 'and', 'to', 'the', 'with', 'whom', 'i'], ['removed', 'from', 'my', 'and', 'to', 'the', 'with', 'whom', 'i', 'served'], ['from', 'my', 'and', 'to', 'the', 'with', 'whom', 'i', 'served', 'at'], ['my', 'and', 'to', 'the', 'with', 'whom', 'i', 'served', 'at', 'the'], ['and', 'to', 'the', 'with', 'whom', 'i', 'served', 'at', 'the', 'fatal'], ['to', 'the', 'with', 'whom', 'i', 'served', 'at', 'the', 'fatal', 'of'], ['the', 'with', 'whom', 'i', 'served', 'at', 'the', 'fatal', 'of', 'there'], ['with', 'whom', 'i', 'served', 'at', 'the', 'fatal', 'of', 'there', 'i'], ['whom', 'i', 'served', 'at', 'the', 'fatal', 'of', 'there', 'i', 'was'], ['i', 'served', 'at', 'the', 'fatal', 'of', 'there', 'i', 'was', 'struck'], ['served', 'at', 'the', 'fatal', 'of', 'there', 'i', 'was', 'struck', 'on'], ['at', 'the', 'fatal', 'of', 'there', 'i', 'was', 'struck', 'on', 'the'], ['the', 'fatal', 'of', 'there', 'i', 'was', 'struck', 'on', 'the', 'shoulder'], ['fatal', 'of', 'there', 'i', 'was', 'struck', 'on', 'the', 'shoulder', 'by'], ['of', 'there', 'i', 'was', 'struck', 'on', 'the', 'shoulder', 'by', 'a'], ['there', 'i', 'was', 'struck', 'on', 'the', 'shoulder', 'by', 'a', 'which'], ['i', 'was', 'struck', 'on', 'the', 'shoulder', 'by', 'a', 'which', 'shattered'], ['was', 'struck', 'on', 'the', 'shoulder', 'by', 'a', 'which', 'shattered', 'the'], ['struck', 'on', 'the', 'shoulder', 'by', 'a', 'which', 'shattered', 'the', 'bone'], ['on', 'the', 'shoulder', 'by', 'a', 'which', 'shattered', 'the', 'bone', 'and'], ['the', 'shoulder', 'by', 'a', 'which', 'shattered', 'the', 'bone', 'and', 'the'], ['shoulder', 'by', 'a', 'which', 'shattered', 'the', 'bone', 'and', 'the', 'i'], ['by', 'a', 'which', 'shattered', 'the', 'bone', 'and', 'the', 'i', 'should'], ['a', 'which', 'shattered', 'the', 'bone', 'and', 'the', 'i', 'should', 'have'], ['which', 'shattered', 'the', 'bone', 'and', 'the', 'i', 'should', 'have', 'fallen'], ['shattered', 'the', 'bone', 'and', 'the', 'i', 'should', 'have', 'fallen', 'into'], ['the', 'bone', 'and', 'the', 'i', 'should', 'have', 'fallen', 'into', 'the'], ['bone', 'and', 'the', 'i', 'should', 'have', 'fallen', 'into', 'the', 'hands'], ['and', 'the', 'i', 'should', 'have', 'fallen', 'into', 'the', 'hands', 'of'], ['the', 'i', 'should', 'have', 'fallen', 'into', 'the', 'hands', 'of', 'the'], ['i', 'should', 'have', 'fallen', 'into', 'the', 'hands', 'of', 'the', 'had'], ['should', 'have', 'fallen', 'into', 'the', 'hands', 'of', 'the', 'had', 'it'], ['have', 'fallen', 'into', 'the', 'hands', 'of', 'the', 'had', 'it', 'not'], ['fallen', 'into', 'the', 'hands', 'of', 'the', 'had', 'it', 'not', 'been'], ['into', 'the', 'hands', 'of', 'the', 'had', 'it', 'not', 'been', 'for'], ['the', 'hands', 'of', 'the', 'had', 'it', 'not', 'been', 'for', 'the'], ['hands', 'of', 'the', 'had', 'it', 'not', 'been', 'for', 'the', 'and'], ['of', 'the', 'had', 'it', 'not', 'been', 'for', 'the', 'and', 'courage'], ['the', 'had', 'it', 'not', 'been', 'for', 'the', 'and', 'courage', 'shown'], ['had', 'it', 'not', 'been', 'for', 'the', 'and', 'courage', 'shown', 'by'], ['it', 'not', 'been', 'for', 'the', 'and', 'courage', 'shown', 'by', 'my'], ['not', 'been', 'for', 'the', 'and', 'courage', 'shown', 'by', 'my', 'who'], ['been', 'for', 'the', 'and', 'courage', 'shown', 'by', 'my', 'who', 'threw'], ['for', 'the', 'and', 'courage', 'shown', 'by', 'my', 'who', 'threw', 'me'], ['the', 'and', 'courage', 'shown', 'by', 'my', 'who', 'threw', 'me', 'across'], ['and', 'courage', 'shown', 'by', 'my', 'who', 'threw', 'me', 'across', 'a'], ['courage', 'shown', 'by', 'my', 'who', 'threw', 'me', 'across', 'a', 'pack'], ['shown', 'by', 'my', 'who', 'threw', 'me', 'across', 'a', 'pack', 'and'], ['by', 'my', 'who', 'threw', 'me', 'across', 'a', 'pack', 'and', 'succeeded'], ['my', 'who', 'threw', 'me', 'across', 'a', 'pack', 'and', 'succeeded', 'in'], ['who', 'threw', 'me', 'across', 'a', 'pack', 'and', 'succeeded', 'in', 'bringing'], ['threw', 'me', 'across', 'a', 'pack', 'and', 'succeeded', 'in', 'bringing', 'me'], ['me', 'across', 'a', 'pack', 'and', 'succeeded', 'in', 'bringing', 'me', 'safely'], ['across', 'a', 'pack', 'and', 'succeeded', 'in', 'bringing', 'me', 'safely', 'to'], ['a', 'pack', 'and', 'succeeded', 'in', 'bringing', 'me', 'safely', 'to', 'the'], ['pack', 'and', 'succeeded', 'in', 'bringing', 'me', 'safely', 'to', 'the', 'british'], ['and', 'succeeded', 'in', 'bringing', 'me', 'safely', 'to', 'the', 'british', 'lines'], ['succeeded', 'in', 'bringing', 'me', 'safely', 'to', 'the', 'british', 'lines', 'worn'], ['in', 'bringing', 'me', 'safely', 'to', 'the', 'british', 'lines', 'worn', 'with'], ['bringing', 'me', 'safely', 'to', 'the', 'british', 'lines', 'worn', 'with', 'pain'], ['me', 'safely', 'to', 'the', 'british', 'lines', 'worn', 'with', 'pain', 'and'], ['safely', 'to', 'the', 'british', 'lines', 'worn', 'with', 'pain', 'and', 'weak'], ['to', 'the', 'british', 'lines', 'worn', 'with', 'pain', 'and', 'weak', 'from'], ['the', 'british', 'lines', 'worn', 'with', 'pain', 'and', 'weak', 'from', 'the'], ['british', 'lines', 'worn', 'with', 'pain', 'and', 'weak', 'from', 'the', 'which'], ['lines', 'worn', 'with', 'pain', 'and', 'weak', 'from', 'the', 'which', 'i'], ['worn', 'with', 'pain', 'and', 'weak', 'from', 'the', 'which', 'i', 'had'], ['with', 'pain', 'and', 'weak', 'from', 'the', 'which', 'i', 'had', 'i'], ['pain', 'and', 'weak', 'from', 'the', 'which', 'i', 'had', 'i', 'was'], ['and', 'weak', 'from', 'the', 'which', 'i', 'had', 'i', 'was', 'removed'], ['weak', 'from', 'the', 'which', 'i', 'had', 'i', 'was', 'removed', 'with'], ['from', 'the', 'which', 'i', 'had', 'i', 'was', 'removed', 'with', 'a'], ['the', 'which', 'i', 'had', 'i', 'was', 'removed', 'with', 'a', 'great'], ['which', 'i', 'had', 'i', 'was', 'removed', 'with', 'a', 'great', 'train'], ['i', 'had', 'i', 'was', 'removed', 'with', 'a', 'great', 'train', 'of'], ['had', 'i', 'was', 'removed', 'with', 'a', 'great', 'train', 'of', 'to'], ['i', 'was', 'removed', 'with', 'a', 'great', 'train', 'of', 'to', 'the'], ['was', 'removed', 'with', 'a', 'great', 'train', 'of', 'to', 'the', 'hospital'], ['removed', 'with', 'a', 'great', 'train', 'of', 'to', 'the', 'hospital', 'at'], ['with', 'a', 'great', 'train', 'of', 'to', 'the', 'hospital', 'at', 'here'], ['a', 'great', 'train', 'of', 'to', 'the', 'hospital', 'at', 'here', 'i'], ['great', 'train', 'of', 'to', 'the', 'hospital', 'at', 'here', 'i', 'and'], ['train', 'of', 'to', 'the', 'hospital', 'at', 'here', 'i', 'and', 'had'], ['of', 'to', 'the', 'hospital', 'at', 'here', 'i', 'and', 'had', 'already'], ['to', 'the', 'hospital', 'at', 'here', 'i', 'and', 'had', 'already', 'so'], ['the', 'hospital', 'at', 'here', 'i', 'and', 'had', 'already', 'so', 'far'], ['hospital', 'at', 'here', 'i', 'and', 'had', 'already', 'so', 'far', 'as'], ['at', 'here', 'i', 'and', 'had', 'already', 'so', 'far', 'as', 'to'], ['here', 'i', 'and', 'had', 'already', 'so', 'far', 'as', 'to', 'be'], ['i', 'and', 'had', 'already', 'so', 'far', 'as', 'to', 'be', 'able'], ['and', 'had', 'already', 'so', 'far', 'as', 'to', 'be', 'able', 'to'], ['had', 'already', 'so', 'far', 'as', 'to', 'be', 'able', 'to', 'walk'], ['already', 'so', 'far', 'as', 'to', 'be', 'able', 'to', 'walk', 'about'], ['so', 'far', 'as', 'to', 'be', 'able', 'to', 'walk', 'about', 'the'], ['far', 'as', 'to', 'be', 'able', 'to', 'walk', 'about', 'the', 'and'], ['as', 'to', 'be', 'able', 'to', 'walk', 'about', 'the', 'and', 'even'], ['to', 'be', 'able', 'to', 'walk', 'about', 'the', 'and', 'even', 'to'], ['be', 'able', 'to', 'walk', 'about', 'the', 'and', 'even', 'to', 'a'], ['able', 'to', 'walk', 'about', 'the', 'and', 'even', 'to', 'a', 'little'], ['to', 'walk', 'about', 'the', 'and', 'even', 'to', 'a', 'little', 'upon'], ['walk', 'about', 'the', 'and', 'even', 'to', 'a', 'little', 'upon', 'the'], ['about', 'the', 'and', 'even', 'to', 'a', 'little', 'upon', 'the', 'when'], ['the', 'and', 'even', 'to', 'a', 'little', 'upon', 'the', 'when', 'i'], ['and', 'even', 'to', 'a', 'little', 'upon', 'the', 'when', 'i', 'was'], ['even', 'to', 'a', 'little', 'upon', 'the', 'when', 'i', 'was', 'struck'], ['to', 'a', 'little', 'upon', 'the', 'when', 'i', 'was', 'struck', 'down'], ['a', 'little', 'upon', 'the', 'when', 'i', 'was', 'struck', 'down', 'by'], ['little', 'upon', 'the', 'when', 'i', 'was', 'struck', 'down', 'by', 'that'], ['upon', 'the', 'when', 'i', 'was', 'struck', 'down', 'by', 'that', 'curse'], ['the', 'when', 'i', 'was', 'struck', 'down', 'by', 'that', 'curse', 'of'], ['when', 'i', 'was', 'struck', 'down', 'by', 'that', 'curse', 'of', 'our'], ['i', 'was', 'struck', 'down', 'by', 'that', 'curse', 'of', 'our', 'indian'], ['was', 'struck', 'down', 'by', 'that', 'curse', 'of', 'our', 'indian', 'for'], ['struck', 'down', 'by', 'that', 'curse', 'of', 'our', 'indian', 'for', 'months'], ['down', 'by', 'that', 'curse', 'of', 'our', 'indian', 'for', 'months', 'my'], ['by', 'that', 'curse', 'of', 'our', 'indian', 'for', 'months', 'my', 'life'], ['that', 'curse', 'of', 'our', 'indian', 'for', 'months', 'my', 'life', 'was'], ['curse', 'of', 'our', 'indian', 'for', 'months', 'my', 'life', 'was', 'despaired'], ['of', 'our', 'indian', 'for', 'months', 'my', 'life', 'was', 'despaired', 'of'], ['our', 'indian', 'for', 'months', 'my', 'life', 'was', 'despaired', 'of', 'and'], ['indian', 'for', 'months', 'my', 'life', 'was', 'despaired', 'of', 'and', 'when'], ['for', 'months', 'my', 'life', 'was', 'despaired', 'of', 'and', 'when', 'at'], ['months', 'my', 'life', 'was', 'despaired', 'of', 'and', 'when', 'at', 'last'], ['my', 'life', 'was', 'despaired', 'of', 'and', 'when', 'at', 'last', 'i'], ['life', 'was', 'despaired', 'of', 'and', 'when', 'at', 'last', 'i', 'came'], ['was', 'despaired', 'of', 'and', 'when', 'at', 'last', 'i', 'came', 'to'], ['despaired', 'of', 'and', 'when', 'at', 'last', 'i', 'came', 'to', 'myself'], ['of', 'and', 'when', 'at', 'last', 'i', 'came', 'to', 'myself', 'and'], ['and', 'when', 'at', 'last', 'i', 'came', 'to', 'myself', 'and', 'became'], ['when', 'at', 'last', 'i', 'came', 'to', 'myself', 'and', 'became', 'i'], ['at', 'last', 'i', 'came', 'to', 'myself', 'and', 'became', 'i', 'was'], ['last', 'i', 'came', 'to', 'myself', 'and', 'became', 'i', 'was', 'so'], ['i', 'came', 'to', 'myself', 'and', 'became', 'i', 'was', 'so', 'weak'], ['came', 'to', 'myself', 'and', 'became', 'i', 'was', 'so', 'weak', 'and'], ['to', 'myself', 'and', 'became', 'i', 'was', 'so', 'weak', 'and', 'that'], ['myself', 'and', 'became', 'i', 'was', 'so', 'weak', 'and', 'that', 'a'], ['and', 'became', 'i', 'was', 'so', 'weak', 'and', 'that', 'a', 'medical'], ['became', 'i', 'was', 'so', 'weak', 'and', 'that', 'a', 'medical', 'board'], ['i', 'was', 'so', 'weak', 'and', 'that', 'a', 'medical', 'board', 'determined'], ['was', 'so', 'weak', 'and', 'that', 'a', 'medical', 'board', 'determined', 'that'], ['so', 'weak', 'and', 'that', 'a', 'medical', 'board', 'determined', 'that', 'not'], ['weak', 'and', 'that', 'a', 'medical', 'board', 'determined', 'that', 'not', 'a'], ['and', 'that', 'a', 'medical', 'board', 'determined', 'that', 'not', 'a', 'day'], ['that', 'a', 'medical', 'board', 'determined', 'that', 'not', 'a', 'day', 'should'], ['a', 'medical', 'board', 'determined', 'that', 'not', 'a', 'day', 'should', 'be'], ['medical', 'board', 'determined', 'that', 'not', 'a', 'day', 'should', 'be', 'lost'], ['board', 'determined', 'that', 'not', 'a', 'day', 'should', 'be', 'lost', 'in'], ['determined', 'that', 'not', 'a', 'day', 'should', 'be', 'lost', 'in', 'me'], ['that', 'not', 'a', 'day', 'should', 'be', 'lost', 'in', 'me', 'back'], ['not', 'a', 'day', 'should', 'be', 'lost', 'in', 'me', 'back', 'to'], ['a', 'day', 'should', 'be', 'lost', 'in', 'me', 'back', 'to', 'england'], ['day', 'should', 'be', 'lost', 'in', 'me', 'back', 'to', 'england', 'i'], ['should', 'be', 'lost', 'in', 'me', 'back', 'to', 'england', 'i', 'was'], ['be', 'lost', 'in', 'me', 'back', 'to', 'england', 'i', 'was', 'in'], ['lost', 'in', 'me', 'back', 'to', 'england', 'i', 'was', 'in', 'the'], ['in', 'me', 'back', 'to', 'england', 'i', 'was', 'in', 'the', 'and'], ['me', 'back', 'to', 'england', 'i', 'was', 'in', 'the', 'and', 'landed'], ['back', 'to', 'england', 'i', 'was', 'in', 'the', 'and', 'landed', 'a'], ['to', 'england', 'i', 'was', 'in', 'the', 'and', 'landed', 'a', 'month'], ['england', 'i', 'was', 'in', 'the', 'and', 'landed', 'a', 'month', 'later'], ['i', 'was', 'in', 'the', 'and', 'landed', 'a', 'month', 'later', 'on'], ['was', 'in', 'the', 'and', 'landed', 'a', 'month', 'later', 'on', 'with'], ['in', 'the', 'and', 'landed', 'a', 'month', 'later', 'on', 'with', 'my'], ['the', 'and', 'landed', 'a', 'month', 'later', 'on', 'with', 'my', 'health'], ['and', 'landed', 'a', 'month', 'later', 'on', 'with', 'my', 'health', 'but'], ['landed', 'a', 'month', 'later', 'on', 'with', 'my', 'health', 'but', 'with'], ['a', 'month', 'later', 'on', 'with', 'my', 'health', 'but', 'with', 'from'], ['month', 'later', 'on', 'with', 'my', 'health', 'but', 'with', 'from', 'a'], ['later', 'on', 'with', 'my', 'health', 'but', 'with', 'from', 'a', 'government'], ['on', 'with', 'my', 'health', 'but', 'with', 'from', 'a', 'government', 'to'], ['with', 'my', 'health', 'but', 'with', 'from', 'a', 'government', 'to', 'spend'], ['my', 'health', 'but', 'with', 'from', 'a', 'government', 'to', 'spend', 'the'], ['health', 'but', 'with', 'from', 'a', 'government', 'to', 'spend', 'the', 'next'], ['but', 'with', 'from', 'a', 'government', 'to', 'spend', 'the', 'next', 'nine'], ['with', 'from', 'a', 'government', 'to', 'spend', 'the', 'next', 'nine', 'months'], ['from', 'a', 'government', 'to', 'spend', 'the', 'next', 'nine', 'months', 'in'], ['a', 'government', 'to', 'spend', 'the', 'next', 'nine', 'months', 'in', 'to'], ['government', 'to', 'spend', 'the', 'next', 'nine', 'months', 'in', 'to', 'it'], ['to', 'spend', 'the', 'next', 'nine', 'months', 'in', 'to', 'it', 'i'], ['spend', 'the', 'next', 'nine', 'months', 'in', 'to', 'it', 'i', 'had'], ['the', 'next', 'nine', 'months', 'in', 'to', 'it', 'i', 'had', 'neither'], ['next', 'nine', 'months', 'in', 'to', 'it', 'i', 'had', 'neither', 'nor'], ['nine', 'months', 'in', 'to', 'it', 'i', 'had', 'neither', 'nor', 'in'], ['months', 'in', 'to', 'it', 'i', 'had', 'neither', 'nor', 'in', 'england'], ['in', 'to', 'it', 'i', 'had', 'neither', 'nor', 'in', 'england', 'and'], ['to', 'it', 'i', 'had', 'neither', 'nor', 'in', 'england', 'and', 'was'], ['it', 'i', 'had', 'neither', 'nor', 'in', 'england', 'and', 'was', 'therefore'], ['i', 'had', 'neither', 'nor', 'in', 'england', 'and', 'was', 'therefore', 'as'], ['had', 'neither', 'nor', 'in', 'england', 'and', 'was', 'therefore', 'as', 'free'], ['neither', 'nor', 'in', 'england', 'and', 'was', 'therefore', 'as', 'free', 'as'], ['nor', 'in', 'england', 'and', 'was', 'therefore', 'as', 'free', 'as', 'air'], ['in', 'england', 'and', 'was', 'therefore', 'as', 'free', 'as', 'air', 'or'], ['england', 'and', 'was', 'therefore', 'as', 'free', 'as', 'air', 'or', 'as'], ['and', 'was', 'therefore', 'as', 'free', 'as', 'air', 'or', 'as', 'free'], ['was', 'therefore', 'as', 'free', 'as', 'air', 'or', 'as', 'free', 'as'], ['therefore', 'as', 'free', 'as', 'air', 'or', 'as', 'free', 'as', 'an'], ['as', 'free', 'as', 'air', 'or', 'as', 'free', 'as', 'an', 'income'], ['free', 'as', 'air', 'or', 'as', 'free', 'as', 'an', 'income', 'of'], ['as', 'air', 'or', 'as', 'free', 'as', 'an', 'income', 'of', 'eleven'], ['air', 'or', 'as', 'free', 'as', 'an', 'income', 'of', 'eleven', 'and'], ['or', 'as', 'free', 'as', 'an', 'income', 'of', 'eleven', 'and', 'a'], ['as', 'free', 'as', 'an', 'income', 'of', 'eleven', 'and', 'a', 'day'], ['free', 'as', 'an', 'income', 'of', 'eleven', 'and', 'a', 'day', 'will'], ['as', 'an', 'income', 'of', 'eleven', 'and', 'a', 'day', 'will', 'permit'], ['an', 'income', 'of', 'eleven', 'and', 'a', 'day', 'will', 'permit', 'a'], ['income', 'of', 'eleven', 'and', 'a', 'day', 'will', 'permit', 'a', 'man'], ['of', 'eleven', 'and', 'a', 'day', 'will', 'permit', 'a', 'man', 'to'], ['eleven', 'and', 'a', 'day', 'will', 'permit', 'a', 'man', 'to', 'be'], ['and', 'a', 'day', 'will', 'permit', 'a', 'man', 'to', 'be', 'under'], ['a', 'day', 'will', 'permit', 'a', 'man', 'to', 'be', 'under', 'such'], ['day', 'will', 'permit', 'a', 'man', 'to', 'be', 'under', 'such', 'circumstances'], ['will', 'permit', 'a', 'man', 'to', 'be', 'under', 'such', 'circumstances', 'i'], ['permit', 'a', 'man', 'to', 'be', 'under', 'such', 'circumstances', 'i', 'naturally'], ['a', 'man', 'to', 'be', 'under', 'such', 'circumstances', 'i', 'naturally', 'to'], ['man', 'to', 'be', 'under', 'such', 'circumstances', 'i', 'naturally', 'to', 'london'], ['to', 'be', 'under', 'such', 'circumstances', 'i', 'naturally', 'to', 'london', 'that'], ['be', 'under', 'such', 'circumstances', 'i', 'naturally', 'to', 'london', 'that', 'great'], ['under', 'such', 'circumstances', 'i', 'naturally', 'to', 'london', 'that', 'great', 'into'], ['such', 'circumstances', 'i', 'naturally', 'to', 'london', 'that', 'great', 'into', 'which'], ['circumstances', 'i', 'naturally', 'to', 'london', 'that', 'great', 'into', 'which', 'all'], ['i', 'naturally', 'to', 'london', 'that', 'great', 'into', 'which', 'all', 'the'], ['naturally', 'to', 'london', 'that', 'great', 'into', 'which', 'all', 'the', 'loungers'], ['to', 'london', 'that', 'great', 'into', 'which', 'all', 'the', 'loungers', 'and'], ['london', 'that', 'great', 'into', 'which', 'all', 'the', 'loungers', 'and', 'of'], ['that', 'great', 'into', 'which', 'all', 'the', 'loungers', 'and', 'of', 'the'], ['great', 'into', 'which', 'all', 'the', 'loungers', 'and', 'of', 'the', 'are'], ['into', 'which', 'all', 'the', 'loungers', 'and', 'of', 'the', 'are', 'there'], ['which', 'all', 'the', 'loungers', 'and', 'of', 'the', 'are', 'there', 'i']]\n"
     ]
    }
   ],
   "source": [
    "print(len(text2))\n",
    "print(SEQLEN)\n",
    "text2_new = text2[:500]\n",
    "test_words1 = []\n",
    "test_labels1 = []\n",
    "for i in range(0, len(text2_new) - SEQLEN, STEP):\n",
    "    test_words1.append(text2_new[i:i + SEQLEN])\n",
    "    #print(test_words1)\n",
    "    test_labels1.append(text2_new[i + SEQLEN])\n",
    "print(test_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(probs):\n",
    "    logsum = 0\n",
    "    for prob in probs:\n",
    "        log_prob = math.log2(prob)\n",
    "        logsum += log_prob\n",
    "    l = logsum/len(probs)\n",
    "    perplex = math.pow(2, -1)\n",
    "    return perplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    example = []\n",
    "    for i in range(len(test_words)):\n",
    "        probs = []\n",
    "        test_input = test_words[i]\n",
    "        #print(test_input)\n",
    "        test_l = test_labels[i]\n",
    "        test_s = np.zeros((1, SEQLEN))\n",
    "        for k, word in enumerate(test_input):\n",
    "            #print('k= ', k)\n",
    "            #print('word= ', word)\n",
    "            test_s[0, k] = word2index[word]\n",
    "        pred = model.predict(test_s, verbose = 0)[0]\n",
    "        prob = pred[word2index[test_l]]\n",
    "        probs.append(prob)\n",
    "    perplex = perplexity(probs)\n",
    "    return perplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "evaluation = eval_model(RNNmodel)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_text(model):\n",
    "    start_ind = np.random.randint(len(test_words))\n",
    "    test_input = test_words[start_ind]\n",
    "    \n",
    "    for ind in range(150):\n",
    "        test_s = np.zeros((1, SEQLEN))\n",
    "        for w, word in enumerate(test_input):\n",
    "            test_s[0, w] = word2index[word]\n",
    "        pred = model.predict(test_s, verbose=0)[0]\n",
    "        v = []\n",
    "        for i in range(5):\n",
    "            max_ind = np.argmax(pred)\n",
    "            pred_w = index2word[max_ind]\n",
    "            v.append(pred_w)\n",
    "            pred[max_ind] = 0\n",
    "        new_word = random.choice(v)\n",
    "        print(new_word, end=' ')\n",
    "        test_input = test_input[1:] + [new_word]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a he said holmes had the of of a one of he was in up that he could about him and his father is not a one which he and there s no he had the from the that it was the other other man to do not a are of the it but she was to think it of a little of my but we is in the more when we had in a in this some of us in it in a little of i with the but what are was mr for you not see no holmes i up that i could the it then not have come out for it s and in one that his will you had been upon the she s but we have a him and i did in that of it for you which you have had a a man for \n"
     ]
    }
   ],
   "source": [
    "gen_text = generate_text(RNNmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Embedding 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(Embedding(nb_words, 100, input_length=SEQLEN))\n",
    "RNNmodel.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_words),\n",
    "                    unroll=True))\n",
    "RNNmodel.add(Dense(nb_words))\n",
    "RNNmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "RNNmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 36s 814us/step - loss: 6.3310 - acc: 0.0628\n",
      "Generating from seed: \n",
      "thought he might prove useful so i just ordered him \n",
      "\n",
      "thought he might prove useful so i just ordered him to the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 36s 805us/step - loss: 5.9158 - acc: 0.0952\n",
      "Generating from seed: \n",
      "by way of the woods to the boscombe pool it \n",
      "\n",
      "by way of the woods to the boscombe pool it is a little man of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door \n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 35s 779us/step - loss: 5.7380 - acc: 0.1138\n",
      "Generating from seed: \n",
      "with what you earn into the bargain you no doubt \n",
      "\n",
      "with what you earn into the bargain you no doubt i have been to be that i have not be to me that i have not be to be that i have been been to be him and i have been to be that i have been been to me that i have not be to be that i have been been to be him and i have been to be that i have been been to me that i have not be to be that i have been been to be him and i have been to be that i have been been to me that i have not \n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 32s 713us/step - loss: 5.6046 - acc: 0.1262\n",
      "Generating from seed: \n",
      "with but cooee is a distinctly australian cry and one \n",
      "\n",
      "with but cooee is a distinctly australian cry and one of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the other was of the other of the \n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 31s 703us/step - loss: 5.4800 - acc: 0.1383\n",
      "Generating from seed: \n",
      "sholtos but have you i asked formed any definite conception \n",
      "\n",
      "sholtos but have you i asked formed any definite conception and to the case of the case of the case of the time of the case of the door of the door of the door was the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door of the door \n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 43s 967us/step - loss: 5.3567 - acc: 0.15140s - loss: 5.3570 - acc: 0.151\n",
      "Generating from seed: \n",
      "it is just possible that it may be of some \n",
      "\n",
      "it is just possible that it may be of some of the case and the is of a man who is a man man to the man and he had a very man who is a very man to be the very man to be the man had been in the very man and the man was a very man to be the man had a very man man to the man of his own own man who was a very man to be the man had been a man man who was a very man and he was a very man man who was a very man man and \n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 33s 752us/step - loss: 5.2415 - acc: 0.1661\n",
      "Generating from seed: \n",
      "a word spoken but with a kindly eye he waved \n",
      "\n",
      "a word spoken but with a kindly eye he waved a little of his own little or man and i was a man and he had been a man and he was a man and a man was a man and a man was in his own as a man was of the house of the floor in the other is a very man and i am not to be a man and i am not be a man but i am not be a man but i am not be a man but i am not be a man but i am not be a man but i am \n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 43s 961us/step - loss: 5.1318 - acc: 0.181910s - loss: 5.0823 - acc - ETA:   - ETA: 7s - l - ETA: - ETA: 1s - loss: 5.1249 - acc: 0. - ETA: 1s - loss: 5.\n",
      "Generating from seed: \n",
      "while holmes who loathed every form of society with his \n",
      "\n",
      "while holmes who loathed every form of society with his chair and his father was a man and a man was very to be a man and i had a man of the man who had been in the other was a man of his own eyes was a little of a man s is it is a very man and i have a little of the man who had been been in a man s a man was a man and a man was in his own as he was a man who had been his father had been in his own or and i had been to be \n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 46s 1ms/step - loss: 5.0361 - acc: 0.1942TA: 2s - loss: 5.0304 - acc: 0 - ETA:\n",
      "Generating from seed: \n",
      "we might expect it ran if i remember right sent \n",
      "\n",
      "we might expect it ran if i remember right sent the little of me you have been you to be your father for the matter the is of a man s he had not a man and with his face and his father was a man and a man and was his face and his his face was his father was a very man and he was a man of a man and he was a man who was a very of his own man and he was not be a man and then he would be a man and i was a man and he had been in his \n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 47s 1ms/step - loss: 4.9703 - acc: 0.2108: 1s -  - ETA: 0s - loss: 4.9685 - acc: 0.2\n",
      "Generating from seed: \n",
      "must have some solid grounds for the assured and easy \n",
      "\n",
      "must have some solid grounds for the assured and easy in his with the was a of one or the which was a little of a man and a is very very to be a very of it is a very much man in the man and a man was a man was a to his face and his father was a man and he was a little of the s the man is a little of a but is a is of a said holmes i have not a very man and not to be a to have a very man for the man was a to be a \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 47s 1ms/step - loss: 4.9443 - acc: 0.2278\n",
      "Generating from seed: \n",
      "have never set eyes on him yet i hope that \n",
      "\n",
      "have never set eyes on him yet i hope that i have not be to the in the of the which i had a very to be but i have the one of the which i had been to the other man in a man and a man and from his he was his his father was in the man and a man with a very with a very man in a man and no his man and was his father was a to have a man in a man and no was in the one of the which was no doubt of the very man and the was of \n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 48s 1ms/step - loss: 4.9604 - acc: 0.2461: 2\n",
      "Generating from seed: \n",
      "in braving it with impunity or in which any of \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in braving it with impunity or in which any of a and that is is the that is the which had been been by an as i have the by the of the of the the is the very of the man as i was a to be a and in the that i had the little of an for the holmes the was of the of the of the of the the of the no of the s the of one of the the of the man of the are the man was the man and a man was of his face and his he was a little of \n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 39s 885us/step - loss: 4.9778 - acc: 0.26511s - loss: 4.970\n",
      "Generating from seed: \n",
      "of bodies lying in strange fantastic poses bowed shoulders bent \n",
      "\n",
      "of bodies lying in strange fantastic poses bowed shoulders bent and all the have had been out of the in my of the i have the the of a of the i have been a little of some very little and i have been in the not have the him but i was a to the man of the man with a very he was a to him and he was a to be in the which was a to me but the is of a of my father s it is the a man who had been a very man for a very of a very man and a \n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 39s 875us/step - loss: 4.9754 - acc: 0.2832\n",
      "Generating from seed: \n",
      "the matter though as i said yesterday some of the \n",
      "\n",
      "the matter though as i said yesterday some of the had been the by a holmes of a holmes as a man who have been been in a to be in the which was a little man said holmes it is a a man he said he was a very man and a man and a very man and a man with a very with a very of a very man and he had his his father was to his he was a with a man and i was a to be but i was a to have a so man for the man but he was his very of \n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 37s 840us/step - loss: 4.9548 - acc: 0.3018\n",
      "Generating from seed: \n",
      "indeed your example is an unfortunate one for your argument \n",
      "\n",
      "indeed your example is an unfortunate one for your argument said holmes said holmes that is was a to be no it is an a man who had been but by one i have been the very man for the man and he was a man and he was his then for his the he was in his him and he was in his i have a a man but i have a out of the he and as the as we have been in the of the of the of the the and i have the the of a man and a man was in his his was was \n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 43s 972us/step - loss: 4.9256 - acc: 0.3211\n",
      "Generating from seed: \n",
      "understand mr turner made his money yes certainly thank you \n",
      "\n",
      "understand mr turner made his money yes certainly thank you have been you have you and to the you are and i am not very have been but you will to be in this is a i have been in the i shall be the you in the i have been in my for it is a and i have been been a as we may be in a in it was the of a man and i had not to be a to be a so in a that i have been been in a very or man to the was a as of a very it is not \n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 47s 1ms/step - loss: 4.8911 - acc: 0.3406\n",
      "Generating from seed: \n",
      "found how i had betrayed myself i began to think \n",
      "\n",
      "found how i had betrayed myself i began to think that the was of us it was in the and he had his to his father was his him and was a to me to the a man he was in his father was a with a very in a man and he was his with his face and that he was a to me that i was in his i was a very in a he and in the that was upon the he was which i had been on the but when i was a to be a little in the very but i was not a holmes \n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 47s 1ms/step - loss: 4.8536 - acc: 0.3557\n",
      "Generating from seed: \n",
      "to surprise her it surprised me but surely it was \n",
      "\n",
      "to surprise her it surprised me but surely it was very little for me but it is it is a to do but i have a to do so i and the you have been in it in it is the of that he was in the he was not the of the and it was in the that i have not a little from my but the is not a little of the he said holmes i have not been in a very to my i have not an the have been to be of the that i have the little from the i have been the have been \n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 48s 1ms/step - loss: 4.8191 - acc: 0.3720\n",
      "Generating from seed: \n",
      "strangers having been seen upon the roads and yet i \n",
      "\n",
      "strangers having been seen upon the roads and yet i had not see the that i am not be but you have to be in it is in a the man of is a s of my it is that the in a man as a as he could not a man and he was a a of a but there was not a of him with his i have the the man who is it in it is it to be a little to be in the i have my the to have had been the in my own the is man with a not a a man but \n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 45s 1ms/step - loss: 4.7796 - acc: 0.3892\n",
      "Generating from seed: \n",
      "at present your majesty will of course stay in london \n",
      "\n",
      "at present your majesty will of course stay in london for the you was not in his very i have a very is a very man and as it was a very man at the his was a man in a was in a a and in a man as a as they have been in the a was of a little as we are at all the said holmes said he had a very man as it his he was from the of a a but he had been a very but i could not be a not but a very as he as we have been in the \n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 47s 1ms/step - loss: 4.7435 - acc: 0.4043\n",
      "Generating from seed: \n",
      "of course that is only just for the time mr \n",
      "\n",
      "of course that is only just for the time mr holmes was my father and to the was of his one or the he had been i have a out of the all but said i have a man of the as i have my own the is he for him but it had not been very so at that he could not and the had been been with a at the time of the of the i shall in my the was was a and of a man and i was not a a of it but i am not a have but what you i have been to \n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 51s 1ms/step - loss: 4.7021 - acc: 0.4203: 5s - loss - ETA: 4s - loss: 4.\n",
      "Generating from seed: \n",
      "by a steep flight of steps leading down to a \n",
      "\n",
      "by a steep flight of steps leading down to a man who is the upon one of the which i had not a my so little as if i was not a to be in the i have a to have but so that the man who was it was in an was a of all on as but as we could not have a very in one said holmes but i was not to be to the in a at which i have the in the of which i have the very there is no a man you s it was the very in which i have not now \n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 42s 948us/step - loss: 4.6649 - acc: 0.43420s - loss: 4.66\n",
      "Generating from seed: \n",
      "no clew in them to mr angel save that he \n",
      "\n",
      "no clew in them to mr angel save that he had a very by a do you know that he is a i think that it is not in the to of a so i was that that it was of it said that he was not a not a a and of a man who have been been i have to that it is a man who is a and of he and now that the was very to be the we which are a very in my upon it is some and i had been very the is a man in which it was in the of the \n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 48s 1ms/step - loss: 4.6265 - acc: 0.4456\n",
      "Generating from seed: \n",
      "in the sailing ship i think that it is quite \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the sailing ship i think that it is quite as to that we have been upon a very well that i had been some and some or and we could not have it is to and that i have you have a man with man from the i have been a little of some on you but i am not a little of said holmes i have not have a very man as he as it the me and the one of the not of some the s have been in the i have not have the as but as he could be in the that i was a \n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 48s 1ms/step - loss: 4.5879 - acc: 0.4576: 6s - loss: 4.5865 - acc\n",
      "Generating from seed: \n",
      "both you and the coroner have been at some pains \n",
      "\n",
      "both you and the coroner have been at some pains said he to his be the up to the of the not and a very so i was that i was not one of the man who is in i in my own her and so i am very it is no one of some very but we may not be in his face and i there is a little not a man for a very man in his was but his father was a little of upon which you have had been as i could have the some one of my father i was the there is not a \n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    RNNmodel.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars, then use it to \n",
    "    # generate text from model for next 100  \n",
    "    test_idx = np.random.randint(len(input_words))\n",
    "    test_words = input_words[test_idx]\n",
    "    print(\"Generating from seed: \")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    print(\"\\n\")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN))\n",
    "        for i, ch in enumerate(test_words[-10:len(test_words)]):\n",
    "            Xtest[0, i] = word2index[ch]\n",
    "        pred = RNNmodel.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2word[np.argmax(pred)]\n",
    "        print(ypred, end=\" \")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_words.append(ypred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Прописываю еще раз в связи с тем, что на момент обучения использовались эти же переменные\n",
    "test_words = []\n",
    "test_labels = []\n",
    "for i in range(0, len(text2) - SEQLEN, STEP):\n",
    "    test_words.append(text2[i:i + SEQLEN])\n",
    "    test_labels.append(text2[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "evaluation = eval_model(RNNmodel)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on i had his as some one or holmes could come to in it with you to the i it is there but one and said holmes what you have a is a very to do but and you do you can see that this was i should you see what in you are to i was there you upon the this case mr could you have my been with me to be his with you who were to be his me or his i not his his father but i could there he had as i have been when a as when we have had him with a been that upon me then to his she would do that was with them my own man and that in his face was a little and when his up or as he in it was a s when you will be \n"
     ]
    }
   ],
   "source": [
    "gen_text = generate_text(RNNmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN embedding 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(Embedding(nb_words, 100, input_length=SEQLEN))\n",
    "RNNmodel.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_words),\n",
    "                    unroll=True))\n",
    "RNNmodel.add(Dense(nb_words))\n",
    "RNNmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "RNNmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])\n",
    "\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    RNNmodel.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars, then use it to \n",
    "    # generate text from model for next 100  \n",
    "    test_idx = np.random.randint(len(input_words))\n",
    "    test_words = input_words[test_idx]\n",
    "    print(\"Generating from seed: \")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    print(\"\\n\")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN))\n",
    "        for i, ch in enumerate(test_words[-10:len(test_words)]):\n",
    "            Xtest[0, i] = word2index[ch]\n",
    "        pred = RNNmodel.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2word[np.argmax(pred)]\n",
    "        print(ypred, end=\" \")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_words.append(ypred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Прописываю еще раз в связи с тем, что на момент обучения использовались эти же переменные\n",
    "test_words = []\n",
    "test_labels = []\n",
    "for i in range(0, len(text2) - SEQLEN, STEP):\n",
    "    test_words.append(text2[i:i + SEQLEN])\n",
    "    test_labels.append(text2[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = eval_model(RNNmodel)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = generate_text(RNNmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel = Sequential()\n",
    "LSTMmodel.add(Embedding(nb_words, 64, input_length=SEQLEN))\n",
    "LSTMmodel.add(LSTM(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_words),\n",
    "                    unroll=True))\n",
    "LSTMmodel.add(Dense(nb_words))\n",
    "LSTMmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "LSTMmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 42s 943us/step - loss: 6.4230 - acc: 0.0539\n",
      "Generating from seed: \n",
      "man s story was absolutely true then what hellish thing \n",
      "\n",
      "man s story was absolutely true then what hellish thing the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 37s 836us/step - loss: 6.1206 - acc: 0.0684\n",
      "Generating from seed: \n",
      "the river to the east of london bridge between a \n",
      "\n",
      "the river to the east of london bridge between a man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man \n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 36s 822us/step - loss: 5.9127 - acc: 0.0855\n",
      "Generating from seed: \n",
      "shall see you at horsham then no your secret lies \n",
      "\n",
      "shall see you at horsham then no your secret lies to the little of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of \n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 37s 845us/step - loss: 5.7577 - acc: 0.1038\n",
      "Generating from seed: \n",
      "fairly to work he started me off upon the letter \n",
      "\n",
      "fairly to work he started me off upon the letter of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of \n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 37s 839us/step - loss: 5.6508 - acc: 0.1135\n",
      "Generating from seed: \n",
      "you presently it was about ten minutes before we regained \n",
      "\n",
      "you presently it was about ten minutes before we regained a little man of the same of the same of the same man of the same man of the same of the same man of the same man of the same of the same man of the same man of the same of the same man of the same man of the same of the same man of the same man of the same of the same man of the same man of the same of the same man of the same man of the same of the same man of the same man of the same of the same \n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 40s 901us/step - loss: 5.5666 - acc: 0.12180s - loss: 5.5630 -\n",
      "Generating from seed: \n",
      "quarrels and this i am sure was one of them \n",
      "\n",
      "quarrels and this i am sure was one of them and i have not been to the room of the whole man and i have not been to the room of the whole man and i have not been to the room of the whole man and i have not been to the room of the whole man and i have not been to the room of the whole man and i have not been to the room of the whole man and i have not been to the room of the whole man and i have not been to the room of the whole man and i have not \n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 41s 920us/step - loss: 5.4953 - acc: 0.1282\n",
      "Generating from seed: \n",
      "what you earn into the bargain you no doubt travel \n",
      "\n",
      "what you earn into the bargain you no doubt travel that i have a little little to be for the man and i have a little little man and i have been to the matter i have not been to be for the own man and i have a little little man and i have been to the matter i have not been to be for the own man and i have a little little man and i have been to the matter i have not been to be for the own man and i have a little little man and i have been to the matter i have not \n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 44s 981us/step - loss: 5.4330 - acc: 0.1354\n",
      "Generating from seed: \n",
      "get hold of replied lestrade with some warmth and that \n",
      "\n",
      "get hold of replied lestrade with some warmth and that i was a little little man of the matter and i have not been very little little than said holmes i have a little little little man and i am not to be said holmes i have a little little little man and i am not to be said holmes i have a little little little man and i am not to be said holmes i have a little little little man and i am not to be said holmes i have a little little little man and i am not to be said holmes i have a little little \n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 44s 987us/step - loss: 5.3850 - acc: 0.1420\n",
      "Generating from seed: \n",
      "here are the father s feet as he paced up \n",
      "\n",
      "here are the father s feet as he paced up to the door of the same door and the king was a man of the man and i have a doubt that i have been heard of the same man and i have been seen of the same man and i have a doubt of the same man and i have a little man of the whole man and i have a little man of the man and i have a little man of the whole man and i have a little man of the man and i have a little man of the whole man and i have a \n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 41s 924us/step - loss: 5.3266 - acc: 0.14851s - loss: 5.3223 - acc: - ETA: 1s - loss: 5.3246 - acc: 0 - ETA: 1s - loss: \n",
      "Generating from seed: \n",
      "only remaining point was what they were burrowing for i \n",
      "\n",
      "only remaining point was what they were burrowing for i had been a little man and i am not t have a little man and i am not t have a little man and i am not t have a little man and i am not t have a little man and i am not t have a little man and i am not t have a little man and i am not t have a little man and i am not t have a little man and i am not t have a little man and i am not t have a little man and i am not t \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 40s 909us/step - loss: 5.2689 - acc: 0.1543\n",
      "Generating from seed: \n",
      "the obvious facts that he has at some time done \n",
      "\n",
      "the obvious facts that he has at some time done to the other and i have been to go for the coroner i have been of the own man of the own man and i have been to the same man and i am not to the own man and i am not to be in the own man of the own man and i have been to the same man and i am not to the own man and i am not to be in the own man of the own man and i have been to the same man and i am not to the own man and \n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 40s 892us/step - loss: 5.2247 - acc: 0.1619\n",
      "Generating from seed: \n",
      "forced to admit that the facts are to the best \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forced to admit that the facts are to the best of the same same same man and the whole same man is of his own man s own man and i have not been very coroner i have been been to the same and i have been heard of the same same same same same whole whole whole little and i shall be to do i shall be to be very own of my own own man and i have not heard my own little little little man and i have been to be whole own and i am not to be than i am not know that i have \n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 45s 1ms/step - loss: 5.1851 - acc: 0.1705\n",
      "Generating from seed: \n",
      "being a traveller in wines they got 4700 for the \n",
      "\n",
      "being a traveller in wines they got 4700 for the whole case and i had been whole majesty and i am not know that i have not been been before i am not know that i have been been whole majesty i have been seen of my own own man and i have been heard of the whole case of the same whole whole whole man is to be so i have been to be whole own and i am not know that i have not been been before i am not know that i have been been whole majesty i have been seen of my own own man and \n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 43s 974us/step - loss: 5.1521 - acc: 0.1780\n",
      "Generating from seed: \n",
      "when you returned on hearing the cry and found your \n",
      "\n",
      "when you returned on hearing the cry and found your father is not a little man and he had been been upon his own whole own and i have been been little whole own i am not am not be i am not know that i have been been little whole own own i am not think that i have been been small whole whole own i am not be i am not know i am not know i am not know my am not have been am been very whole than i am not think that i have been been little whole own own i am not think that \n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 37s 845us/step - loss: 5.1186 - acc: 0.1875\n",
      "Generating from seed: \n",
      "on the ground then here are the father s feet \n",
      "\n",
      "on the ground then here are the father s feet and i was a little man and a few man was very whole and i am a little man and i am not think that i was not to be so i am a little little for my own own man and i have been had been man and i had been seen his whole few little little man and his own own man and i have been in the own man of the same own man and i have been and then i am a little man and i had been little in my own own man and i \n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 48s 1ms/step - loss: 5.0781 - acc: 0.1973\n",
      "Generating from seed: \n",
      "everything was as right as possible the table was set \n",
      "\n",
      "everything was as right as possible the table was set and i am not think that i have been some little man of my own own man and a man s i have been had been little for my own own man and a man had been been upon us he was a very man and a man and would be a man but he was a man and a man and a man had been would not have been in his own own own man and i have been wilson have been do to be so i have a little little matter to be so i have a little \n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 43s 969us/step - loss: 5.0627 - acc: 0.2066\n",
      "Generating from seed: \n",
      "anything which the mind of man could invent we would \n",
      "\n",
      "anything which the mind of man could invent we would not be have a little man and then he was a very man and his father had been in his own or or two and of the do you know of it must be a man s very man and was a very man and he was a very man and a man was very and i am a very man and i have been a man and would be a man of his own i have been very man and i have been two little little man said holmes i have been a man and then he had been \n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 46s 1ms/step - loss: 5.0315 - acc: 0.2159\n",
      "Generating from seed: \n",
      "an absolute imbecile in his profession he has one positive \n",
      "\n",
      "an absolute imbecile in his profession he has one positive man he was very am in his own and i have been one of my own little man and i am not think of you that i have been some little man but i am not think that he is not a am am am not a am think of i have you have been own man for my own am not have been very for the own of am one of the man s i have been out of the case that i have been in would am not be think of that i have been some little man \n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 44s 998us/step - loss: 4.9508 - acc: 0.2302\n",
      "Generating from seed: \n",
      "this is what began it all you just read it \n",
      "\n",
      "this is what began it all you just read it has been to be little for the matter of you and i have been a little man of his own own i am not am not know holmes said holmes i have a little man said holmes you have been a man and am a am am am not a very am am am not have not know how i have been to go for the is must be in the man and i have been little little know of my own go and i have not been little am not be am not know that i have not been \n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 41s 933us/step - loss: 4.9649 - acc: 0.2437\n",
      "Generating from seed: \n",
      "you don t it s a fine law abiding country \n",
      "\n",
      "you don t it s a fine law abiding country is a very very man and his am not be i have a very am of am not be am not so i have been to know you of my own i have not heard of my own i have been little by my own own of my am not not have been very am not in my think that i have not been of my own own i have been for my own not have been heard of the matter i have been been of my own see that i had not heard of my own own i am \n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 49s 1ms/step - loss: 4.9753 - acc: 0.2565\n",
      "Generating from seed: \n",
      "can waste time over this sort of fantastic talk mr \n",
      "\n",
      "can waste time over this sort of fantastic talk mr holmes he said that you have been and i have been little for my own think of my father had not been to know my own is the am not a am not a very am know i think that i have not been of the am not am not have a very am not a very man in his own i have a very am am not not be not in my own not a am not have a am very am not in a man s father said he was a am a see that he had been \n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 41s 928us/step - loss: 4.9777 - acc: 0.2703\n",
      "Generating from seed: \n",
      "little methods which are if he won t mind my \n",
      "\n",
      "little methods which are if he won t mind my own i have a am a am am not so i have a am one of my own think of that i had been heard of my have been see upon it i had a am not a little man but i have a am am am not not have been very very know of know it was a see that is that you have been the am am not have been see for it is not not a am not have a am see one of the would have been see that it was a very very would be \n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 41s 924us/step - loss: 4.9486 - acc: 0.2841\n",
      "Generating from seed: \n",
      "elias whitney d d principal of the theological college of \n",
      "\n",
      "elias whitney d d principal of the theological college of would have been been see for that he was a very very man in his father and his father had been a little little for me had not been a little man who had been been in his own he had a very man and his father had been and had been not to be so in his not the man s the man was a man and a man was he had been heard to him an father had been very man and was a little of his father s and a very man and he had been very \n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44378/44378 [==============================] - 42s 946us/step - loss: 4.9460 - acc: 0.29932s - l - ETA: 0s - loss: 4.9457 - \n",
      "Generating from seed: \n",
      "violet ink she had written in a hurry and dipped \n",
      "\n",
      "violet ink she had written in a hurry and dipped her street when i am not so be i have been to be so for my is not that the one was had not been in would have been not been not in his not be his father s i have been little for my father s not so i am a man and i have a very of do so i have not an been of my the been of his have been not his his his had been not so his i have been his little little have been not be i have a am not be not \n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 45s 1ms/step - loss: 4.9516 - acc: 0.3143:  - E\n",
      "Generating from seed: \n",
      "a crumpled envelope and turning to the table he shook \n",
      "\n",
      "a crumpled envelope and turning to the table he shook a very upon which he had not a very man and a man was a he did not him at him and he would have been to come to do so i have not an i have been by the think of you and i have been two of my father had not think i am a little you have no little little for me and i have no very man of his but if he was the of his have been been not in his were so i have a little of his own own of the would have \n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    LSTMmodel.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    " \n",
    "    test_idx = np.random.randint(len(input_words))\n",
    "    test_words = input_words[test_idx]\n",
    "    print(\"Generating from seed: \")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    print(\"\\n\")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN))\n",
    "        for i, ch in enumerate(test_words[-10:len(test_words)]):\n",
    "            Xtest[0, i] = word2index[ch]\n",
    "        pred = LSTMmodel.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2word[np.argmax(pred)]\n",
    "        print(ypred, end=\" \")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_words.append(ypred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Прописываю еще раз в связи с тем, что на момент обучения использовались эти же переменные\n",
    "test_words = []\n",
    "test_labels = []\n",
    "for i in range(0, len(text2) - SEQLEN, STEP):\n",
    "    test_words.append(text2[i:i + SEQLEN])\n",
    "    test_labels.append(text2[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "evaluation = eval_model(LSTMmodel)\n",
    "print(evaluation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it was in a very more than be that were not have been not to be very for a very of his be i have the two or a shall have one of this be and then to do so he would not be more to do in you see that it would see of an the am and then are it to in my a out upon that all the he must be be so as to have as we were in that there is holmes think of some see you to am a am of mr holmes for the had i think you that i shall not have not some have been a could so do to do in an was a am to one should in the time for it not have his very man for the his own that i was was to the may been \n"
     ]
    }
   ],
   "source": [
    "gen_text = generate_text(LSTMmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM embedding 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel = Sequential()\n",
    "LSTMmodel.add(Embedding(nb_words, 100, input_length=SEQLEN))\n",
    "LSTMmodel.add(LSTM(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_words),\n",
    "                    unroll=True))\n",
    "LSTMmodel.add(Dense(nb_words))\n",
    "LSTMmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "LSTMmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])\n",
    "\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    LSTMmodel.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    " \n",
    "    test_idx = np.random.randint(len(input_words))\n",
    "    test_words = input_words[test_idx]\n",
    "    print(\"Generating from seed: \")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    print(\"\\n\")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN))\n",
    "        for i, ch in enumerate(test_words[-10:len(test_words)]):\n",
    "            Xtest[0, i] = word2index[ch]\n",
    "        pred = LSTMmodel.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2word[np.argmax(pred)]\n",
    "        print(ypred, end=\" \")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_words.append(ypred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Прописываю еще раз в связи с тем, что на момент обучения использовались эти же переменные\n",
    "test_words = []\n",
    "test_labels = []\n",
    "for i in range(0, len(text2) - SEQLEN, STEP):\n",
    "    test_words.append(text2[i:i + SEQLEN])\n",
    "    test_labels.append(text2[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = eval_model(LSTMmodel)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = generate_text(LSTMmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM embedding 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel = Sequential()\n",
    "LSTMmodel.add(Embedding(nb_words, 100, input_length=SEQLEN))\n",
    "LSTMmodel.add(LSTM(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_words),\n",
    "                    unroll=True))\n",
    "LSTMmodel.add(Dense(nb_words))\n",
    "LSTMmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "LSTMmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])\n",
    "\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    LSTMmodel.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    " \n",
    "    test_idx = np.random.randint(len(input_words))\n",
    "    test_words = input_words[test_idx]\n",
    "    print(\"Generating from seed: \")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    print(\"\\n\")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN))\n",
    "        for i, ch in enumerate(test_words[-10:len(test_words)]):\n",
    "            Xtest[0, i] = word2index[ch]\n",
    "        pred = LSTMmodel.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2word[np.argmax(pred)]\n",
    "        print(ypred, end=\" \")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_words.append(ypred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Прописываю еще раз в связи с тем, что на момент обучения использовались эти же переменные\n",
    "test_words = []\n",
    "test_labels = []\n",
    "for i in range(0, len(text2) - SEQLEN, STEP):\n",
    "    test_words.append(text2[i:i + SEQLEN])\n",
    "    test_labels.append(text2[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = eval_model(LSTMmodel)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = generate_text(LSTMmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 51s 1ms/step - loss: 6.4308 - acc: 0.0544\n",
      "Generating from seed: \n",
      "of theories to suit facts but the note itself what \n",
      "\n",
      "of theories to suit facts but the note itself what the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the of of the \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 55s 1ms/step - loss: 6.1223 - acc: 0.0665\n",
      "Generating from seed: \n",
      "on the sundial i read peeping over his shoulder what s not to be of a you and i have a little of a but i am not to be a very i have the little of the but i have it is a very man who is a a man and i have the one of my own and i have been a man and that the has been out the very of the he was a and of the and which i was in the of which i have had been in a and of my father was the of that a holmes and the the is of \n",
      "\n",
      "on the sundial i read peeping over his shoulder what s not to be of a you and i have a little of a but i am not to be a very i have the little of the but i have it is a very man who is a a man and i have the one of my own and i have been a man and that the has been out the very of the he was a and of the and which i was in the of which i have had been in a and of my father was the of that a holmes and the the is of of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of \n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 55s 1ms/step - loss: 5.9307 - acc: 0.0842\n",
      "Generating from seed: \n",
      "have been done in china i have made a small \n",
      "\n",
      "have been done in china i have made a small man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man of the man \n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 48s 1ms/step - loss: 5.7767 - acc: 0.1017\n",
      "Generating from seed: \n",
      "i have hopes then come i am all impatience to \n",
      "\n",
      "i have hopes then come i am all impatience to the own man of the own man and i have not to be the little man of the matter i have not to be the little man of the matter i have not to be the little man of the matter i have not to be the little man of the matter i have not to be the little man of the matter i have not to be the little man of the matter i have not to be the little man of the matter i have not to be the little man of the matter i have not to \n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 56s 1ms/step - loss: 5.6581 - acc: 0.1138\n",
      "Generating from seed: \n",
      "striking his stick upon the flags which lined the floor \n",
      "\n",
      "striking his stick upon the flags which lined the floor of the few man of the own man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i have not be to the little man of the matter i \n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 57s 1ms/step - loss: 5.5724 - acc: 0.1209\n",
      "Generating from seed: \n",
      "of his hand your majesty has something which i should \n",
      "\n",
      "of his hand your majesty has something which i should be to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for you to be for \n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 57s 1ms/step - loss: 5.4996 - acc: 0.1285\n",
      "Generating from seed: \n",
      "a very stout florid faced elderly gentleman with fiery red \n",
      "\n",
      "a very stout florid faced elderly gentleman with fiery red of the black black thick and and the man was a man of the same man and the man was a little man of the matter i have been been little little and i have been been little little and i have been been little little and i have been been little little and i have been been little little and i have been been little little and i have been been little little and i have been been little little and i have been been little little and i have been been little little and i have been been \n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 50s 1ms/step - loss: 5.4296 - acc: 0.1356\n",
      "Generating from seed: \n",
      "lighting your task is confined to that when you raise \n",
      "\n",
      "lighting your task is confined to that when you raise the whole man and the whole man had been been to be in the same man and the same man was a few man of the same man was a few man of the same man was a few man of the same man was a few man of the same man was a few man of the same man was a few man of the same man was a few man of the same man was a few man of the same man was a few man of the same man was a few man of the same man \n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 50s 1ms/step - loss: 5.3647 - acc: 0.1431: 3s - loss: 5 - E\n",
      "Generating from seed: \n",
      "the wood about the same then if it was removed \n",
      "\n",
      "the wood about the same then if it was removed the whole man was a few man and he was a little man and he had been been in the same man and he had been been in the same man and he had been been in the same man and he had been been in the same man and he had been been in the same man and he had been been in the same man and he had been been in the same man and he had been been in the same man and he had been been in the same man and he had been been in \n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 64s 1ms/step - loss: 5.3047 - acc: 0.1491: 1s - loss\n",
      "Generating from seed: \n",
      "desires to consult you upon a matter of the very \n",
      "\n",
      "desires to consult you upon a matter of the very man and i shall be the same small little little little of this and i was not a little man of holmes and i have been been in the same small man of the door of his own little man and he was a little little man and he was not a little man and he was not a little man and he was not a little man and he was not a little man and he was not a little man and he was not a little man and he was not a little man and he was not \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 63s 1ms/step - loss: 5.2553 - acc: 0.1561\n",
      "Generating from seed: \n",
      "open drawers as if the lady had hurriedly ransacked them \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open drawers as if the lady had hurriedly ransacked them and we had been few small than for the whole man was a man and he was not a little man and i am not a little man and i have been been in the same same same am be and few be few than holmes i have been been in some house and i am not know that i was not a little man and i have been know that i had been been in some own man and i have been know that i had been been in some own man and i have been know that i \n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 52s 1ms/step - loss: 5.2105 - acc: 0.1611\n",
      "Generating from seed: \n",
      "a word became what you would call over here a \n",
      "\n",
      "a word became what you would call over here a man said holmes he was a few man and he was not a little man and he was not a few man and he was not a little man and he was not a few man and he was not a little man and he was not a few man and he was not a little man and he was not a few man and he was not a little man and he was not a few man and he was not a little man and he was not a few man and he was not a little man and \n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 53s 1ms/step - loss: 5.1597 - acc: 0.1707\n",
      "Generating from seed: \n",
      "she would send it on the day when the betrothal \n",
      "\n",
      "she would send it on the day when the betrothal is a little little man and i have been go of the whole man s whole and i have been seen in the whole man s whole and i have whole little little of the whole man s whole and i have been seen in the whole man s whole and i have whole little little of the whole man s whole and i have been seen in the whole man s whole and i have whole little little of the whole man s whole and i have been seen in the whole man s whole and i have whole \n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 59s 1ms/step - loss: 5.1178 - acc: 0.1794: 5s - loss: 5.1073 - a - ETA: 4s - loss: \n",
      "Generating from seed: \n",
      "that a and b cleared or left the country and \n",
      "\n",
      "that a and b cleared or left the country and door with a whole whole whole whole man is not have been very little than i am not a whole whole man s whole man s whole man s very man and he was not a little man and he was a very little man and he was a little whole man and i am not a whole whole man s whole man s whole man s very man and he was not a little man and he was a very little man and he was a little whole man and i am not a whole whole man s whole \n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 56s 1ms/step - loss: 5.1085 - acc: 0.1903\n",
      "Generating from seed: \n",
      "with a long draught of water you are hungry i \n",
      "\n",
      "with a long draught of water you are hungry i am not very little t have been been in my own man s whole man s very man and he was not and he was a very man and he was not very man and he was very very man and he was very little of he was very little and i have been been been in my own little whole man and he would be to be a little whole man who was not very in the other s i was not in the man who was not very very and i was not to think that i had \n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 56s 1ms/step - loss: 5.0962 - acc: 0.1995\n",
      "Generating from seed: \n",
      "an uncertain foot then glancing quickly round he straightened himself \n",
      "\n",
      "an uncertain foot then glancing quickly round he straightened himself in a few room and chair which was a very little whole matter of which i have been to the man s door i was not to the man of his own was a man and a whole man who is a little matter that i have not a whole little whole man is not a whole man s whole man s holmes and he had been been to him and he was a very whole man s whole man s whole man s very man and he was not a very man and he was not a whole man \n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 58s 1ms/step - loss: 5.0708 - acc: 0.2098\n",
      "Generating from seed: \n",
      "like the forecastle of an emigrant ship through the gloom \n",
      "\n",
      "like the forecastle of an emigrant ship through the gloom that the whole door was was and man were as we can have been the whole man and i shall be the matter with the whole little matter i have been to the other we have been in the matter s i have been to think of the whole man had been very little to have been been in the whole man s matter and i have been to be know that the whole was was to be so that he had been been in some man and he had been been in his son he had been been in \n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 49s 1ms/step - loss: 5.0703 - acc: 0.2192: 1s - loss: 5.0651 - acc: 0.2 - ETA: 0s - loss: 5.0654 \n",
      "Generating from seed: \n",
      "i won t insult your intelligence by telling you how \n",
      "\n",
      "i won t insult your intelligence by telling you how i have been the little man s chair i shall be it and i shall be a little man of this own own man s own and i have been to be that i had been t have been been in my own and i have been been to know holmes and i had been in my own little and i have been been to know holmes and the whole man was in his own own other not be a little man and i have been to be know that he was a very not have been been in one \n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 46s 1ms/step - loss: 5.0143 - acc: 0.2325\n",
      "Generating from seed: \n",
      "a mews in a lane which runs down by one \n",
      "\n",
      "a mews in a lane which runs down by one of the whole other i had not to the door that he had been been in his own matter and that he had been been to me and that was his own man s own and i have been a know of my own own own man and i have been know that she is a very own little man said holmes i have been to the whole man and then he was a very own man and then he am a very man and then he am not very i very man said holmes he is a very own \n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 47s 1ms/step - loss: 5.0160 - acc: 0.2481\n",
      "Generating from seed: \n",
      "might rely on you but what is it you wish \n",
      "\n",
      "might rely on you but what is it you wish to me i have been in one of my own was to have a know we have been a own own man and then i have been to be so that he had been in some own man and not have been in some man and as he had been in his am a man and he had been been in his own own and not have been been very know that i had not not have been been in a know that he had been in some own man and that was his own little little and i have \n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 48s 1ms/step - loss: 5.0231 - acc: 0.2574\n",
      "Generating from seed: \n",
      "can spare i advertised for him in last saturday s \n",
      "\n",
      "can spare i advertised for him in last saturday s little in his father s a man and she is not and that she is not to be a think of this own matter if you have no very know that she is a very little man who is not a little man and the other was is one of my little and i have my father s to be be very for i was not to have been been know by he i was to the other man s it was a very man and a man who would not be the man and i was not to be \n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 54s 1ms/step - loss: 5.0149 - acc: 0.2720\n",
      "Generating from seed: \n",
      "then i shall go in it but i must owe \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "then i shall go in it but i must owe you that i have not to have been know what is not do you of my father s i have been at the time that i had not to have been know what i was not to have been know what you will not be know that you have been very i have not know that holmes is my in the am so i am not and i have been a very do not know holmes that i should not be the matter of the matter have you know you will see that for the i shall be very so \n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 50s 1ms/step - loss: 4.9932 - acc: 0.2828\n",
      "Generating from seed: \n",
      "of the criminal but how did you gain them you \n",
      "\n",
      "of the criminal but how did you gain them you have to be a very man and i have been been in some own man who had not have been very know what i was not that she is not very i have been to think of it but i have not to be very am that there is not one of the man who had a very little of have been own in one of his man was to the man who s a very man and that was all his face and a very little have been to me man and i was not to be very well \n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 53s 1ms/step - loss: 4.9148 - acc: 0.2943: 2s - loss: 4.9119 - acc: 0 - ETA: 2s - loss: 4.9096 - acc: 0.2 - ETA:\n",
      "Generating from seed: \n",
      "merryweather is a bank director and personally interested in the \n",
      "\n",
      "merryweather is a bank director and personally interested in the case i am so know that you have been very so i have been very for it of my father s not he said holmes you have been to me and that the man had been was not to the man and his was his face and he was a few very little to be but holmes was a little for the matter of the man s holmes is the little to me and the was very well it is a little little little to the case of the have been been very to have been the been in this \n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "44378/44378 [==============================] - 56s 1ms/step - loss: 4.9307 - acc: 0.3099: 11s - l -  - ETA: 4s - loss: 4.918\n",
      "Generating from seed: \n",
      "police from time to time i heard some vague account \n",
      "\n",
      "police from time to time i heard some vague account of a and a man who had been in one of the time and he had the been for he had been in his own case and that was the upon my own little man and the man was a very little and i was a very man in my own own matter have been in that i shall be one of the time to the time to be the other but i could not have a very so that i had not a very not not know holmes but i would not have a to do an so that \n"
     ]
    }
   ],
   "source": [
    "GRUmodel = Sequential()\n",
    "GRUmodel.add(Embedding(nb_words, 64, input_length=SEQLEN))\n",
    "GRUmodel.add(LSTM(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_words),\n",
    "                    unroll=True))\n",
    "GRUmodel.add(Dense(nb_words))\n",
    "GRUmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "GRUmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])\n",
    "\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    GRUmodel.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    " \n",
    "    test_idx = np.random.randint(len(input_words))\n",
    "    test_words = input_words[test_idx]\n",
    "    print(\"Generating from seed: \")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    print(\"\\n\")\n",
    "    for i in test_words:\n",
    "        print(i, end=\" \")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN))\n",
    "        for i, ch in enumerate(test_words[-10:len(test_words)]):\n",
    "            Xtest[0, i] = word2index[ch]\n",
    "        pred = GRUmodel.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2word[np.argmax(pred)]\n",
    "        print(ypred, end=\" \")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_words.append(ypred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Прописываю еще раз в связи с тем, что на момент обучения использовались эти же переменные\n",
    "test_words = []\n",
    "test_labels = []\n",
    "for i in range(0, len(text2) - SEQLEN, STEP):\n",
    "    test_words.append(text2[i:i + SEQLEN])\n",
    "    test_labels.append(text2[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "evaluation = eval_model(GRUmodel)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but for that it had not from one left an a time to my own but it was not that she will do it is a very man in a very but there some no man or his face for the very own i of him and he would be a more of it old man said when it had been one in his door were by his father i who s much at the other s in the house and that was not in that time she could come at all of my time to you will be the an matter which you may come in you at the matter be i shall be in that an case and found not but your was an had in one come to that and that i would have no am much very not not be holmes so not will have the \n"
     ]
    }
   ],
   "source": [
    "gen_text = generate_text(GRUmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой модели кроме последней прописаны еще различные embedding-и. \n",
    "В целях экономии времени, как бы не было ограничено число эпох (к сожалению, удалось прогнать для 3-х моделей только с единственной эпохой:(), построение моделей с разным числом эмбеддингов тоже пришлось урезать. \n",
    "Поэтому выводы будут представлены с начальными эмбеддингами (в этом случае - это 64).\n",
    "Насчет количества эпох, текст получается более связный и \"красивый\", если мы будем использовать не одну, а более эпох. При этом показатель loss тоже снижается. Однако, на компьютере прогон одной модели занимает порядка 2,5 часов (скорее всего так долго еще из-за того, что тренирочный текст оказался достаточно большим). Но модель simpleRNN все же удалось прогнать с 3 эпохами и вот, что получилось: \n",
    "\n",
    "Iteration #: 24 \n",
    "Epoch 1/3 \n",
    "44378/44378 [==============================] - 95s 2ms/step - loss: 3.7130 \n",
    "Epoch 2/3 \n",
    "44378/44378 [==============================] - 95s 2ms/step - loss: 3.7065 \n",
    "Epoch 3/3 \n",
    "44378/44378 [==============================] - 96s 2ms/step - loss: 3.6996 \n",
    "preparations have gone so far that we can risk the \n",
    "\n",
    "preparations have gone so far that we can risk the very way a down that your of all this have have your you said holmes as to have have the the little then would not have very the to is a or that he has not an now if it is i to not more with her there and i in the in the some nothing to a it was it we never little before by a what and in he then upon an your at was was in a he man in this holmes and when it for he was in the other he was you to what in\n",
    "\n",
    "Довольно-таки неплохо, как мне кажется:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же говорить о перплексии, то для простой рекурентной нейросети этот показать составил 0,5,\n",
    "для LSTM - 0,5, \n",
    "для GRU - 0,5\n",
    "Выходит, что с данными условиями все три модели работают примерно одинаково, различия , как можно видеть, при обучении в показаниях loss и accuracy на последних итерациях."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RNN (Lesson 5-6).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
